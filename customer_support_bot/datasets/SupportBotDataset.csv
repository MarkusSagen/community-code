Question,Answer,1
Is there a way to upload models to the Peltarion platform?,"No, it's currently not possible to upload models to the Peltarion platform.",1
Is it possible to download the trained model and run it locally?,"Yes, (depending on your subscription plan)  you can. There's a button in the upper-right corner on the Model view.",1
Nothing happens when I call Peltarion from Bubble,"The most common issue when users work with Peltarion from Bubble is that the Bubble app isn't properly built. Maybe the workflow (Bubble term) isn't setup correctly, or maybe the labels displaying the result aren't connected to the data. A good start, given there's no error message shown (see other Bubble-related question below) is to ask for screenshots from the different views and see how it's all setup.",1
I get an error message when calling Peltarion from Bubble,"There are multiple potential causes for this. A checklist for the most common issues are:
- Is the model deployed and enabled on the Peltarion platform?
- Are the credentials correct?
Calling the API with cURL verifies that the credentials are correct and the API is enabled, so it might be a good step.
If it still doesn't work, one possibility is to go to Azure, stream the logs for the middle layer (""peltarionforward"") and ask the user to call the Peltarion platform again. Following the logs, you will see the request and the response which gives you a good picture of what's happening.
",1
I want to cancel my subscription,"Reply that we'll do it, and the account will be gone within 90 days. Talk to Patrick Juhl about removal.",1
I get an error when running my experiment,"There might be many causes for this, so the simplest way to do this is to check the logs. If you have access - great, otherwise check with the platform team. To find the logs, you'd need the project ID which you can get from copying the browser URL.",1
I'm unable to change encoding of feature,"Hi, the dataset settings are locked when the dataset becomes saved. To change settings, you must click on Go to draft to start editing settings, and save a new version of the dataset when you are done. Let me know if you need further assistance!",1
"I have two features or labels ""Customer's msg"" and ""bot response"" . Through feature settings I am unable to change the encoding from Categorical to text","Hi, the dataset settings are locked when the dataset becomes saved. To change settings, you must click on Go to draft to start editing settings, and save a new version of the dataset when you are done. Let me know if you need further assistance!",1
"I tried to upload my dataset. In my case, the dataset consists of text, like a speech, that I want to upload and then run semantic search, showing me not only exact matches, but also closely related quotes. Do you think your platform can help me with this project, and what is exactly the best format to upload this kind of data, as this is not tabular data, but rather unstructured text. Thank you","The problem you describe sounds like it could be solved with Text similarity.
I would recommend you to try the tutorial Find similar Google questions so that you can get an idea of how it works on the platform and what results you might expect.

The way you would use it for your own problem is to upload a dataset containing many pieces of text that you want to index. The CSV file format is appropriate for this purpose, where you would have 1 feature (=column) with the texts you want to index, and at least 1 extra feature. The extra feature isn't actually used by the model, so you could have a column full of 0 for instance. You might also want extra features (=extra columns) that give info about the text, like the author, source, etc.

Once you uploaded this file and deployed a model using it (similarly to the tutorial), you will be able to send arbitrary text to the platform via the API and you will receive the texts from your dataset that are semantically related.",1
"I have an error saying: ""Target: This block needs a shape of . Update the previous blocks OR change the target feature to match the shape.""","The ""Target shape"" error message appears when the last block of the model graph (often a Dense block) doesn't output data in the same shape as the shape of the feature that is used in the Target block.

This can usually be fixed easily by changing the number of Nodes inside the last dense block to match the Target block. For example, if the Target uses a Numeric feature, the Dense block just before the Target should use 1 Node (corresponding to 1 numeric value).

If the target uses a Categorical feature with, for instance, 3 categories, then the last Dense block should use 3 Nodes (corresponding to the probabilities for 3 categories).

Now, there is something peculiar with similarity models because they don't actually need training so the Target feature doesn't matter, but the model graph should still look correct to be able to run.

Therefore you could use any numeric or categorical feature in the Target block, and make sure that the last Dense block matches the same shape as that feature. If you only have text in your dataset, you could create a dummy Numeric feature which is 0 everywhere just for the purpose of providing a Target to the model graph.

Let me know if that helps, or if things are still unclear and you're not sure how to proceed.

",1
The main issue right now is that any query I attempt on the API produces a 500 error. Do you have any idea on how I can figure this problem out?,"Typically, the first thing to check is if the model is Enabled, as it's easy to forget it after the deployment is created. For similarity models you will need to wait until indexing has finished to get the Enable button available.
If that's not the cause of the problem, there could be more things to check. For instance how to you query the API? Could you share an example of the code you use for that?
If it's OK for you that I look inside your experiment, I could also double check the model settings and test calling the API to see what logs I get.",1
"I always get an error saying: ""Target: Categorical crossentropy requires a target dimension of at least 2. Did you mean to use binary crossentropy instead?"" I also get this warning: ""The model doesnt contain any trainable blocks. Clicking Run will only go over the validation subset once, and no training will occur. To make a block trainable check the Trainable box."" I try to fix these errors and warning but I am probably messing something up in the process. On the Google questions tutorial there is this: ""The USE Embedding model is already pretrained for the purpose of text similarity. As a result, we don’t need to train it. We can directly run the model to create it and move to the next step."" How so, if when I import my dataset I face all these error and warnings? Sorry if I am bothering you, but I feel quite lost at the moment. Thank you","If I understand your status correctly, now you manage to use the similarity search feature correctly but there are 2 problems that you had to guess how to solve.

I'll give you some explanation for each problem so that you understand what's happening and how to solve it.

Target: Categorical crossentropy requires a target dimension of at least 2.
This message appears when there is a mismatch between the model target feature and the target's loss function. Even though the target feature is not actually used for similarity use cases, a model graph should always be correct as the same model could be deployed for different usages.
In your case, you can follow the suggestion and change the loss function to Binary crossentropy to make the model graph correct. If you were in a case where you need to train the model, you would also want to double-check that you are using the intended target feature and that it is encoded appropriately.
The model doesn't contain any trainable blocks.
This message appears when none of the blocks used in your model are set to Trainable. This could be a problem if you intend to train the model to solve your own personal task, but as you noticed we don't need to train models in the case of similarity search applications. Therefore you can simply ignore this message and, as it says, when you click on Run no training will occur which will save computation time. Skipping training lets you create a deployment faster.
I hope this covers the questions you had, and that you are not having another problem that I haven't noticed. Don't hesitate to ask otherwise!
",1
Hey. I get stuck on the log in page. It does not load anything except for the chat. Can you help me?,"Did you try to close your browser and then open it again? Sometimes data gets cached which messes up with the page loading.
Could you try to go to https://platform.peltarion.com/ in incognito mode? This should work if the problem is due to some cookies that went wrong.
",1
Is there a way to add to BERT's vocabulary and/or to use BioBERT? We're dealing with medical invoice data and there's quite a bit of acronyms/domain specific language on those.,"I would have to answer no because the biomedical pretraining of BioBERT is expensive and it's not possible to import your own models.

But it looks like biomedical is a very active field so let me check if we have any plans around that, and I'll get back to you later.

For extra info, would you be able to let me know roughly how long a typical invoice is, how many you have, and what you would like to do with them?",1
Is there a way to upload pickled files?,"Unfortunately not, the only Python file format support is Numpy arrays. Note that the arrays also should use 'float32' as data type to upload them on the platform.
Something that works very well is to build a Pandas dataframe from your data, and save it as a CSV file for upload.
If you have high dimensional data that is only numeric (eg. segmentation masks or want to have arrays as target), you could also upload Numpy array files saved with np.save('file.npy', X.astype('float32')).

You can find the exact specs for each file format there: https://peltarion.com/knowledge-center/documentation/datasets-view/import-files-and-data-sources-to-the-platform/requirements-of-imported-files
",1
"I understand that the running time is that costs money. Do I have to wait until the experiment stops itself or I can decide to stop the experiment when I see that the experiment precision and accuracy are good, because what I get a lower value is just an asymptotic/tangential like curves","There's a feature activated by default on the modelling view called Early Stopping. The purpose with that setting is that it will automatically stop the training if the results aren't getting any better. This is what you usually want. If you, for another reason, want to stop training, you can do that by pressing the pause button on the experiment.",1
"I have a data file, in which I define several possible targets of the neural net. When I build a comp graph in Peltarion, I can only select one of these targets. Is there a possibility to somehow join or merge different of these targets into one?
(The use case is that I need to try different combinations of targets. For example, I have targets A, B and C. In one design, I'd like to try targets A and C, in another design, I'd like to try A and B.)
Is it possible to somehow join different values into one target (without generating all possibilities in the data file?)","What kind of data are your targets? If you work with binary or numeric targets, I'd suggest looking at building feature sets. We have documented it here: https://peltarion.com/knowledge-center/documentation/datasets-view/edit-an-imported-dataset-for-use-in-experiments/dataset-features
If your targets are numeric, you can group them together in a feature set and use that feature set as your target when training the model
The different targets will still be separated (ie. different columns in your csv) in the dataset, but then you can combine them into a single target using feature sets on the Dataset view on the Peltarion platform. Is that feasible for your use case?",1
PLEASE I WANT TO CANCEL MY SUBSCRIPTION,"Hi, We're sorry to see you leave :(
Your account will be deleted within 90 days.",1
my model size reaches 12.3 GB while limit is 5GB,"Particularly big models may require a lot of RAM to run, and an easy fix you could do is to reduce the Batch size in the modeling Settings panel. I would recommend that you decrease it just enough until the model is able to run.

This will let your model iterate over the dataset using fewer examples at a time.",1
Is there any way i can generate report after done with the model training,No we dont have that functionality right now.,1
Please delete my account,"We're sorry to see you go. Your account will be deleted within 90 days from today.

You're always welcome back and don't hesitate to let us know if there are things you would like us to improve.",1
"If I may asking a little bit of support for API deployment
do you have any worked example in python? I'm nearly there, but I'm working alone (and not used to deploy =) )","What kind of model are you working with? For most models, the easiest way to use the deployment from Python is with a tool call Sidekick: https://github.com/Peltarion/sidekick#get-predictions-out---use-a-deployed-experiment
It works with all models except similarity search
pip install git+https://github.com/Peltarion/sidekick#egg=sidekick
I put together an example using requests here, for reference: https://colab.research.google.com/drive/1ne0uWsQf5DwkqbTo6TB_CbTgUdMi7rjC?usp=sharing",1
"Block configuration
Some operations in your model could not have been executed.
This is probably linked to some invalid block parameters
or connections.
Reference ID: a8000815","So we dug into this a bit. It seems you have image(s) that are corrupt somehow. Unfortunately we can’t see which one.
Here is a reading tip that could help you do a first check.
https://stackoverflow.com/questions/17757114/imagemagick-to-verify-image-integrity


Another way is to simply iterate a bit and upload half of the dataset first (or you could try creating a subset)Try it out, then for half of what’s left etc. until you reach a point where you at least minimized the data you can’t use",1
"i deployed an model

how can i test after deployment ?",You are able to test your Deployment using the the Peltarion Test App: https://peltarion.com/knowledge-center/documentation/deployment-view#_using_your_deployment . Hope this helps!,1
How can I get familiar with terminology?,"Hi, great question. We have made the a glossary of terms in our Knowledge Base: https://peltarion.com/knowledge-center/documentation/glossary and we are adding new AI concepts to our concepts section as well: https://peltarion.com/knowledge-center/documentation/ai-concepts . Hope these help and please let us know if you find something that you feel should be added!",1
how do i get to my projects? i see NEW project - but how to i get to anything i already started? also the existing tutorial data sets - there is a problem with the popup overlay -,"Hi, sorry to hear that you are having trouble locating your projects. You should be able to find a list of your current projects by clicking on the 'Projects' text in the top left anywhere you are in the platform.",1
How to start ? I'm new to this,"Hi, if you are new to the platform the best place to start is our Tutorial section: https://peltarion.com/knowledge-center/documentation/tutorials . If you like to learn more about the world AI and how to use the platform as well, we have created a course that will be helpful for you: https://faster-ai.teachable.com/ .",1
I have some sales data from Salesforces and I would like to understand which criterias are more likely to make me win a deal,"This sounds like a use case you could do on the platform. It all depends on the quality of your data and your problem type really.

We have some tutorials that could match your use case.


Regression

The Sales forecasting solves a regression problem where the model predicts a number. It also shows you how to integrate your model prediction into Excel or Google sheet.


https://peltarion.com/knowledge-center/documentation/tutorials/sales-forecasting-with-spreadsheet-integration

Binary classification

The Buy or not solves a binary problem where the model predicts if a customer will buy or not. This sounds a bit like your use case, will you win the deal or not.


https://peltarion.com/knowledge-center/documentation/tutorials/buy-or-not-/-predict-from-tabular-data

I suggest that you sign up to the platform (if you haven't already) and try these tutorials out and then use your own data.

Don't hesitate to reach out to us again if you have any further questions.
",1
"Hi! I uploaded dataset. 1.5 Gb size, images. Created index.csv and put everything in .zip archive.
But it takes forever to generate table view in dataset detailed view. Also trying to Save version throw an error:
Generic error (16576835258925044263).
Can you help me with that?","Hi,

Let's see what the problem is. I need a few things from you if it is ok.
First, could you please send me the URL to the page where you get this error?

Is it ok if I take a look at your project.

Second, can you send me the zip vie wetransfer, sprend or similar so I can take a look at it?
...
We found two things.
- Fix the paths images/image-2365 to images/image-2365.jpg, that is add .jpg to each file path
- And correct gender on row with images/image-2365. It crashes if you got an empty cell.",1
"H5 model results different to peltarion deployment

I have downloaded various H5 models which were trained on the platform. I am using these H5 models in Keras. However, when I compare the H5 results to the http post on the platform, the results are different.


","We think the cause of the problem is in the ordering of the channels of the image. Whereas most image files are saved with Red-Green-Blue ordering, our platform works internally with Blue-Green-Red ordering, which is what the H5 downloaded model expects to receive.

Unfortunately this way of processing images is not the most common and we haven't documented it well, so we're sorry for that. But we have current work ongoing to support the SavedModel format for download, and to homogenize usage of Red-Green-Blue. So if you plan to download your models for local usage, things should get easier in the future.

I hope this will solve the issue, but let me know if that's not the case or if there is anything else I can help you with. ",1
So what does the API accept? I believe it doesn't accept Base64 encoded images?,"So it does accept b64-encoded images as well. I'm not sure if it accepts it like this when sending form-data, though. Seems some information is lost. But I know the Peltarion platform accepts b64 if you send it as JSON. There's an example of that (although in Python) in our Deployment API page: https://peltarion.com/knowledge-center/documentation/peltarion-apis/deployment-api",1
"Dear Peltarion-Team, I'm interested in stock related Twitter sentiment analysis. Do you provide Data on this topic as well?","We do not provide a dataset with tweets tagged with sentiment.
However, we have a dataset with headlines that consists of about 28K news headlines and their tags, indicating whether the headline was sarcastic or not.

But there should be a dataset out there with twitter sentiments. If there is you would probably be able to upload that dataset to the platform and use it.

This is an example but I can't download it since I'm not part of the competition.
https://www.kaggle.com/c/twitter-sentiment-analysis/

When you use datasets that's not yours, remember to read the terms and conditions for that dataset before you use it:)

",1
Is this platform provide any third party deployment services?,"Yes, once your model is deployed, you can connect it to other applications through an HTTP API.
You can read more here: https://peltarion.com/knowledge-center/documentation/peltarion-connectors",1
Is it possible to run a list of items through the API?,"Hi!
You send multiple items in the payload to the api. You can read more here:  https://peltarion.com/knowledge-center/documentation/peltarion-connectors
It is not supported in all connectors thought so check the documentation.",1
i keep getting a 500 error code when making calls to my API? is there documentation on what the issue is?,Could you tell me a little bit more about what you are trying to do? This error could derive from many different things. You can read more here: https://peltarion.com/knowledge-center/documentation/peltarion-connectors,1
"
am trying to create a new sample with peltarion

in my csv file I have 4 column, first 3 are text fields, and last one is bool

am trying to make a logic to predict my last bool field ie true or false from the input ie other 3 fields

but the status am expecting is true/false. Wonder why am getting numbers there.","The value you are getting as status is the probability that the status is the positive class, which for you would be the status True.
A common way to proceed is to consider that if the probability is above 0.5 then it's positive, and below 0.5 it's negative. So 0.2513224 would mean False.

If that's relevant you can read more about choosing a value of threshold on the ROC curve page.",1
"Hello, i would like to know if you have a dataset for performing a creation of a Artificial Intelligence ?
Thanks for the Answer","Hello, we have lots of datasets on the platform for building different kinds of AI models. You can find then on the ""Datasets"" view on the platform.",1
"Hi, I'm developing apps on bubble.io and I'm currently testing IMDb reviews, whether it's positive or negative based on the given text. For some reason, I'm receiving this error","Hello, this seems to be a mismatch between the data format that your model, trained on the Peltarion platform, expects and what is sent from Bubble. Could you have a look at your Workflow view on Bubble and the Deployment page on Peltarion and see if the data sent matches what the model expects?

I've attached two screenshots where you can see what I mean. In my example, the expected input and the data sent differs so I will get the error message you shared above. You can also post screenshots of your Deployment view and the Workflow view in Bubble and I'll have a look.",1
"
Hi, we run a horse racing data website. I've looked at Peltarion before, but it's I've not been sure what we're doing really. Would we be able to predict a horses Odds from our data using it?","I'm guessing that you have a bunch of measurements about the horse, and possibly some previous race results, and you want to calculate a probability from these values.
Strictly speaking that sounds possible, this would be similar to our predict real estate prices tutorial, where you predict a value (the expected price) from a bunch of metrics about a neighborhood (and an images that you probably wouldn't use).

Then there are a few open questions, like

Can you get the data on the platform? The best way depends on what/how much info you have about a horse, but generally for tabular data we support CSV files which you can create easily, for instance from a spreadsheet.
Do you need to preprocess the data, and what kind of model would work best? This depends entirely on the type of data, and on how complex the problem actually. For instance, I assume you would need to consider the relation with the specific horses from a given race to get accurate odds, we would have to think how to design such a model. 
I would recommend that you start by doing the predict real estate prices tutorial to get a feeling of the platform, and see how working on it and using deployments work in practice.

Then you could try to build a simple model, maybe using only some of your most important data, to see if you can get somewhere. If you describe to me a little the data you have I can help you figure out how to import it.

Let me know what you want to do.",1
How should I prepare text classification data ?,,1
" I delpoyed the experiment from epoch1 then it worked. One more question I wan to ask is, When I was testing, I texted sentences in English then the result is history, after that I translated the sentences into Swedish and the result changed to biography. Is it because the training dataset of Swedish is thin so the accurancy is low? Actually I want to have a look at the confusion matrix of each language but there is only one matrix for multilingual. It may be related to the structure of the model so I want to ask is there a pre-process that translate other languages to English that embedded in the model?","It is possible that the model accuracy can have some variance for different languages, although I would first check what the probabilities calculated for each genre were to rule out simple noise on a ""difficult"" example.

What you could do to get confusion matrices per languages is to add a feature column to your dataset that contains the language of your examples. Then, in the Datasets view, you could create subsets by filtering on the language, so that you have a subset for all the English examples, one subset for all the Swedish examples, etc.

After you run the model and go to the Evaluation view, you will be able to select which subset you want to use in the predictions inspection.

I hope that helps, let me know if something is still unclear or if you have more questions.
",1
"Hi! Sorry to disturb you, but I was wondering if it is possible to build a Jarvis-like model. And if so, would it be reasonable for a beginner?","Building your own Jarvis can be very difficult, but you could have a look at our tutorial list to get ideas about smaller tasks that can be solved on our platform.
https://peltarion.com/knowledge-center/documentation/tutorials",1
I would like to create an enhanced defense communication intelligence Any suggestions?,"Welcome to the platform.

I would recommend that you check out our tutorial list to see if any of the applications can be used in your communication project.

Let me know if you have any questions.
https://peltarion.com/knowledge-center/documentation/tutorials",1
"Peltarion is definitely a great deep learning tool. While, I may I know if it works with time series prediction? or in other words, is Peltarion has RNN or LSTM models?","Time-series isn’t something we have native support for on the platform, since all the models expect fixed-size input.
A simple workaround is to reorder your data to have the last N values in the same row of data. When you have a large number V of variables, this tends to create many features so after a point I would recommend uploading a NumPy array rather than a csv file. If you have T time points, the shape of this array would be (T, NxV).The target you want to predict should be in an extra column of this array.Then you could have a first try with the Dense or Convolution blocks.",1
how do i delete my account?,"Hi, sorry to ser your leave. We will delete your account within 90 days.
Happy weekend!",1
"I tried to deploy a model to see how it would work and used the API. I've made some tests with Postman but I get this response and I don't really understand why : 503 Service Unavailable
No server is available to handle this request.","Simple check, is the deployment in the Enabled state?
Otherwise, could you share the URL of your project so that I could take a look at it?",1
"I'm trying to model an encoder-decoder 1D model. I see that in the 2D models, you have a 2D deconv layer. I must be missing something, but I can't find a 1D deconv layer. Is there a 1D deconv layer possible?","Sorry for the late reply. I've tried to figure out why but I havenät got a good answer. So the only answer I can give you right now is that no one has requested/needed it so far.

I'll continue to ask our data scientists to see why they haven't seen a use for it and what you could do instead.",1
sir i am begineer and also interested to learn AI ..plz help me about fundamental process of AI,"Hi, welcome to the platform.

If you're a beginner and want to get into AI, feel free to check this course: https://faster-ai.teachable.com

It contains an introduction to AI and some hands-on exercises to build your first models.

If you would like to learn more about what the platform can do for you, check out this overview page. And if you're ready to jump right in, learn by practicing with one of our tutorials.
https://peltarion.com/knowledge-center/documentation/get-started-with-the-platform
https://peltarion.com/knowledge-center/documentation/tutorials

Best,
",1
Is there a way to feed training data into the platform in real time?,"Hi,
No, it's not possible to feed training data into the platform at the moment.",1
"Hi, is there an option to disable or enable which layers that should be frozen or not, to be set before training? for example, I want use snippet model like mobileNet and didn't want to change its original weight, only the other additional dense that could be tuned.","Hi,
Yes, you can do that. In each block that is trainable, there is a check box “Trainable”. If you want to keep the weight this box should not be checked.

Snippets

When you select the MobileNet snippet you get a choice to make the weights trainable. Don't! Keep the weights. Then all ""Trainable"" boxes in the snippet will be unchecked.

",1
"Just registered (for free) to try your tool but having trouble uploading any type of sources, in particular images like GIF or PNGs.. Using MacBook )

Any advice on that?","Hi,
All the details you need to know you can find here:

https://peltarion.com/knowledge-center/documentation/datasets-view/import-files-and-data-sources-to-the-platform/requirements-of-imported-files",1
"hi, is there any project example or datasets to experience multiple object detection and its count within one image?","Hi,
I'm sorry we haven't got that feature at the moment.
We've got many examples when it comes to image & text classification. similarity & regression + examples with tabular data.",1
"for image classification, is it possible to enrich the dataset with augmentation? like random flip, rotation, zoom, that lead to larger quantity of the dataset as well.","Hi,
Yes that is possible.
You can read more about it here

https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/image-augmentation",1
How is the IMDB Data stored in your platform?,"I've checked again how the IMDB data is processed, so I'll try to clarify some points that you've asked about.

The thing with the scores is that the IMDB reviews are rated numerically, but the Stanford team that created the dataset wanted to only solve a binary classification problem with positive/negative classes.
It was also them who decided to exclude reviews rated between 4 and 7 in order to avoid working with ambiguous text.
https://ai.stanford.edu/~amaas/data/sentiment/

If you would like to work with more than 2 categories, you can absolutely have more in your own dataset. You could also work with the numerical scores if you prefer.

I'm attaching an example of CSV file with a 3-category feature, and a score feature, as an example.

The delicate part when working with CSV and text is that the text feature might include commas and quote marks, which are normally used to delimit the CSV fields.
You can read more about that on in the CSV file specifications.
https://peltarion.com/knowledge-center/documentation/datasets-view/import-files-and-data-sources-to-the-platform/requirements-of-imported-files",1
" looking for a good reconfigurable ai. I'm not sure what you offer but I really need help if it's close to a thing I am looking for.
Countering cyber attacks. Studying sensor information. Maybe acquiring sensors. Also doing some design to reduce environmental pollution and degradation.

","My apologies for the slow response here. We're not so familiar with cyber-security, but if I present briefly what our models are good for I would say that we can handle:

Image input
Text input
Numeric and categorical inputs
Any mix of the input types above
And as a model output you could get:

Numerical values
Classification (including probabilities for each category)
To train a model, you'd have to provide a number of examples that contain both the input and the output. Do you think any of your problems could benefit from these kinds of models?
If so just let me know more about some of your applications and I could guide you more precisely.",1
Yeah. I'm looking for the source of toxic radiation in the 90Ghz to 120Ghz spectrum and then need decision making about how to handle a humanitarian crisis that the attack causes by dealing with the source of the attack. I guess I would want it to take in sensor information and then do remediation work to reduce the scope of the problem the attack has caused at the source of it or by other means.,"Assuming that there is only a discrete set of decisions possible (e.g. Decision A, Decision B, Decision C), what you could do is train a model with the sensor inputs from past events and the decisions that were taken.

If a model can predict those accurately, when a new event occurs you would be able to know very quickly which decision (A, B, or C) is the most likely to be taken from similar input according to the past events.

I would recommend that you break down your problem into small parts so that you could solve each one in the best way, and focus on what really matters.

Don't hesitate to have a look at the tutorials to see what kind of methods are available with us, and if they could help to solve some pieces of your general problem.
https://peltarion.com/knowledge-center/documentation/tutorials",1
"Hi, when I tried uploading a csv file I received the following error message.
File exceeded column limit (5000 columns)
However my column/fields total is about 500 fields.","There was an interesting issue related to the format of the file that made the platform unable to read it. We'll discuss internally how to catch this and accept a file on this format.

I haven't seen this issue before - may I ask what tool you used to compile and save/download this data?

.....
A: so the last export was a csv export from excel 2011. for mac ",1
Can I generate copywriting scripts using this?,"Hello, our services are well-suited for text analysis and sentiment analysis, but we don't have generation capabilities on the platform",1
"Hello. How can I predict trend, direction in a multivariate streaming time-series data? My goal is to train AI for currency market.","Time-series isn't something we have native support for on the platform, since all the models expect fixed-size input.
A simple workaround is to reorder your data to have the last N values in the same row of data. When you have a large number V of variables, this tends to create many features so after a point I would recommend uploading a NumPy array rather than a csv file. If you have T time points, the shape of this array would be (T, NxV).

The target you want to predict should be in an extra column of this array.

Then you could have a first try with the Dense or Convolution blocks.

I hope this gives you useful hints, but if something isn't clear or if you have more questions just let me know.
",1
"But a real question: I have an auto-encoder experiment that was trained with 64x64 images, I am forced to send to deployed experiment a bigger image as 64x64 chunks. Can I skip this chunking to 64x64 chunks somehow? I would like to use 64x64 training data and after deployment use 640x640 images in Http calls as input image??","Good that you solved the first problem with the image augmentation.

For the image size, I would say it depends on the where is the content of the image.
You can submit an image that is bigger than 64x64 to the deployed model, but what will happen is that the whole image will be either resized  or cropped around the center, according to the Image transformation setting that was selected in the datasets view. 

If your big image has several objects in it that should be processed individually, then you would have to cut the image in smaller chunks yourself first. 

As a side note, since you are using autoencoders, we have recently released the Output block that you can use to get data from anywhere in your network at deployment time. When you have an Output block, you can deactivate Use for predictions in the target block. This lets you train the autoencoder as usual, but the deployment will avoid returning the whole 64x64 image in the prediction.
",1
"Hi, I really liked the Peltarion APIs. I wanted to know if there is an API for training as well, so that I can push the data using Data API, automatically trigger the training and then the deployment, all using APIs","As you noted there are APIs for Data upload and Deployment query, but the steps in between have to be done from the website. There is no ongoing plan to add APIs for model building and training, but I will relay your question to the product development team. 

It is rather clear that being able to automate more tasks is good, but do you have a specific case in mind where you would benefit from a model building/training API?",1
When I develop an ai with the help of peltarion and deploy it.........who will own the ai (or the code) peltarion or me ?,"Hi Shreyas,

Intellectual property on the platform is covered on this page https://peltarion.com/terms, in particular please see sections 9 and 16 which might be of interest to you.
Please also note that some of the datasets and models (especially models with pretrained weights) that are accessible on the platform may have their own licensing terms which you have to follow. You can find more information on these pages: https://peltarion.com/knowledge-center/documentation/terms/pretrained-licenses and https://peltarion.com/knowledge-center/documentation/terms/dataset-licenses
Are there some special conditions that you are looking for? I could put you in touch with our sales team if you would like to discuss use terms.",1
"Hi, I tried to create an image classification model to call from Bubble.io. It seems that everything for creating the model and deploying it went okay. However when I tested the deployment it didnt work. It give me a 500 error. Can you help me out with this?


Also need to understand whats the minimum number of images needed to train the model?","You model is set up to work with 4-channel images, i.e. 3 color channels plus transparency. Unfortunately, this means that the model always expects to receive transparent images so I suspect that this is the cause of the problem. 

I recommend that you make a new version of your dataset where you set the Color mode of the Image feature to Color. The Shape of the Image feature should change to 229×366×3, which is the most widespread color mode for images.
Train a new model from this dataset and check if it works as intended.

Regarding the amount of images that you need, it depends on the task that you are trying to solve. Generally, the more complex tasks require more images. It looks like your dataset has only 2 categories of images which are rather simple to differenciate from the amount of green they contain, so I would think that what you have is enough.",1
"We are looking to build a model that can match job postings with candidates and vice versa. Would this be something that can be modeled here? If so, can you give me some guidance on what I should be looking at?
","Hi,
Thank you for reaching out to us. The answer is ""Well, it depends"" :)
Basically it depends on the data that you have and how it is labeled.

If you want, someone from our data scientist team can contact you to see if your use case would work. Could that be a plan?",1
"Hey! Can I use a sequence length longer than 512 for BERT? I have about 4000 observations and I would like to use a sequence length of 1500, would it be possible and would I run into memory problems?","Hi 
No, unfortunately it's not possible to go over 512 sequence length with BERT. The main reason is that the 512 input size is what the authors designed and pre-trained BERT for.

What happens when you pick a smaller sequence length is that some part of the model is simply ignored, but to use a larger size than 512 you would need to re-build the model with more nodes and train it from scratch.
Like you said, there is also a practical limit since you will hit memory limits on most GPUs.We have the same recommendations as the Google team, which is to run a batch size of 6 when using a sequence length of 512. If the model allowed it, you might have been able to fit a sequence length of 1500 on a GPU, but then you would be training by using just 1 or 2 examples at a time.
But you should also consider that the compute time goes with the square of the sequence length, so running with 1500 will take 9x longer than running with 500 sequence length. This is true both during training and during inference. 
So to run your case, I would recommend to either

Split your input text into shorter sequences, possibly with some overlap between sequences if that makes sense.
Use a lighter model that could handle longer sequences. You could start with the FastText embeddings and then add a few 1D-convolution layers.
I hope this helps. If you want to let me know a bit more about your problem, I'll be happy to think if there are better approaches that you could try. 

Best,
Romain",1
Please do not register me.,"Hi John,
Do you want us to delete your user account or are you referring to something else? We will of course comply with your wish to unregister, but since you are a user, I need to get your confirmation on that is in fact what you want to do.",1
Accuracy,Accuracy is a performance metric that allows you to evaluate how good your model is. It's used in classification models and is the ratio of:or equivalently:Note that accuracy is highly sensitive to class imbalances in your data.,1
What is Accuracy,Accuracy is a performance metric that allows you to evaluate how good your model is. It's used in classification models and is the ratio of:or equivalently:Note that accuracy is highly sensitive to class imbalances in your data.,1
Can you help me with Accuracy,Accuracy is a performance metric that allows you to evaluate how good your model is. It's used in classification models and is the ratio of:or equivalently:Note that accuracy is highly sensitive to class imbalances in your data.,1
What does Accuracy mean?,Accuracy is a performance metric that allows you to evaluate how good your model is. It's used in classification models and is the ratio of:or equivalently:Note that accuracy is highly sensitive to class imbalances in your data.,1
How do I use Accuracy?,Accuracy is a performance metric that allows you to evaluate how good your model is. It's used in classification models and is the ratio of:or equivalently:Note that accuracy is highly sensitive to class imbalances in your data.,1
Activation function,"An activation function is a non-linear function which takes the weighted sum of all the inputs to a node and maps them to values in the range of 0 to 1 (e.g., Sigmoid), 0 to ∞ (e.g. ReLu) or -1 to 1 (e.g., TanH).Its non-linear nature is what allows neural networks to model any kind of function (it makes them a universal function approximator).Use an activation function in every node of a network. On the Peltarion Platform, all nodes are automatically assigned an activation function, which can be changed as one of the configurable parameters of the blocks that have nodes. You can read about Activation here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/activation",1
What is Activation function,"An activation function is a non-linear function which takes the weighted sum of all the inputs to a node and maps them to values in the range of 0 to 1 (e.g., Sigmoid), 0 to ∞ (e.g. ReLu) or -1 to 1 (e.g., TanH).Its non-linear nature is what allows neural networks to model any kind of function (it makes them a universal function approximator).Use an activation function in every node of a network. On the Peltarion Platform, all nodes are automatically assigned an activation function, which can be changed as one of the configurable parameters of the blocks that have nodes. You can read about Activation here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/activation",1
Can you help me with Activation function,"An activation function is a non-linear function which takes the weighted sum of all the inputs to a node and maps them to values in the range of 0 to 1 (e.g., Sigmoid), 0 to ∞ (e.g. ReLu) or -1 to 1 (e.g., TanH).Its non-linear nature is what allows neural networks to model any kind of function (it makes them a universal function approximator).Use an activation function in every node of a network. On the Peltarion Platform, all nodes are automatically assigned an activation function, which can be changed as one of the configurable parameters of the blocks that have nodes. You can read about Activation here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/activation",1
What does Activation function mean?,"An activation function is a non-linear function which takes the weighted sum of all the inputs to a node and maps them to values in the range of 0 to 1 (e.g., Sigmoid), 0 to ∞ (e.g. ReLu) or -1 to 1 (e.g., TanH).Its non-linear nature is what allows neural networks to model any kind of function (it makes them a universal function approximator).Use an activation function in every node of a network. On the Peltarion Platform, all nodes are automatically assigned an activation function, which can be changed as one of the configurable parameters of the blocks that have nodes. You can read about Activation here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/activation",1
How do I use Activation function?,"An activation function is a non-linear function which takes the weighted sum of all the inputs to a node and maps them to values in the range of 0 to 1 (e.g., Sigmoid), 0 to ∞ (e.g. ReLu) or -1 to 1 (e.g., TanH).Its non-linear nature is what allows neural networks to model any kind of function (it makes them a universal function approximator).Use an activation function in every node of a network. On the Peltarion Platform, all nodes are automatically assigned an activation function, which can be changed as one of the configurable parameters of the blocks that have nodes. You can read about Activation here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/activation",1
Adadelta optimizer,"Adadelta is a more robust extension of Adagrad that seeks to reduce its aggressive, monotonically decreasing learning rate based on a fixed moving window of gradient updates, instead of accumulating all past gradients.
It is recommended to leave the parameters of this optimizer at their default values. You can read about Adadelta here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/the-optimizers/adadelta",1
What is Adadelta optimizer,"Adadelta is a more robust extension of Adagrad that seeks to reduce its aggressive, monotonically decreasing learning rate based on a fixed moving window of gradient updates, instead of accumulating all past gradients.
It is recommended to leave the parameters of this optimizer at their default values. You can read about Adadelta here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/the-optimizers/adadelta",1
Can you help me with Adadelta optimizer,"Adadelta is a more robust extension of Adagrad that seeks to reduce its aggressive, monotonically decreasing learning rate based on a fixed moving window of gradient updates, instead of accumulating all past gradients.
It is recommended to leave the parameters of this optimizer at their default values. You can read about Adadelta here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/the-optimizers/adadelta",1
What does Adadelta optimizer mean?,"Adadelta is a more robust extension of Adagrad that seeks to reduce its aggressive, monotonically decreasing learning rate based on a fixed moving window of gradient updates, instead of accumulating all past gradients.
It is recommended to leave the parameters of this optimizer at their default values. You can read about Adadelta here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/the-optimizers/adadelta",1
How do I use Adadelta optimizer?,"Adadelta is a more robust extension of Adagrad that seeks to reduce its aggressive, monotonically decreasing learning rate based on a fixed moving window of gradient updates, instead of accumulating all past gradients.
It is recommended to leave the parameters of this optimizer at their default values. You can read about Adadelta here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/the-optimizers/adadelta",1
Adagrad optimizer,"Adagrad is an optimizer that adapts the learning rate to the parameters. Adagrad performs:Smaller updates (i.e., low learning rates) for parameters associated with frequently occurring featuresLarger updates (i.e., high learning rates) for parameters associated with infrequent features. You can read about Adagrad here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/the-optimizers/adagrad",1
What is Adagrad optimizer,"Adagrad is an optimizer that adapts the learning rate to the parameters. Adagrad performs:Smaller updates (i.e., low learning rates) for parameters associated with frequently occurring featuresLarger updates (i.e., high learning rates) for parameters associated with infrequent features. You can read about Adagrad here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/the-optimizers/adagrad",1
Can you help me with Adagrad optimizer,"Adagrad is an optimizer that adapts the learning rate to the parameters. Adagrad performs:Smaller updates (i.e., low learning rates) for parameters associated with frequently occurring featuresLarger updates (i.e., high learning rates) for parameters associated with infrequent features. You can read about Adagrad here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/the-optimizers/adagrad",1
What does Adagrad optimizer mean?,"Adagrad is an optimizer that adapts the learning rate to the parameters. Adagrad performs:Smaller updates (i.e., low learning rates) for parameters associated with frequently occurring featuresLarger updates (i.e., high learning rates) for parameters associated with infrequent features. You can read about Adagrad here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/the-optimizers/adagrad",1
How do I use Adagrad optimizer?,"Adagrad is an optimizer that adapts the learning rate to the parameters. Adagrad performs:Smaller updates (i.e., low learning rates) for parameters associated with frequently occurring featuresLarger updates (i.e., high learning rates) for parameters associated with infrequent features. You can read about Adagrad here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/the-optimizers/adagrad",1
Adam optimizer,"Adam is the optimizer of choice for training deep learning models.Adam can be viewed as a combination of RMSprop and momentum.
RMSprop contributes the exponentially decaying average of past squared gradients, while momentum accounts for the exponentially decaying average of past gradients.
Adam adds bias-correction and momentum to RMSprop.
Momentum can be seen as a ball rolling down a slope, Adam behaves like a heavy ball with friction, which thus prefers flat minima in the loss function landscape. The authors of the original paper empirically show that Adam works well in practice and compares favorably to other adaptive learning-method algorithms. You can read about Adam here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/the-optimizers/adam",1
What is Adam optimizer,"Adam is the optimizer of choice for training deep learning models.Adam can be viewed as a combination of RMSprop and momentum.
RMSprop contributes the exponentially decaying average of past squared gradients, while momentum accounts for the exponentially decaying average of past gradients.
Adam adds bias-correction and momentum to RMSprop.
Momentum can be seen as a ball rolling down a slope, Adam behaves like a heavy ball with friction, which thus prefers flat minima in the loss function landscape. The authors of the original paper empirically show that Adam works well in practice and compares favorably to other adaptive learning-method algorithms. You can read about Adam here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/the-optimizers/adam",1
Can you help me with Adam optimizer,"Adam is the optimizer of choice for training deep learning models.Adam can be viewed as a combination of RMSprop and momentum.
RMSprop contributes the exponentially decaying average of past squared gradients, while momentum accounts for the exponentially decaying average of past gradients.
Adam adds bias-correction and momentum to RMSprop.
Momentum can be seen as a ball rolling down a slope, Adam behaves like a heavy ball with friction, which thus prefers flat minima in the loss function landscape. The authors of the original paper empirically show that Adam works well in practice and compares favorably to other adaptive learning-method algorithms. You can read about Adam here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/the-optimizers/adam",1
What does Adam optimizer mean?,"Adam is the optimizer of choice for training deep learning models.Adam can be viewed as a combination of RMSprop and momentum.
RMSprop contributes the exponentially decaying average of past squared gradients, while momentum accounts for the exponentially decaying average of past gradients.
Adam adds bias-correction and momentum to RMSprop.
Momentum can be seen as a ball rolling down a slope, Adam behaves like a heavy ball with friction, which thus prefers flat minima in the loss function landscape. The authors of the original paper empirically show that Adam works well in practice and compares favorably to other adaptive learning-method algorithms. You can read about Adam here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/the-optimizers/adam",1
How do I use Adam optimizer?,"Adam is the optimizer of choice for training deep learning models.Adam can be viewed as a combination of RMSprop and momentum.
RMSprop contributes the exponentially decaying average of past squared gradients, while momentum accounts for the exponentially decaying average of past gradients.
Adam adds bias-correction and momentum to RMSprop.
Momentum can be seen as a ball rolling down a slope, Adam behaves like a heavy ball with friction, which thus prefers flat minima in the loss function landscape. The authors of the original paper empirically show that Adam works well in practice and compares favorably to other adaptive learning-method algorithms. You can read about Adam here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/the-optimizers/adam",1
Adamax optimizer,Adamax is an extension of Adam based on the infinity norm. You can read about Adamax here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/the-optimizers/adamax,1
What is Adamax optimizer,Adamax is an extension of Adam based on the infinity norm. You can read about Adamax here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/the-optimizers/adamax,1
Can you help me with Adamax optimizer,Adamax is an extension of Adam based on the infinity norm. You can read about Adamax here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/the-optimizers/adamax,1
What does Adamax optimizer mean?,Adamax is an extension of Adam based on the infinity norm. You can read about Adamax here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/the-optimizers/adamax,1
How do I use Adamax optimizer?,Adamax is an extension of Adam based on the infinity norm. You can read about Adamax here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/the-optimizers/adamax,1
Add,"The Add block can take any number of inputs, all with the same shape, and returns a single tensor of the same shape, containing the element-wise sum over all inputs.Useful when building residual networks, where the layer's input is added with an Add node to its output. You can read about Add and remove members of the organization here: https://peltarion.com/knowledge-center/documentation/organization-settings-view/members-view#_add_and_remove_members_of_the_organization",1
What is Add,"The Add block can take any number of inputs, all with the same shape, and returns a single tensor of the same shape, containing the element-wise sum over all inputs.Useful when building residual networks, where the layer's input is added with an Add node to its output. You can read about Add and remove members of the organization here: https://peltarion.com/knowledge-center/documentation/organization-settings-view/members-view#_add_and_remove_members_of_the_organization",1
Can you help me with Add,"The Add block can take any number of inputs, all with the same shape, and returns a single tensor of the same shape, containing the element-wise sum over all inputs.Useful when building residual networks, where the layer's input is added with an Add node to its output. You can read about Add and remove members of the organization here: https://peltarion.com/knowledge-center/documentation/organization-settings-view/members-view#_add_and_remove_members_of_the_organization",1
What does Add mean?,"The Add block can take any number of inputs, all with the same shape, and returns a single tensor of the same shape, containing the element-wise sum over all inputs.Useful when building residual networks, where the layer's input is added with an Add node to its output. You can read about Add and remove members of the organization here: https://peltarion.com/knowledge-center/documentation/organization-settings-view/members-view#_add_and_remove_members_of_the_organization",1
How do I use Add?,"The Add block can take any number of inputs, all with the same shape, and returns a single tensor of the same shape, containing the element-wise sum over all inputs.Useful when building residual networks, where the layer's input is added with an Add node to its output. You can read about Add and remove members of the organization here: https://peltarion.com/knowledge-center/documentation/organization-settings-view/members-view#_add_and_remove_members_of_the_organization",1
Amsgrad optimizer,A variant of Adam based on the algorithm from the paper On the Convergence of Adam and Beyond.,1
What is Amsgrad optimizer,A variant of Adam based on the algorithm from the paper On the Convergence of Adam and Beyond.,1
Can you help me with Amsgrad optimizer,A variant of Adam based on the algorithm from the paper On the Convergence of Adam and Beyond.,1
What does Amsgrad optimizer mean?,A variant of Adam based on the algorithm from the paper On the Convergence of Adam and Beyond.,1
How do I use Amsgrad optimizer?,A variant of Adam based on the algorithm from the paper On the Convergence of Adam and Beyond.,1
Area under the ROC Curve (AUC),The AUC is the area under the ROC curve and is a performance measure that tells you how well your model can classify different classes. The higher the AUC the better the model. You can read about ROC Curve  here: https://peltarion.com/knowledge-center/documentation/evaluation-view/predictions-inspection/roc-curve,1
What is Area under the ROC Curve (AUC),The AUC is the area under the ROC curve and is a performance measure that tells you how well your model can classify different classes. The higher the AUC the better the model. You can read about ROC Curve  here: https://peltarion.com/knowledge-center/documentation/evaluation-view/predictions-inspection/roc-curve,1
Can you help me with Area under the ROC Curve (AUC),The AUC is the area under the ROC curve and is a performance measure that tells you how well your model can classify different classes. The higher the AUC the better the model. You can read about ROC Curve  here: https://peltarion.com/knowledge-center/documentation/evaluation-view/predictions-inspection/roc-curve,1
What does Area under the ROC Curve (AUC) mean?,The AUC is the area under the ROC curve and is a performance measure that tells you how well your model can classify different classes. The higher the AUC the better the model. You can read about ROC Curve  here: https://peltarion.com/knowledge-center/documentation/evaluation-view/predictions-inspection/roc-curve,1
How do I use Area under the ROC Curve (AUC)?,The AUC is the area under the ROC curve and is a performance measure that tells you how well your model can classify different classes. The higher the AUC the better the model. You can read about ROC Curve  here: https://peltarion.com/knowledge-center/documentation/evaluation-view/predictions-inspection/roc-curve,1
Autoencoder,"An autoencoder is a special kind of neural network that aims to copy its input to its output. What makes this a non trivial task is that rather than just directly copying the input to the output, the network first tries to encode the input into a small number of parameters (the latent-space representation) and then tries to reconstruct the original data at the output from it.The latent-space can be thought of an efficient re-coding of the input data. This re-coding of the input data can itself be interpreted in different ways, each one of which gives us insights into the applications of autoencoders:Data compressionDimensionality reduction / feature extraction - the smaller encoding can be thought of the autoencoder having performed dimensionality reduction (using non linear transformations!) on the original data.Data denoising - the latent-space's learned ability to distinguish the noise and to discard it, can be used to remove noise from the input data (e.g. removing noise from an image)Generative modeling - by forcing the latent-space representation to roughly stick to a unit gaussian distribution, it is possible to sample a new latent vector from the unit gaussian and pass it to the decoder. This process effectively 'generates' a completely new data output, one that the network never had seen before.",1
What is Autoencoder,"An autoencoder is a special kind of neural network that aims to copy its input to its output. What makes this a non trivial task is that rather than just directly copying the input to the output, the network first tries to encode the input into a small number of parameters (the latent-space representation) and then tries to reconstruct the original data at the output from it.The latent-space can be thought of an efficient re-coding of the input data. This re-coding of the input data can itself be interpreted in different ways, each one of which gives us insights into the applications of autoencoders:Data compressionDimensionality reduction / feature extraction - the smaller encoding can be thought of the autoencoder having performed dimensionality reduction (using non linear transformations!) on the original data.Data denoising - the latent-space's learned ability to distinguish the noise and to discard it, can be used to remove noise from the input data (e.g. removing noise from an image)Generative modeling - by forcing the latent-space representation to roughly stick to a unit gaussian distribution, it is possible to sample a new latent vector from the unit gaussian and pass it to the decoder. This process effectively 'generates' a completely new data output, one that the network never had seen before.",1
Can you help me with Autoencoder,"An autoencoder is a special kind of neural network that aims to copy its input to its output. What makes this a non trivial task is that rather than just directly copying the input to the output, the network first tries to encode the input into a small number of parameters (the latent-space representation) and then tries to reconstruct the original data at the output from it.The latent-space can be thought of an efficient re-coding of the input data. This re-coding of the input data can itself be interpreted in different ways, each one of which gives us insights into the applications of autoencoders:Data compressionDimensionality reduction / feature extraction - the smaller encoding can be thought of the autoencoder having performed dimensionality reduction (using non linear transformations!) on the original data.Data denoising - the latent-space's learned ability to distinguish the noise and to discard it, can be used to remove noise from the input data (e.g. removing noise from an image)Generative modeling - by forcing the latent-space representation to roughly stick to a unit gaussian distribution, it is possible to sample a new latent vector from the unit gaussian and pass it to the decoder. This process effectively 'generates' a completely new data output, one that the network never had seen before.",1
What does Autoencoder mean?,"An autoencoder is a special kind of neural network that aims to copy its input to its output. What makes this a non trivial task is that rather than just directly copying the input to the output, the network first tries to encode the input into a small number of parameters (the latent-space representation) and then tries to reconstruct the original data at the output from it.The latent-space can be thought of an efficient re-coding of the input data. This re-coding of the input data can itself be interpreted in different ways, each one of which gives us insights into the applications of autoencoders:Data compressionDimensionality reduction / feature extraction - the smaller encoding can be thought of the autoencoder having performed dimensionality reduction (using non linear transformations!) on the original data.Data denoising - the latent-space's learned ability to distinguish the noise and to discard it, can be used to remove noise from the input data (e.g. removing noise from an image)Generative modeling - by forcing the latent-space representation to roughly stick to a unit gaussian distribution, it is possible to sample a new latent vector from the unit gaussian and pass it to the decoder. This process effectively 'generates' a completely new data output, one that the network never had seen before.",1
How do I use Autoencoder?,"An autoencoder is a special kind of neural network that aims to copy its input to its output. What makes this a non trivial task is that rather than just directly copying the input to the output, the network first tries to encode the input into a small number of parameters (the latent-space representation) and then tries to reconstruct the original data at the output from it.The latent-space can be thought of an efficient re-coding of the input data. This re-coding of the input data can itself be interpreted in different ways, each one of which gives us insights into the applications of autoencoders:Data compressionDimensionality reduction / feature extraction - the smaller encoding can be thought of the autoencoder having performed dimensionality reduction (using non linear transformations!) on the original data.Data denoising - the latent-space's learned ability to distinguish the noise and to discard it, can be used to remove noise from the input data (e.g. removing noise from an image)Generative modeling - by forcing the latent-space representation to roughly stick to a unit gaussian distribution, it is possible to sample a new latent vector from the unit gaussian and pass it to the decoder. This process effectively 'generates' a completely new data output, one that the network never had seen before.",1
Backpropagation,"Backpropagation is shorthand for “the backward propagation of errors” and is the main algorithm used to calculate the partial derivative of the error for each parameter in a neural network.In other words, the algorithm computes the gradient over all parameters which is used by gradient descent to determine how to update the weights of the network, in order to achieve a lower loss. Backpropagation can be thought of as an implementation of the chain rule of derivatives for computation graphs.",1
What is Backpropagation,"Backpropagation is shorthand for “the backward propagation of errors” and is the main algorithm used to calculate the partial derivative of the error for each parameter in a neural network.In other words, the algorithm computes the gradient over all parameters which is used by gradient descent to determine how to update the weights of the network, in order to achieve a lower loss. Backpropagation can be thought of as an implementation of the chain rule of derivatives for computation graphs.",1
Can you help me with Backpropagation,"Backpropagation is shorthand for “the backward propagation of errors” and is the main algorithm used to calculate the partial derivative of the error for each parameter in a neural network.In other words, the algorithm computes the gradient over all parameters which is used by gradient descent to determine how to update the weights of the network, in order to achieve a lower loss. Backpropagation can be thought of as an implementation of the chain rule of derivatives for computation graphs.",1
What does Backpropagation mean?,"Backpropagation is shorthand for “the backward propagation of errors” and is the main algorithm used to calculate the partial derivative of the error for each parameter in a neural network.In other words, the algorithm computes the gradient over all parameters which is used by gradient descent to determine how to update the weights of the network, in order to achieve a lower loss. Backpropagation can be thought of as an implementation of the chain rule of derivatives for computation graphs.",1
How do I use Backpropagation?,"Backpropagation is shorthand for “the backward propagation of errors” and is the main algorithm used to calculate the partial derivative of the error for each parameter in a neural network.In other words, the algorithm computes the gradient over all parameters which is used by gradient descent to determine how to update the weights of the network, in order to achieve a lower loss. Backpropagation can be thought of as an implementation of the chain rule of derivatives for computation graphs.",1
Batch,A batch is a fixed number of examples used in one training iteration during the model training phase. You can read about Batch size here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/optimization-principles-(in-deep-learning)#Batch_size,1
What is Batch,A batch is a fixed number of examples used in one training iteration during the model training phase. You can read about Batch size here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/optimization-principles-(in-deep-learning)#Batch_size,1
Can you help me with Batch,A batch is a fixed number of examples used in one training iteration during the model training phase. You can read about Batch size here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/optimization-principles-(in-deep-learning)#Batch_size,1
What does Batch mean?,A batch is a fixed number of examples used in one training iteration during the model training phase. You can read about Batch size here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/optimization-principles-(in-deep-learning)#Batch_size,1
How do I use Batch?,A batch is a fixed number of examples used in one training iteration during the model training phase. You can read about Batch size here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/optimization-principles-(in-deep-learning)#Batch_size,1
Batch gradient descent,"Batch gradient descent is an implementation of gradient descent which computes the real gradient of the loss function by taking into account all the training examples.In practice, batch gradient descent is rarely used for deep learning applications, because calculating the real gradient from all the training examples 1) requires to store the entire training set in the processor's cache memory (which is often not feasible) and 2) it's slow. Instead, methods that approximate the real gradient like stochastic gradient descent or mini-batch (stochastic) gradient descent are used.",1
What is Batch gradient descent,"Batch gradient descent is an implementation of gradient descent which computes the real gradient of the loss function by taking into account all the training examples.In practice, batch gradient descent is rarely used for deep learning applications, because calculating the real gradient from all the training examples 1) requires to store the entire training set in the processor's cache memory (which is often not feasible) and 2) it's slow. Instead, methods that approximate the real gradient like stochastic gradient descent or mini-batch (stochastic) gradient descent are used.",1
Can you help me with Batch gradient descent,"Batch gradient descent is an implementation of gradient descent which computes the real gradient of the loss function by taking into account all the training examples.In practice, batch gradient descent is rarely used for deep learning applications, because calculating the real gradient from all the training examples 1) requires to store the entire training set in the processor's cache memory (which is often not feasible) and 2) it's slow. Instead, methods that approximate the real gradient like stochastic gradient descent or mini-batch (stochastic) gradient descent are used.",1
What does Batch gradient descent mean?,"Batch gradient descent is an implementation of gradient descent which computes the real gradient of the loss function by taking into account all the training examples.In practice, batch gradient descent is rarely used for deep learning applications, because calculating the real gradient from all the training examples 1) requires to store the entire training set in the processor's cache memory (which is often not feasible) and 2) it's slow. Instead, methods that approximate the real gradient like stochastic gradient descent or mini-batch (stochastic) gradient descent are used.",1
How do I use Batch gradient descent?,"Batch gradient descent is an implementation of gradient descent which computes the real gradient of the loss function by taking into account all the training examples.In practice, batch gradient descent is rarely used for deep learning applications, because calculating the real gradient from all the training examples 1) requires to store the entire training set in the processor's cache memory (which is often not feasible) and 2) it's slow. Instead, methods that approximate the real gradient like stochastic gradient descent or mini-batch (stochastic) gradient descent are used.",1
Batch normalization,"Batch normalization standardizes the output of a previous activation layer by subtracting the batch mean and dividing by the batch standard deviation.This helps speed up the training of the network. It also makes the network learn to generalize, as it introduces a small controlled amount of noise in the inputs of the subsequent layer. The effect on the network of the latter is similar to those of dropout.Use batch normalization with convolutional neural networks after a convolutional layer (or after a convolutional + pooling layer). You can read about Batch normalization here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/batch-normalization",1
What is Batch normalization,"Batch normalization standardizes the output of a previous activation layer by subtracting the batch mean and dividing by the batch standard deviation.This helps speed up the training of the network. It also makes the network learn to generalize, as it introduces a small controlled amount of noise in the inputs of the subsequent layer. The effect on the network of the latter is similar to those of dropout.Use batch normalization with convolutional neural networks after a convolutional layer (or after a convolutional + pooling layer). You can read about Batch normalization here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/batch-normalization",1
Can you help me with Batch normalization,"Batch normalization standardizes the output of a previous activation layer by subtracting the batch mean and dividing by the batch standard deviation.This helps speed up the training of the network. It also makes the network learn to generalize, as it introduces a small controlled amount of noise in the inputs of the subsequent layer. The effect on the network of the latter is similar to those of dropout.Use batch normalization with convolutional neural networks after a convolutional layer (or after a convolutional + pooling layer). You can read about Batch normalization here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/batch-normalization",1
What does Batch normalization mean?,"Batch normalization standardizes the output of a previous activation layer by subtracting the batch mean and dividing by the batch standard deviation.This helps speed up the training of the network. It also makes the network learn to generalize, as it introduces a small controlled amount of noise in the inputs of the subsequent layer. The effect on the network of the latter is similar to those of dropout.Use batch normalization with convolutional neural networks after a convolutional layer (or after a convolutional + pooling layer). You can read about Batch normalization here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/batch-normalization",1
How do I use Batch normalization?,"Batch normalization standardizes the output of a previous activation layer by subtracting the batch mean and dividing by the batch standard deviation.This helps speed up the training of the network. It also makes the network learn to generalize, as it introduces a small controlled amount of noise in the inputs of the subsequent layer. The effect on the network of the latter is similar to those of dropout.Use batch normalization with convolutional neural networks after a convolutional layer (or after a convolutional + pooling layer). You can read about Batch normalization here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/batch-normalization",1
Bias,"Bias can have three meanings:Biased data (ethics) - data that inherently favors and/or is detrimental to things or (group of) people. This bias can be introduced, intentionally or not, during the data creation, collection or usage stage.Bias model - see separate entry of the same name.Bias term - in a mathematical formula, the bias term is its offset from the origin and is often referred to as b or wo in the deep learning terminology.",1
What is Bias,"Bias can have three meanings:Biased data (ethics) - data that inherently favors and/or is detrimental to things or (group of) people. This bias can be introduced, intentionally or not, during the data creation, collection or usage stage.Bias model - see separate entry of the same name.Bias term - in a mathematical formula, the bias term is its offset from the origin and is often referred to as b or wo in the deep learning terminology.",1
Can you help me with Bias,"Bias can have three meanings:Biased data (ethics) - data that inherently favors and/or is detrimental to things or (group of) people. This bias can be introduced, intentionally or not, during the data creation, collection or usage stage.Bias model - see separate entry of the same name.Bias term - in a mathematical formula, the bias term is its offset from the origin and is often referred to as b or wo in the deep learning terminology.",1
What does Bias mean?,"Bias can have three meanings:Biased data (ethics) - data that inherently favors and/or is detrimental to things or (group of) people. This bias can be introduced, intentionally or not, during the data creation, collection or usage stage.Bias model - see separate entry of the same name.Bias term - in a mathematical formula, the bias term is its offset from the origin and is often referred to as b or wo in the deep learning terminology.",1
How do I use Bias?,"Bias can have three meanings:Biased data (ethics) - data that inherently favors and/or is detrimental to things or (group of) people. This bias can be introduced, intentionally or not, during the data creation, collection or usage stage.Bias model - see separate entry of the same name.Bias term - in a mathematical formula, the bias term is its offset from the origin and is often referred to as b or wo in the deep learning terminology.",1
Binary crossentropy,"Binary crossentropy is a loss function used on problems involving yes/no (binary) decisions.where ŷ is the predicted expected value and y is the observed value.Binary crossentropy measures how far away from the true value (which is either 0 or 1) the prediction is for each of the classes and then averages these class-wise errors to obtain the final loss.You use binary crossentropy on multi-label problems.
Use binary crossentropy together with the sigmoid activation function. You can read about Binary crossentropy here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/binary-crossentropy",1
What is Binary crossentropy,"Binary crossentropy is a loss function used on problems involving yes/no (binary) decisions.where ŷ is the predicted expected value and y is the observed value.Binary crossentropy measures how far away from the true value (which is either 0 or 1) the prediction is for each of the classes and then averages these class-wise errors to obtain the final loss.You use binary crossentropy on multi-label problems.
Use binary crossentropy together with the sigmoid activation function. You can read about Binary crossentropy here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/binary-crossentropy",1
Can you help me with Binary crossentropy,"Binary crossentropy is a loss function used on problems involving yes/no (binary) decisions.where ŷ is the predicted expected value and y is the observed value.Binary crossentropy measures how far away from the true value (which is either 0 or 1) the prediction is for each of the classes and then averages these class-wise errors to obtain the final loss.You use binary crossentropy on multi-label problems.
Use binary crossentropy together with the sigmoid activation function. You can read about Binary crossentropy here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/binary-crossentropy",1
What does Binary crossentropy mean?,"Binary crossentropy is a loss function used on problems involving yes/no (binary) decisions.where ŷ is the predicted expected value and y is the observed value.Binary crossentropy measures how far away from the true value (which is either 0 or 1) the prediction is for each of the classes and then averages these class-wise errors to obtain the final loss.You use binary crossentropy on multi-label problems.
Use binary crossentropy together with the sigmoid activation function. You can read about Binary crossentropy here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/binary-crossentropy",1
How do I use Binary crossentropy?,"Binary crossentropy is a loss function used on problems involving yes/no (binary) decisions.where ŷ is the predicted expected value and y is the observed value.Binary crossentropy measures how far away from the true value (which is either 0 or 1) the prediction is for each of the classes and then averages these class-wise errors to obtain the final loss.You use binary crossentropy on multi-label problems.
Use binary crossentropy together with the sigmoid activation function. You can read about Binary crossentropy here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/binary-crossentropy",1
Block,A block is the basic building unit in the Peltarion Platform. They represent the basic components of a neural network and/or the actions that can be carried out on them. You can read about Blocks here: https://peltarion.com/knowledge-center/documentation/ai-concepts/natural-language-processing#_blocks,1
What is Block,A block is the basic building unit in the Peltarion Platform. They represent the basic components of a neural network and/or the actions that can be carried out on them. You can read about Blocks here: https://peltarion.com/knowledge-center/documentation/ai-concepts/natural-language-processing#_blocks,1
Can you help me with Block,A block is the basic building unit in the Peltarion Platform. They represent the basic components of a neural network and/or the actions that can be carried out on them. You can read about Blocks here: https://peltarion.com/knowledge-center/documentation/ai-concepts/natural-language-processing#_blocks,1
What does Block mean?,A block is the basic building unit in the Peltarion Platform. They represent the basic components of a neural network and/or the actions that can be carried out on them. You can read about Blocks here: https://peltarion.com/knowledge-center/documentation/ai-concepts/natural-language-processing#_blocks,1
How do I use Block?,A block is the basic building unit in the Peltarion Platform. They represent the basic components of a neural network and/or the actions that can be carried out on them. You can read about Blocks here: https://peltarion.com/knowledge-center/documentation/ai-concepts/natural-language-processing#_blocks,1
Categorical crossentropy,"Categorical crossentropy is a loss function that is used for single label classification. This is when only one category is applicable for each data point. In other words, an example can belong to one class only.where ŷ is the predicted expected value and y is the observed value.Categorical crossentropy will compare the distribution of the predictions (the activations in the target, one for each class) with the true distribution, where the probability of the true class is set to 1 and 0 for the other classes. To put it in a different way, the true class is represented as a one-hot encoded vector, and the closer the model's outputs are to that vector, the lower the loss.Use categorical crossentropy in classification problems where only one result can be correct.
Use categorical crossentropy together with the softmax activation function. You can read about Categorical crossentropy here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/categorical-crossentropy",1
What is Categorical crossentropy,"Categorical crossentropy is a loss function that is used for single label classification. This is when only one category is applicable for each data point. In other words, an example can belong to one class only.where ŷ is the predicted expected value and y is the observed value.Categorical crossentropy will compare the distribution of the predictions (the activations in the target, one for each class) with the true distribution, where the probability of the true class is set to 1 and 0 for the other classes. To put it in a different way, the true class is represented as a one-hot encoded vector, and the closer the model's outputs are to that vector, the lower the loss.Use categorical crossentropy in classification problems where only one result can be correct.
Use categorical crossentropy together with the softmax activation function. You can read about Categorical crossentropy here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/categorical-crossentropy",1
Can you help me with Categorical crossentropy,"Categorical crossentropy is a loss function that is used for single label classification. This is when only one category is applicable for each data point. In other words, an example can belong to one class only.where ŷ is the predicted expected value and y is the observed value.Categorical crossentropy will compare the distribution of the predictions (the activations in the target, one for each class) with the true distribution, where the probability of the true class is set to 1 and 0 for the other classes. To put it in a different way, the true class is represented as a one-hot encoded vector, and the closer the model's outputs are to that vector, the lower the loss.Use categorical crossentropy in classification problems where only one result can be correct.
Use categorical crossentropy together with the softmax activation function. You can read about Categorical crossentropy here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/categorical-crossentropy",1
What does Categorical crossentropy mean?,"Categorical crossentropy is a loss function that is used for single label classification. This is when only one category is applicable for each data point. In other words, an example can belong to one class only.where ŷ is the predicted expected value and y is the observed value.Categorical crossentropy will compare the distribution of the predictions (the activations in the target, one for each class) with the true distribution, where the probability of the true class is set to 1 and 0 for the other classes. To put it in a different way, the true class is represented as a one-hot encoded vector, and the closer the model's outputs are to that vector, the lower the loss.Use categorical crossentropy in classification problems where only one result can be correct.
Use categorical crossentropy together with the softmax activation function. You can read about Categorical crossentropy here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/categorical-crossentropy",1
How do I use Categorical crossentropy?,"Categorical crossentropy is a loss function that is used for single label classification. This is when only one category is applicable for each data point. In other words, an example can belong to one class only.where ŷ is the predicted expected value and y is the observed value.Categorical crossentropy will compare the distribution of the predictions (the activations in the target, one for each class) with the true distribution, where the probability of the true class is set to 1 and 0 for the other classes. To put it in a different way, the true class is represented as a one-hot encoded vector, and the closer the model's outputs are to that vector, the lower the loss.Use categorical crossentropy in classification problems where only one result can be correct.
Use categorical crossentropy together with the softmax activation function. You can read about Categorical crossentropy here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/categorical-crossentropy",1
Categorical feature,"A categorical feature is an input variable that has a discrete set of possible values.Example: If your variable is season the possible values it can take are Winter, Spring, Summer and Autumn.",1
What is Categorical feature,"A categorical feature is an input variable that has a discrete set of possible values.Example: If your variable is season the possible values it can take are Winter, Spring, Summer and Autumn.",1
Can you help me with Categorical feature,"A categorical feature is an input variable that has a discrete set of possible values.Example: If your variable is season the possible values it can take are Winter, Spring, Summer and Autumn.",1
What does Categorical feature mean?,"A categorical feature is an input variable that has a discrete set of possible values.Example: If your variable is season the possible values it can take are Winter, Spring, Summer and Autumn.",1
How do I use Categorical feature?,"A categorical feature is an input variable that has a discrete set of possible values.Example: If your variable is season the possible values it can take are Winter, Spring, Summer and Autumn.",1
Class,"A class is a group to which a specific example can belong to. For example, in the multi-classification model we built in the 'Classifying images of clothes' tutorial, the classes are 'Ankle boot', 'T-shirt', 'Dress', 'Pullover', etc. In a classification model, a class is your target i.e., what you want your model to predict. Also, classes appear in the dataset as a categorical feature. You can read about Classification models - Evaluate and improve  here: https://peltarion.com/knowledge-center/documentation/improve-experiments/tips-to-improve-for-beginners/classification-models---evaluate-and-improve",1
What is Class,"A class is a group to which a specific example can belong to. For example, in the multi-classification model we built in the 'Classifying images of clothes' tutorial, the classes are 'Ankle boot', 'T-shirt', 'Dress', 'Pullover', etc. In a classification model, a class is your target i.e., what you want your model to predict. Also, classes appear in the dataset as a categorical feature. You can read about Classification models - Evaluate and improve  here: https://peltarion.com/knowledge-center/documentation/improve-experiments/tips-to-improve-for-beginners/classification-models---evaluate-and-improve",1
Can you help me with Class,"A class is a group to which a specific example can belong to. For example, in the multi-classification model we built in the 'Classifying images of clothes' tutorial, the classes are 'Ankle boot', 'T-shirt', 'Dress', 'Pullover', etc. In a classification model, a class is your target i.e., what you want your model to predict. Also, classes appear in the dataset as a categorical feature. You can read about Classification models - Evaluate and improve  here: https://peltarion.com/knowledge-center/documentation/improve-experiments/tips-to-improve-for-beginners/classification-models---evaluate-and-improve",1
What does Class mean?,"A class is a group to which a specific example can belong to. For example, in the multi-classification model we built in the 'Classifying images of clothes' tutorial, the classes are 'Ankle boot', 'T-shirt', 'Dress', 'Pullover', etc. In a classification model, a class is your target i.e., what you want your model to predict. Also, classes appear in the dataset as a categorical feature. You can read about Classification models - Evaluate and improve  here: https://peltarion.com/knowledge-center/documentation/improve-experiments/tips-to-improve-for-beginners/classification-models---evaluate-and-improve",1
How do I use Class?,"A class is a group to which a specific example can belong to. For example, in the multi-classification model we built in the 'Classifying images of clothes' tutorial, the classes are 'Ankle boot', 'T-shirt', 'Dress', 'Pullover', etc. In a classification model, a class is your target i.e., what you want your model to predict. Also, classes appear in the dataset as a categorical feature. You can read about Classification models - Evaluate and improve  here: https://peltarion.com/knowledge-center/documentation/improve-experiments/tips-to-improve-for-beginners/classification-models---evaluate-and-improve",1
Class weighting,"Class weighting is the inclusion of a coefficient in the loss function calculation, to improve single-label classification results on imbalanced datasets.
This coefficient scales the error of each training example inversely to the frequency of its target category.Similarly to oversampling and undersampling, class weighting prevents models from achieving artificially high accuracy by only learning which class is the most frequent, i.e., the most likely to be presented to the model.Use on the platform: Select Use class weights in the Target block.Example: An imbalanced dataset containing 900 examples of class A and 100 images of class B, a classification model that always predicts A would achieve a relatively low loss and a 90% accuracy.
By scaling up the error of misclassified B examples, class weighting pushes models to learn a better representation of each class.",1
What is Class weighting,"Class weighting is the inclusion of a coefficient in the loss function calculation, to improve single-label classification results on imbalanced datasets.
This coefficient scales the error of each training example inversely to the frequency of its target category.Similarly to oversampling and undersampling, class weighting prevents models from achieving artificially high accuracy by only learning which class is the most frequent, i.e., the most likely to be presented to the model.Use on the platform: Select Use class weights in the Target block.Example: An imbalanced dataset containing 900 examples of class A and 100 images of class B, a classification model that always predicts A would achieve a relatively low loss and a 90% accuracy.
By scaling up the error of misclassified B examples, class weighting pushes models to learn a better representation of each class.",1
Can you help me with Class weighting,"Class weighting is the inclusion of a coefficient in the loss function calculation, to improve single-label classification results on imbalanced datasets.
This coefficient scales the error of each training example inversely to the frequency of its target category.Similarly to oversampling and undersampling, class weighting prevents models from achieving artificially high accuracy by only learning which class is the most frequent, i.e., the most likely to be presented to the model.Use on the platform: Select Use class weights in the Target block.Example: An imbalanced dataset containing 900 examples of class A and 100 images of class B, a classification model that always predicts A would achieve a relatively low loss and a 90% accuracy.
By scaling up the error of misclassified B examples, class weighting pushes models to learn a better representation of each class.",1
What does Class weighting mean?,"Class weighting is the inclusion of a coefficient in the loss function calculation, to improve single-label classification results on imbalanced datasets.
This coefficient scales the error of each training example inversely to the frequency of its target category.Similarly to oversampling and undersampling, class weighting prevents models from achieving artificially high accuracy by only learning which class is the most frequent, i.e., the most likely to be presented to the model.Use on the platform: Select Use class weights in the Target block.Example: An imbalanced dataset containing 900 examples of class A and 100 images of class B, a classification model that always predicts A would achieve a relatively low loss and a 90% accuracy.
By scaling up the error of misclassified B examples, class weighting pushes models to learn a better representation of each class.",1
How do I use Class weighting?,"Class weighting is the inclusion of a coefficient in the loss function calculation, to improve single-label classification results on imbalanced datasets.
This coefficient scales the error of each training example inversely to the frequency of its target category.Similarly to oversampling and undersampling, class weighting prevents models from achieving artificially high accuracy by only learning which class is the most frequent, i.e., the most likely to be presented to the model.Use on the platform: Select Use class weights in the Target block.Example: An imbalanced dataset containing 900 examples of class A and 100 images of class B, a classification model that always predicts A would achieve a relatively low loss and a 90% accuracy.
By scaling up the error of misclassified B examples, class weighting pushes models to learn a better representation of each class.",1
Classification,"Classification is the process through which a trained model predicts (or assigns) one or several classes for one example. If the model is constrained to predict precisely one class for each example it is a single label classification model. If the model can assign each example to several classes it is a multi label classification model.To train the model, a training set needs to have multiple labeled examples for each of the desired prediction classes.Multi-label classification is a variant of classification where multiple classes (labels) may be assigned to each example.
Example: You want to know which out of a number of objects that are present in an image, where there can be both a dog and a person and a car in the same image.Single-label classification is a variant of classification where precisely one class (label) is assigned to each example.
Example: Images of skin lesions is classified into either benign or malignant, since a lesion cannot be both at the same time. You can read about Classification models - Evaluate and improve  here: https://peltarion.com/knowledge-center/documentation/improve-experiments/tips-to-improve-for-beginners/classification-models---evaluate-and-improve",1
What is Classification,"Classification is the process through which a trained model predicts (or assigns) one or several classes for one example. If the model is constrained to predict precisely one class for each example it is a single label classification model. If the model can assign each example to several classes it is a multi label classification model.To train the model, a training set needs to have multiple labeled examples for each of the desired prediction classes.Multi-label classification is a variant of classification where multiple classes (labels) may be assigned to each example.
Example: You want to know which out of a number of objects that are present in an image, where there can be both a dog and a person and a car in the same image.Single-label classification is a variant of classification where precisely one class (label) is assigned to each example.
Example: Images of skin lesions is classified into either benign or malignant, since a lesion cannot be both at the same time. You can read about Classification models - Evaluate and improve  here: https://peltarion.com/knowledge-center/documentation/improve-experiments/tips-to-improve-for-beginners/classification-models---evaluate-and-improve",1
Can you help me with Classification,"Classification is the process through which a trained model predicts (or assigns) one or several classes for one example. If the model is constrained to predict precisely one class for each example it is a single label classification model. If the model can assign each example to several classes it is a multi label classification model.To train the model, a training set needs to have multiple labeled examples for each of the desired prediction classes.Multi-label classification is a variant of classification where multiple classes (labels) may be assigned to each example.
Example: You want to know which out of a number of objects that are present in an image, where there can be both a dog and a person and a car in the same image.Single-label classification is a variant of classification where precisely one class (label) is assigned to each example.
Example: Images of skin lesions is classified into either benign or malignant, since a lesion cannot be both at the same time. You can read about Classification models - Evaluate and improve  here: https://peltarion.com/knowledge-center/documentation/improve-experiments/tips-to-improve-for-beginners/classification-models---evaluate-and-improve",1
What does Classification mean?,"Classification is the process through which a trained model predicts (or assigns) one or several classes for one example. If the model is constrained to predict precisely one class for each example it is a single label classification model. If the model can assign each example to several classes it is a multi label classification model.To train the model, a training set needs to have multiple labeled examples for each of the desired prediction classes.Multi-label classification is a variant of classification where multiple classes (labels) may be assigned to each example.
Example: You want to know which out of a number of objects that are present in an image, where there can be both a dog and a person and a car in the same image.Single-label classification is a variant of classification where precisely one class (label) is assigned to each example.
Example: Images of skin lesions is classified into either benign or malignant, since a lesion cannot be both at the same time. You can read about Classification models - Evaluate and improve  here: https://peltarion.com/knowledge-center/documentation/improve-experiments/tips-to-improve-for-beginners/classification-models---evaluate-and-improve",1
How do I use Classification?,"Classification is the process through which a trained model predicts (or assigns) one or several classes for one example. If the model is constrained to predict precisely one class for each example it is a single label classification model. If the model can assign each example to several classes it is a multi label classification model.To train the model, a training set needs to have multiple labeled examples for each of the desired prediction classes.Multi-label classification is a variant of classification where multiple classes (labels) may be assigned to each example.
Example: You want to know which out of a number of objects that are present in an image, where there can be both a dog and a person and a car in the same image.Single-label classification is a variant of classification where precisely one class (label) is assigned to each example.
Example: Images of skin lesions is classified into either benign or malignant, since a lesion cannot be both at the same time. You can read about Classification models - Evaluate and improve  here: https://peltarion.com/knowledge-center/documentation/improve-experiments/tips-to-improve-for-beginners/classification-models---evaluate-and-improve",1
Clustering,"Clustering is the process through which an algorithm tries to group data points into different clusters based on some similarity between them.Unlike classification, no model is trained beforehand to predict predefined classes (in other words, no training examples are provided). Instead, a clustering algorithm discovers by itself what relationships are found in the data and groups the individual data points based on this. This is an example of unsupervised learning.",1
What is Clustering,"Clustering is the process through which an algorithm tries to group data points into different clusters based on some similarity between them.Unlike classification, no model is trained beforehand to predict predefined classes (in other words, no training examples are provided). Instead, a clustering algorithm discovers by itself what relationships are found in the data and groups the individual data points based on this. This is an example of unsupervised learning.",1
Can you help me with Clustering,"Clustering is the process through which an algorithm tries to group data points into different clusters based on some similarity between them.Unlike classification, no model is trained beforehand to predict predefined classes (in other words, no training examples are provided). Instead, a clustering algorithm discovers by itself what relationships are found in the data and groups the individual data points based on this. This is an example of unsupervised learning.",1
What does Clustering mean?,"Clustering is the process through which an algorithm tries to group data points into different clusters based on some similarity between them.Unlike classification, no model is trained beforehand to predict predefined classes (in other words, no training examples are provided). Instead, a clustering algorithm discovers by itself what relationships are found in the data and groups the individual data points based on this. This is an example of unsupervised learning.",1
How do I use Clustering?,"Clustering is the process through which an algorithm tries to group data points into different clusters based on some similarity between them.Unlike classification, no model is trained beforehand to predict predefined classes (in other words, no training examples are provided). Instead, a clustering algorithm discovers by itself what relationships are found in the data and groups the individual data points based on this. This is an example of unsupervised learning.",1
Concatenate,"Concatenate takes any number of inputs that have the same shape, and merges them along a specified axis. The output has the same size as the sum of all sizes of the input along the axis to concatenate, and the same shape for all other axes, if any.Note that the input order is important.Concatenating can be useful to merge features coming from different parts of the model towards the end (for instance merging image features with tabular data when estimating the price of a house), or joining together multiple images that are tiles of a bigger map.Read more about how you can use the Concatenate block on the Platform here. You can read about Concatenate here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/concatenate",1
What is Concatenate,"Concatenate takes any number of inputs that have the same shape, and merges them along a specified axis. The output has the same size as the sum of all sizes of the input along the axis to concatenate, and the same shape for all other axes, if any.Note that the input order is important.Concatenating can be useful to merge features coming from different parts of the model towards the end (for instance merging image features with tabular data when estimating the price of a house), or joining together multiple images that are tiles of a bigger map.Read more about how you can use the Concatenate block on the Platform here. You can read about Concatenate here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/concatenate",1
Can you help me with Concatenate,"Concatenate takes any number of inputs that have the same shape, and merges them along a specified axis. The output has the same size as the sum of all sizes of the input along the axis to concatenate, and the same shape for all other axes, if any.Note that the input order is important.Concatenating can be useful to merge features coming from different parts of the model towards the end (for instance merging image features with tabular data when estimating the price of a house), or joining together multiple images that are tiles of a bigger map.Read more about how you can use the Concatenate block on the Platform here. You can read about Concatenate here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/concatenate",1
What does Concatenate mean?,"Concatenate takes any number of inputs that have the same shape, and merges them along a specified axis. The output has the same size as the sum of all sizes of the input along the axis to concatenate, and the same shape for all other axes, if any.Note that the input order is important.Concatenating can be useful to merge features coming from different parts of the model towards the end (for instance merging image features with tabular data when estimating the price of a house), or joining together multiple images that are tiles of a bigger map.Read more about how you can use the Concatenate block on the Platform here. You can read about Concatenate here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/concatenate",1
How do I use Concatenate?,"Concatenate takes any number of inputs that have the same shape, and merges them along a specified axis. The output has the same size as the sum of all sizes of the input along the axis to concatenate, and the same shape for all other axes, if any.Note that the input order is important.Concatenating can be useful to merge features coming from different parts of the model towards the end (for instance merging image features with tabular data when estimating the price of a house), or joining together multiple images that are tiles of a bigger map.Read more about how you can use the Concatenate block on the Platform here. You can read about Concatenate here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/concatenate",1
Confusion matrix,"A confusion matrix helps to illustrate what kinds of errors a classification model is making.If you have a binary classifier model that distinguishes between a positive and a negative class, you can define the following 4 values depending on the actual vs predicted class.The resulting matrix has 4 fields known as:True Positives (TP)True Negatives (TN)False Positives (FP),False Negatives (FN)Different combinations of these fields result in a number of key metrics, including: accuracy, precision, recall, specificity and f1 score.The confusion matrix is a compact but very informative representation of how your classification model is performing. It is the go to tool for evaluating classification models.The confusion matrix is used for binary or multiclass, single label, classification problems. You can read about Confusion matrix  here: https://peltarion.com/knowledge-center/documentation/evaluation-view/predictions-inspection/confusion-matrix",1
What is Confusion matrix,"A confusion matrix helps to illustrate what kinds of errors a classification model is making.If you have a binary classifier model that distinguishes between a positive and a negative class, you can define the following 4 values depending on the actual vs predicted class.The resulting matrix has 4 fields known as:True Positives (TP)True Negatives (TN)False Positives (FP),False Negatives (FN)Different combinations of these fields result in a number of key metrics, including: accuracy, precision, recall, specificity and f1 score.The confusion matrix is a compact but very informative representation of how your classification model is performing. It is the go to tool for evaluating classification models.The confusion matrix is used for binary or multiclass, single label, classification problems. You can read about Confusion matrix  here: https://peltarion.com/knowledge-center/documentation/evaluation-view/predictions-inspection/confusion-matrix",1
Can you help me with Confusion matrix,"A confusion matrix helps to illustrate what kinds of errors a classification model is making.If you have a binary classifier model that distinguishes between a positive and a negative class, you can define the following 4 values depending on the actual vs predicted class.The resulting matrix has 4 fields known as:True Positives (TP)True Negatives (TN)False Positives (FP),False Negatives (FN)Different combinations of these fields result in a number of key metrics, including: accuracy, precision, recall, specificity and f1 score.The confusion matrix is a compact but very informative representation of how your classification model is performing. It is the go to tool for evaluating classification models.The confusion matrix is used for binary or multiclass, single label, classification problems. You can read about Confusion matrix  here: https://peltarion.com/knowledge-center/documentation/evaluation-view/predictions-inspection/confusion-matrix",1
What does Confusion matrix mean?,"A confusion matrix helps to illustrate what kinds of errors a classification model is making.If you have a binary classifier model that distinguishes between a positive and a negative class, you can define the following 4 values depending on the actual vs predicted class.The resulting matrix has 4 fields known as:True Positives (TP)True Negatives (TN)False Positives (FP),False Negatives (FN)Different combinations of these fields result in a number of key metrics, including: accuracy, precision, recall, specificity and f1 score.The confusion matrix is a compact but very informative representation of how your classification model is performing. It is the go to tool for evaluating classification models.The confusion matrix is used for binary or multiclass, single label, classification problems. You can read about Confusion matrix  here: https://peltarion.com/knowledge-center/documentation/evaluation-view/predictions-inspection/confusion-matrix",1
How do I use Confusion matrix?,"A confusion matrix helps to illustrate what kinds of errors a classification model is making.If you have a binary classifier model that distinguishes between a positive and a negative class, you can define the following 4 values depending on the actual vs predicted class.The resulting matrix has 4 fields known as:True Positives (TP)True Negatives (TN)False Positives (FP),False Negatives (FN)Different combinations of these fields result in a number of key metrics, including: accuracy, precision, recall, specificity and f1 score.The confusion matrix is a compact but very informative representation of how your classification model is performing. It is the go to tool for evaluating classification models.The confusion matrix is used for binary or multiclass, single label, classification problems. You can read about Confusion matrix  here: https://peltarion.com/knowledge-center/documentation/evaluation-view/predictions-inspection/confusion-matrix",1
Convolution operation (convolve),"In the context of deep learning a convolution operation is a mathematical operation between a matrix (which usually encodes an image) and another smaller matrix called the filter, where each element of the matrix is multiplied by the filter as follows 1:For a visualization of how a filter affects a matrix, we recommend this excellent demo.For a detailed explanation of convolutions in the context of Deep Learning see Christopher Olah's excellent article or Dumoulin, V., Visin, F. (2016). A guide to convolution arithmetic for deep learning. arXiv:1603.07285v2, a fantastic paper.1 Technically this is actually called cross-correlation, which is very closely related to convolutions.",1
What is Convolution operation (convolve),"In the context of deep learning a convolution operation is a mathematical operation between a matrix (which usually encodes an image) and another smaller matrix called the filter, where each element of the matrix is multiplied by the filter as follows 1:For a visualization of how a filter affects a matrix, we recommend this excellent demo.For a detailed explanation of convolutions in the context of Deep Learning see Christopher Olah's excellent article or Dumoulin, V., Visin, F. (2016). A guide to convolution arithmetic for deep learning. arXiv:1603.07285v2, a fantastic paper.1 Technically this is actually called cross-correlation, which is very closely related to convolutions.",1
Can you help me with Convolution operation (convolve),"In the context of deep learning a convolution operation is a mathematical operation between a matrix (which usually encodes an image) and another smaller matrix called the filter, where each element of the matrix is multiplied by the filter as follows 1:For a visualization of how a filter affects a matrix, we recommend this excellent demo.For a detailed explanation of convolutions in the context of Deep Learning see Christopher Olah's excellent article or Dumoulin, V., Visin, F. (2016). A guide to convolution arithmetic for deep learning. arXiv:1603.07285v2, a fantastic paper.1 Technically this is actually called cross-correlation, which is very closely related to convolutions.",1
What does Convolution operation (convolve) mean?,"In the context of deep learning a convolution operation is a mathematical operation between a matrix (which usually encodes an image) and another smaller matrix called the filter, where each element of the matrix is multiplied by the filter as follows 1:For a visualization of how a filter affects a matrix, we recommend this excellent demo.For a detailed explanation of convolutions in the context of Deep Learning see Christopher Olah's excellent article or Dumoulin, V., Visin, F. (2016). A guide to convolution arithmetic for deep learning. arXiv:1603.07285v2, a fantastic paper.1 Technically this is actually called cross-correlation, which is very closely related to convolutions.",1
How do I use Convolution operation (convolve)?,"In the context of deep learning a convolution operation is a mathematical operation between a matrix (which usually encodes an image) and another smaller matrix called the filter, where each element of the matrix is multiplied by the filter as follows 1:For a visualization of how a filter affects a matrix, we recommend this excellent demo.For a detailed explanation of convolutions in the context of Deep Learning see Christopher Olah's excellent article or Dumoulin, V., Visin, F. (2016). A guide to convolution arithmetic for deep learning. arXiv:1603.07285v2, a fantastic paper.1 Technically this is actually called cross-correlation, which is very closely related to convolutions.",1
Convolutional layer,"A convolutional layer applies the convolution operation between its filters and its input. On the Peltarion Platform, you can find the 2 dimensional implementation of a convolutional layer under the name of '2D Convolution.'This type of layer helps you take advantage of the spatial information in your data e.g., the relationships between adjacent pixels in an image (this reflects the intuition that features in an image are often not dependent on the position). By applying the same filter to all positions of an image, they can help reduce the number of parameters of your model compared to fully connected layers.Use convolutional layers on data where the spacial relationships of the data are important, like images. In theory, you can also try using convolutional layers on sequential or time series data, but LSTM units are more tailored for this data.",1
What is Convolutional layer,"A convolutional layer applies the convolution operation between its filters and its input. On the Peltarion Platform, you can find the 2 dimensional implementation of a convolutional layer under the name of '2D Convolution.'This type of layer helps you take advantage of the spatial information in your data e.g., the relationships between adjacent pixels in an image (this reflects the intuition that features in an image are often not dependent on the position). By applying the same filter to all positions of an image, they can help reduce the number of parameters of your model compared to fully connected layers.Use convolutional layers on data where the spacial relationships of the data are important, like images. In theory, you can also try using convolutional layers on sequential or time series data, but LSTM units are more tailored for this data.",1
Can you help me with Convolutional layer,"A convolutional layer applies the convolution operation between its filters and its input. On the Peltarion Platform, you can find the 2 dimensional implementation of a convolutional layer under the name of '2D Convolution.'This type of layer helps you take advantage of the spatial information in your data e.g., the relationships between adjacent pixels in an image (this reflects the intuition that features in an image are often not dependent on the position). By applying the same filter to all positions of an image, they can help reduce the number of parameters of your model compared to fully connected layers.Use convolutional layers on data where the spacial relationships of the data are important, like images. In theory, you can also try using convolutional layers on sequential or time series data, but LSTM units are more tailored for this data.",1
What does Convolutional layer mean?,"A convolutional layer applies the convolution operation between its filters and its input. On the Peltarion Platform, you can find the 2 dimensional implementation of a convolutional layer under the name of '2D Convolution.'This type of layer helps you take advantage of the spatial information in your data e.g., the relationships between adjacent pixels in an image (this reflects the intuition that features in an image are often not dependent on the position). By applying the same filter to all positions of an image, they can help reduce the number of parameters of your model compared to fully connected layers.Use convolutional layers on data where the spacial relationships of the data are important, like images. In theory, you can also try using convolutional layers on sequential or time series data, but LSTM units are more tailored for this data.",1
How do I use Convolutional layer?,"A convolutional layer applies the convolution operation between its filters and its input. On the Peltarion Platform, you can find the 2 dimensional implementation of a convolutional layer under the name of '2D Convolution.'This type of layer helps you take advantage of the spatial information in your data e.g., the relationships between adjacent pixels in an image (this reflects the intuition that features in an image are often not dependent on the position). By applying the same filter to all positions of an image, they can help reduce the number of parameters of your model compared to fully connected layers.Use convolutional layers on data where the spacial relationships of the data are important, like images. In theory, you can also try using convolutional layers on sequential or time series data, but LSTM units are more tailored for this data.",1
Convolutional neural network,"A convolutional neural network is a type of neural network that makes use of convolutional, pooling and dense layers.They are tailored to take advantage of the spacial information in your data e.g., the relationships between adjacent pixels in an image (this reflects the intuition that features in an image are often not dependent on the position). By convolving the input data with the filters of the convolutional layers and subsequently pooling their outputs with pooling layer, convolutional neural networks are able to reduce the number of parameters that your model needed to learn from the data, when compared to fully connected layers.Use convolutional neural networks when you're working with image data.",1
What is Convolutional neural network,"A convolutional neural network is a type of neural network that makes use of convolutional, pooling and dense layers.They are tailored to take advantage of the spacial information in your data e.g., the relationships between adjacent pixels in an image (this reflects the intuition that features in an image are often not dependent on the position). By convolving the input data with the filters of the convolutional layers and subsequently pooling their outputs with pooling layer, convolutional neural networks are able to reduce the number of parameters that your model needed to learn from the data, when compared to fully connected layers.Use convolutional neural networks when you're working with image data.",1
Can you help me with Convolutional neural network,"A convolutional neural network is a type of neural network that makes use of convolutional, pooling and dense layers.They are tailored to take advantage of the spacial information in your data e.g., the relationships between adjacent pixels in an image (this reflects the intuition that features in an image are often not dependent on the position). By convolving the input data with the filters of the convolutional layers and subsequently pooling their outputs with pooling layer, convolutional neural networks are able to reduce the number of parameters that your model needed to learn from the data, when compared to fully connected layers.Use convolutional neural networks when you're working with image data.",1
What does Convolutional neural network mean?,"A convolutional neural network is a type of neural network that makes use of convolutional, pooling and dense layers.They are tailored to take advantage of the spacial information in your data e.g., the relationships between adjacent pixels in an image (this reflects the intuition that features in an image are often not dependent on the position). By convolving the input data with the filters of the convolutional layers and subsequently pooling their outputs with pooling layer, convolutional neural networks are able to reduce the number of parameters that your model needed to learn from the data, when compared to fully connected layers.Use convolutional neural networks when you're working with image data.",1
How do I use Convolutional neural network?,"A convolutional neural network is a type of neural network that makes use of convolutional, pooling and dense layers.They are tailored to take advantage of the spacial information in your data e.g., the relationships between adjacent pixels in an image (this reflects the intuition that features in an image are often not dependent on the position). By convolving the input data with the filters of the convolutional layers and subsequently pooling their outputs with pooling layer, convolutional neural networks are able to reduce the number of parameters that your model needed to learn from the data, when compared to fully connected layers.Use convolutional neural networks when you're working with image data.",1
Dataset,"A dataset is a collection of data. A machine learning dataset will contain features that are used to predict the desired targets. Each entry in the dataset is an example that is used to either train, validate or test the model. You can read about Datasets view here: /knowledge-center/documentation/datasets-view",1
What is Dataset,"A dataset is a collection of data. A machine learning dataset will contain features that are used to predict the desired targets. Each entry in the dataset is an example that is used to either train, validate or test the model. You can read about Datasets view here: /knowledge-center/documentation/datasets-view",1
Can you help me with Dataset,"A dataset is a collection of data. A machine learning dataset will contain features that are used to predict the desired targets. Each entry in the dataset is an example that is used to either train, validate or test the model. You can read about Datasets view here: /knowledge-center/documentation/datasets-view",1
What does Dataset mean?,"A dataset is a collection of data. A machine learning dataset will contain features that are used to predict the desired targets. Each entry in the dataset is an example that is used to either train, validate or test the model. You can read about Datasets view here: /knowledge-center/documentation/datasets-view",1
How do I use Dataset?,"A dataset is a collection of data. A machine learning dataset will contain features that are used to predict the desired targets. Each entry in the dataset is an example that is used to either train, validate or test the model. You can read about Datasets view here: /knowledge-center/documentation/datasets-view",1
Deconvolution,"Deconvolution performs an opposite operation to the convolution operation. This is also referred to as transposed convolution, which better reflects the actual mathematical operation.The deconvolution operation is used when we transform the output of a convolution back into a tensor that has the same shape as the input of that convolution, which is useful if we want a model that transforms images into other images, instead of just giving categorical or scalar predictions. Convolution is not itself an invertible operation, which means we cannot simply go from output back to the input. Deconvolution layers have instead to learn weights in the same way as convolution layers.Autoencoders and image segmentation models are examples of models that make use of deconvolutions. You can read about 2D Deconvolution block here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/2d-deconvolution-block",1
What is Deconvolution,"Deconvolution performs an opposite operation to the convolution operation. This is also referred to as transposed convolution, which better reflects the actual mathematical operation.The deconvolution operation is used when we transform the output of a convolution back into a tensor that has the same shape as the input of that convolution, which is useful if we want a model that transforms images into other images, instead of just giving categorical or scalar predictions. Convolution is not itself an invertible operation, which means we cannot simply go from output back to the input. Deconvolution layers have instead to learn weights in the same way as convolution layers.Autoencoders and image segmentation models are examples of models that make use of deconvolutions. You can read about 2D Deconvolution block here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/2d-deconvolution-block",1
Can you help me with Deconvolution,"Deconvolution performs an opposite operation to the convolution operation. This is also referred to as transposed convolution, which better reflects the actual mathematical operation.The deconvolution operation is used when we transform the output of a convolution back into a tensor that has the same shape as the input of that convolution, which is useful if we want a model that transforms images into other images, instead of just giving categorical or scalar predictions. Convolution is not itself an invertible operation, which means we cannot simply go from output back to the input. Deconvolution layers have instead to learn weights in the same way as convolution layers.Autoencoders and image segmentation models are examples of models that make use of deconvolutions. You can read about 2D Deconvolution block here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/2d-deconvolution-block",1
What does Deconvolution mean?,"Deconvolution performs an opposite operation to the convolution operation. This is also referred to as transposed convolution, which better reflects the actual mathematical operation.The deconvolution operation is used when we transform the output of a convolution back into a tensor that has the same shape as the input of that convolution, which is useful if we want a model that transforms images into other images, instead of just giving categorical or scalar predictions. Convolution is not itself an invertible operation, which means we cannot simply go from output back to the input. Deconvolution layers have instead to learn weights in the same way as convolution layers.Autoencoders and image segmentation models are examples of models that make use of deconvolutions. You can read about 2D Deconvolution block here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/2d-deconvolution-block",1
How do I use Deconvolution?,"Deconvolution performs an opposite operation to the convolution operation. This is also referred to as transposed convolution, which better reflects the actual mathematical operation.The deconvolution operation is used when we transform the output of a convolution back into a tensor that has the same shape as the input of that convolution, which is useful if we want a model that transforms images into other images, instead of just giving categorical or scalar predictions. Convolution is not itself an invertible operation, which means we cannot simply go from output back to the input. Deconvolution layers have instead to learn weights in the same way as convolution layers.Autoencoders and image segmentation models are examples of models that make use of deconvolutions. You can read about 2D Deconvolution block here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/2d-deconvolution-block",1
Deconvolutional layer,"A deconvolutional layer applies the deconvolution (or more correctly the transposed convolution operation) between its filters and its input. On the Peltarion Platform, you can find the 2 dimensional implementation of a deconvolutional layer under the name of '2D Deconvolution.'This type of layer helps you transform the output of a convolution back into a tensor that has the same shape as the input of that convolution, which is useful if we want a model that transforms images into other images, instead of just giving categorical or scalar predictions.Autoencoders and image segmentation models are examples of models that make use of deconvolutional layers.",1
What is Deconvolutional layer,"A deconvolutional layer applies the deconvolution (or more correctly the transposed convolution operation) between its filters and its input. On the Peltarion Platform, you can find the 2 dimensional implementation of a deconvolutional layer under the name of '2D Deconvolution.'This type of layer helps you transform the output of a convolution back into a tensor that has the same shape as the input of that convolution, which is useful if we want a model that transforms images into other images, instead of just giving categorical or scalar predictions.Autoencoders and image segmentation models are examples of models that make use of deconvolutional layers.",1
Can you help me with Deconvolutional layer,"A deconvolutional layer applies the deconvolution (or more correctly the transposed convolution operation) between its filters and its input. On the Peltarion Platform, you can find the 2 dimensional implementation of a deconvolutional layer under the name of '2D Deconvolution.'This type of layer helps you transform the output of a convolution back into a tensor that has the same shape as the input of that convolution, which is useful if we want a model that transforms images into other images, instead of just giving categorical or scalar predictions.Autoencoders and image segmentation models are examples of models that make use of deconvolutional layers.",1
What does Deconvolutional layer mean?,"A deconvolutional layer applies the deconvolution (or more correctly the transposed convolution operation) between its filters and its input. On the Peltarion Platform, you can find the 2 dimensional implementation of a deconvolutional layer under the name of '2D Deconvolution.'This type of layer helps you transform the output of a convolution back into a tensor that has the same shape as the input of that convolution, which is useful if we want a model that transforms images into other images, instead of just giving categorical or scalar predictions.Autoencoders and image segmentation models are examples of models that make use of deconvolutional layers.",1
How do I use Deconvolutional layer?,"A deconvolutional layer applies the deconvolution (or more correctly the transposed convolution operation) between its filters and its input. On the Peltarion Platform, you can find the 2 dimensional implementation of a deconvolutional layer under the name of '2D Deconvolution.'This type of layer helps you transform the output of a convolution back into a tensor that has the same shape as the input of that convolution, which is useful if we want a model that transforms images into other images, instead of just giving categorical or scalar predictions.Autoencoders and image segmentation models are examples of models that make use of deconvolutional layers.",1
Dense (or fully connected) layer,"In a dense layer every node of the layer is connected to every node in the subsequent layer. Thus, it feeds all outputs from the previous layer to all its nodes, each of which provides one output to the subsequent layer. On the Peltarion Platform this layer is represented by the dense block.A dense layer is the most basic layer of a neural network. The combination of more than 1 of these layers results in the classsical type of neural network or multilayer perceptorn (MLP). They are very flexible in nature and can in general learn almost any mapping from inputs to outputs.Use dense layers to build complete networks that are used for classification or prediction problems on tabular data. You can also use dense layers as the last layer(s) before the convolutional layers or recurrent neural networks. You can read about Dense here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/dense",1
What is Dense (or fully connected) layer,"In a dense layer every node of the layer is connected to every node in the subsequent layer. Thus, it feeds all outputs from the previous layer to all its nodes, each of which provides one output to the subsequent layer. On the Peltarion Platform this layer is represented by the dense block.A dense layer is the most basic layer of a neural network. The combination of more than 1 of these layers results in the classsical type of neural network or multilayer perceptorn (MLP). They are very flexible in nature and can in general learn almost any mapping from inputs to outputs.Use dense layers to build complete networks that are used for classification or prediction problems on tabular data. You can also use dense layers as the last layer(s) before the convolutional layers or recurrent neural networks. You can read about Dense here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/dense",1
Can you help me with Dense (or fully connected) layer,"In a dense layer every node of the layer is connected to every node in the subsequent layer. Thus, it feeds all outputs from the previous layer to all its nodes, each of which provides one output to the subsequent layer. On the Peltarion Platform this layer is represented by the dense block.A dense layer is the most basic layer of a neural network. The combination of more than 1 of these layers results in the classsical type of neural network or multilayer perceptorn (MLP). They are very flexible in nature and can in general learn almost any mapping from inputs to outputs.Use dense layers to build complete networks that are used for classification or prediction problems on tabular data. You can also use dense layers as the last layer(s) before the convolutional layers or recurrent neural networks. You can read about Dense here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/dense",1
What does Dense (or fully connected) layer mean?,"In a dense layer every node of the layer is connected to every node in the subsequent layer. Thus, it feeds all outputs from the previous layer to all its nodes, each of which provides one output to the subsequent layer. On the Peltarion Platform this layer is represented by the dense block.A dense layer is the most basic layer of a neural network. The combination of more than 1 of these layers results in the classsical type of neural network or multilayer perceptorn (MLP). They are very flexible in nature and can in general learn almost any mapping from inputs to outputs.Use dense layers to build complete networks that are used for classification or prediction problems on tabular data. You can also use dense layers as the last layer(s) before the convolutional layers or recurrent neural networks. You can read about Dense here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/dense",1
How do I use Dense (or fully connected) layer?,"In a dense layer every node of the layer is connected to every node in the subsequent layer. Thus, it feeds all outputs from the previous layer to all its nodes, each of which provides one output to the subsequent layer. On the Peltarion Platform this layer is represented by the dense block.A dense layer is the most basic layer of a neural network. The combination of more than 1 of these layers results in the classsical type of neural network or multilayer perceptorn (MLP). They are very flexible in nature and can in general learn almost any mapping from inputs to outputs.Use dense layers to build complete networks that are used for classification or prediction problems on tabular data. You can also use dense layers as the last layer(s) before the convolutional layers or recurrent neural networks. You can read about Dense here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/dense",1
Dimensionality reduction,"Dimensionality reduction is the process of converting your data into a low(er) dimensional representation, while retaining as much information as possible. In practice this implies identifying the features in your dataset that are the most important for the model to achieve the desired objective (a.k.a., the principal variables), and then either discarding or summarizing the remaining features in terms of the principal variables.Dimensionality reduction is useful to ""reduce the amount of unnecessary information"" in your data, which can help speed up model training and in some cases help reduce overfitting.Use dimensionality reduction on datasets that have a large number of features as part of your data preprocessing step. Dimensionality reduction is also used in various embedding techniques.",1
What is Dimensionality reduction,"Dimensionality reduction is the process of converting your data into a low(er) dimensional representation, while retaining as much information as possible. In practice this implies identifying the features in your dataset that are the most important for the model to achieve the desired objective (a.k.a., the principal variables), and then either discarding or summarizing the remaining features in terms of the principal variables.Dimensionality reduction is useful to ""reduce the amount of unnecessary information"" in your data, which can help speed up model training and in some cases help reduce overfitting.Use dimensionality reduction on datasets that have a large number of features as part of your data preprocessing step. Dimensionality reduction is also used in various embedding techniques.",1
Can you help me with Dimensionality reduction,"Dimensionality reduction is the process of converting your data into a low(er) dimensional representation, while retaining as much information as possible. In practice this implies identifying the features in your dataset that are the most important for the model to achieve the desired objective (a.k.a., the principal variables), and then either discarding or summarizing the remaining features in terms of the principal variables.Dimensionality reduction is useful to ""reduce the amount of unnecessary information"" in your data, which can help speed up model training and in some cases help reduce overfitting.Use dimensionality reduction on datasets that have a large number of features as part of your data preprocessing step. Dimensionality reduction is also used in various embedding techniques.",1
What does Dimensionality reduction mean?,"Dimensionality reduction is the process of converting your data into a low(er) dimensional representation, while retaining as much information as possible. In practice this implies identifying the features in your dataset that are the most important for the model to achieve the desired objective (a.k.a., the principal variables), and then either discarding or summarizing the remaining features in terms of the principal variables.Dimensionality reduction is useful to ""reduce the amount of unnecessary information"" in your data, which can help speed up model training and in some cases help reduce overfitting.Use dimensionality reduction on datasets that have a large number of features as part of your data preprocessing step. Dimensionality reduction is also used in various embedding techniques.",1
How do I use Dimensionality reduction?,"Dimensionality reduction is the process of converting your data into a low(er) dimensional representation, while retaining as much information as possible. In practice this implies identifying the features in your dataset that are the most important for the model to achieve the desired objective (a.k.a., the principal variables), and then either discarding or summarizing the remaining features in terms of the principal variables.Dimensionality reduction is useful to ""reduce the amount of unnecessary information"" in your data, which can help speed up model training and in some cases help reduce overfitting.Use dimensionality reduction on datasets that have a large number of features as part of your data preprocessing step. Dimensionality reduction is also used in various embedding techniques.",1
Dropout,Dropout is a regularization technique which randomly zeros out (i.e. “drops out”) some of the weights in a given layer during each training iteration. The effects of this can be interpreted as training different neural networks during each training iteration. The final trained network is thus analogous to the 'average' of all the networks seen during training. You can read about Dropout here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/dropout,1
What is Dropout,Dropout is a regularization technique which randomly zeros out (i.e. “drops out”) some of the weights in a given layer during each training iteration. The effects of this can be interpreted as training different neural networks during each training iteration. The final trained network is thus analogous to the 'average' of all the networks seen during training. You can read about Dropout here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/dropout,1
Can you help me with Dropout,Dropout is a regularization technique which randomly zeros out (i.e. “drops out”) some of the weights in a given layer during each training iteration. The effects of this can be interpreted as training different neural networks during each training iteration. The final trained network is thus analogous to the 'average' of all the networks seen during training. You can read about Dropout here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/dropout,1
What does Dropout mean?,Dropout is a regularization technique which randomly zeros out (i.e. “drops out”) some of the weights in a given layer during each training iteration. The effects of this can be interpreted as training different neural networks during each training iteration. The final trained network is thus analogous to the 'average' of all the networks seen during training. You can read about Dropout here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/dropout,1
How do I use Dropout?,Dropout is a regularization technique which randomly zeros out (i.e. “drops out”) some of the weights in a given layer during each training iteration. The effects of this can be interpreted as training different neural networks during each training iteration. The final trained network is thus analogous to the 'average' of all the networks seen during training. You can read about Dropout here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/dropout,1
Embedding,"Embeddings allow you to turn features into fixed-size vectors of real numbers.
The key aspects of embeddings are that they:Map data to a vector of a given dimensionAre trained so that numerical relationships between embeddings (e.g., Euclidean distance, cosine similarity) express meaningful relationships inside the dataUse an Embedding block to learn embeddings for categorical feature inputs. You can read about Embedding here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/embedding",1
What is Embedding,"Embeddings allow you to turn features into fixed-size vectors of real numbers.
The key aspects of embeddings are that they:Map data to a vector of a given dimensionAre trained so that numerical relationships between embeddings (e.g., Euclidean distance, cosine similarity) express meaningful relationships inside the dataUse an Embedding block to learn embeddings for categorical feature inputs. You can read about Embedding here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/embedding",1
Can you help me with Embedding,"Embeddings allow you to turn features into fixed-size vectors of real numbers.
The key aspects of embeddings are that they:Map data to a vector of a given dimensionAre trained so that numerical relationships between embeddings (e.g., Euclidean distance, cosine similarity) express meaningful relationships inside the dataUse an Embedding block to learn embeddings for categorical feature inputs. You can read about Embedding here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/embedding",1
What does Embedding mean?,"Embeddings allow you to turn features into fixed-size vectors of real numbers.
The key aspects of embeddings are that they:Map data to a vector of a given dimensionAre trained so that numerical relationships between embeddings (e.g., Euclidean distance, cosine similarity) express meaningful relationships inside the dataUse an Embedding block to learn embeddings for categorical feature inputs. You can read about Embedding here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/embedding",1
How do I use Embedding?,"Embeddings allow you to turn features into fixed-size vectors of real numbers.
The key aspects of embeddings are that they:Map data to a vector of a given dimensionAre trained so that numerical relationships between embeddings (e.g., Euclidean distance, cosine similarity) express meaningful relationships inside the dataUse an Embedding block to learn embeddings for categorical feature inputs. You can read about Embedding here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/embedding",1
Epoch,"An epoch represents a full pass over the entire training set, meaning that the model has seen each example once. An epoch is thus the total number of examples / batch size number of training iterations. You can read about Epoch here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model#epoch",1
What is Epoch,"An epoch represents a full pass over the entire training set, meaning that the model has seen each example once. An epoch is thus the total number of examples / batch size number of training iterations. You can read about Epoch here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model#epoch",1
Can you help me with Epoch,"An epoch represents a full pass over the entire training set, meaning that the model has seen each example once. An epoch is thus the total number of examples / batch size number of training iterations. You can read about Epoch here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model#epoch",1
What does Epoch mean?,"An epoch represents a full pass over the entire training set, meaning that the model has seen each example once. An epoch is thus the total number of examples / batch size number of training iterations. You can read about Epoch here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model#epoch",1
How do I use Epoch?,"An epoch represents a full pass over the entire training set, meaning that the model has seen each example once. An epoch is thus the total number of examples / batch size number of training iterations. You can read about Epoch here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model#epoch",1
Error,Error is the numeric value that represents how different the predicted output of your model is when compared to the expected output. It is the essential building block of a loss function. You can read about Error messages  here: https://peltarion.com/knowledge-center/documentation/troubleshooting/error-messages,1
What is Error,Error is the numeric value that represents how different the predicted output of your model is when compared to the expected output. It is the essential building block of a loss function. You can read about Error messages  here: https://peltarion.com/knowledge-center/documentation/troubleshooting/error-messages,1
Can you help me with Error,Error is the numeric value that represents how different the predicted output of your model is when compared to the expected output. It is the essential building block of a loss function. You can read about Error messages  here: https://peltarion.com/knowledge-center/documentation/troubleshooting/error-messages,1
What does Error mean?,Error is the numeric value that represents how different the predicted output of your model is when compared to the expected output. It is the essential building block of a loss function. You can read about Error messages  here: https://peltarion.com/knowledge-center/documentation/troubleshooting/error-messages,1
How do I use Error?,Error is the numeric value that represents how different the predicted output of your model is when compared to the expected output. It is the essential building block of a loss function. You can read about Error messages  here: https://peltarion.com/knowledge-center/documentation/troubleshooting/error-messages,1
Example,"An example is an entry in your dataset which holds values for each of the features of your dataset and possibly a label as well.Usually an example is a row in your datasetAn example specifies what the target should do, given the features. The examples in your dataset should be representative of the data you expect to have available when you deploy the model and which you will use to predict the desired output. You can read about Example: Mood dashboard here: https://peltarion.com/knowledge-center/documentation/cheat-sheets/no-code-ai-/-cheat-sheet#_example_mood_dashboard",1
What is Example,"An example is an entry in your dataset which holds values for each of the features of your dataset and possibly a label as well.Usually an example is a row in your datasetAn example specifies what the target should do, given the features. The examples in your dataset should be representative of the data you expect to have available when you deploy the model and which you will use to predict the desired output. You can read about Example: Mood dashboard here: https://peltarion.com/knowledge-center/documentation/cheat-sheets/no-code-ai-/-cheat-sheet#_example_mood_dashboard",1
Can you help me with Example,"An example is an entry in your dataset which holds values for each of the features of your dataset and possibly a label as well.Usually an example is a row in your datasetAn example specifies what the target should do, given the features. The examples in your dataset should be representative of the data you expect to have available when you deploy the model and which you will use to predict the desired output. You can read about Example: Mood dashboard here: https://peltarion.com/knowledge-center/documentation/cheat-sheets/no-code-ai-/-cheat-sheet#_example_mood_dashboard",1
What does Example mean?,"An example is an entry in your dataset which holds values for each of the features of your dataset and possibly a label as well.Usually an example is a row in your datasetAn example specifies what the target should do, given the features. The examples in your dataset should be representative of the data you expect to have available when you deploy the model and which you will use to predict the desired output. You can read about Example: Mood dashboard here: https://peltarion.com/knowledge-center/documentation/cheat-sheets/no-code-ai-/-cheat-sheet#_example_mood_dashboard",1
How do I use Example?,"An example is an entry in your dataset which holds values for each of the features of your dataset and possibly a label as well.Usually an example is a row in your datasetAn example specifies what the target should do, given the features. The examples in your dataset should be representative of the data you expect to have available when you deploy the model and which you will use to predict the desired output. You can read about Example: Mood dashboard here: https://peltarion.com/knowledge-center/documentation/cheat-sheets/no-code-ai-/-cheat-sheet#_example_mood_dashboard",1
Exploding gradient problem,"The exploding gradient problem is the phenomenon of the gradients calculated by gradient descent progressively accumulating with each training iteration.This means that the weights of the nodes are changed by exponentially growing amounts, making the network become unstable and thus, unable to be trained. The gradient values can become so large that they effectively are unable to be computed, at which point the model crashes.",1
What is Exploding gradient problem,"The exploding gradient problem is the phenomenon of the gradients calculated by gradient descent progressively accumulating with each training iteration.This means that the weights of the nodes are changed by exponentially growing amounts, making the network become unstable and thus, unable to be trained. The gradient values can become so large that they effectively are unable to be computed, at which point the model crashes.",1
Can you help me with Exploding gradient problem,"The exploding gradient problem is the phenomenon of the gradients calculated by gradient descent progressively accumulating with each training iteration.This means that the weights of the nodes are changed by exponentially growing amounts, making the network become unstable and thus, unable to be trained. The gradient values can become so large that they effectively are unable to be computed, at which point the model crashes.",1
What does Exploding gradient problem mean?,"The exploding gradient problem is the phenomenon of the gradients calculated by gradient descent progressively accumulating with each training iteration.This means that the weights of the nodes are changed by exponentially growing amounts, making the network become unstable and thus, unable to be trained. The gradient values can become so large that they effectively are unable to be computed, at which point the model crashes.",1
How do I use Exploding gradient problem?,"The exploding gradient problem is the phenomenon of the gradients calculated by gradient descent progressively accumulating with each training iteration.This means that the weights of the nodes are changed by exponentially growing amounts, making the network become unstable and thus, unable to be trained. The gradient values can become so large that they effectively are unable to be computed, at which point the model crashes.",1
F1-score,"In theory a good model (one that makes the right predictions) will be one that has both high precision, as well as high recall. In practice however, a model has to make compromises between both metrics. Thus, it can be hard to compare the performance between a model with high recall and low precision versus a model with low recall and high precision.F1-score is a metric that summarizes both precision and recall in a single value, by calculating their harmonic mean, which allows it to be used to compare the performance across different models. It's defined as: You can read about Micro F1-score  here: https://peltarion.com/knowledge-center/documentation/evaluation-view/classification-loss-metrics/micro-f1-score",1
What is F1-score,"In theory a good model (one that makes the right predictions) will be one that has both high precision, as well as high recall. In practice however, a model has to make compromises between both metrics. Thus, it can be hard to compare the performance between a model with high recall and low precision versus a model with low recall and high precision.F1-score is a metric that summarizes both precision and recall in a single value, by calculating their harmonic mean, which allows it to be used to compare the performance across different models. It's defined as: You can read about Micro F1-score  here: https://peltarion.com/knowledge-center/documentation/evaluation-view/classification-loss-metrics/micro-f1-score",1
Can you help me with F1-score,"In theory a good model (one that makes the right predictions) will be one that has both high precision, as well as high recall. In practice however, a model has to make compromises between both metrics. Thus, it can be hard to compare the performance between a model with high recall and low precision versus a model with low recall and high precision.F1-score is a metric that summarizes both precision and recall in a single value, by calculating their harmonic mean, which allows it to be used to compare the performance across different models. It's defined as: You can read about Micro F1-score  here: https://peltarion.com/knowledge-center/documentation/evaluation-view/classification-loss-metrics/micro-f1-score",1
What does F1-score mean?,"In theory a good model (one that makes the right predictions) will be one that has both high precision, as well as high recall. In practice however, a model has to make compromises between both metrics. Thus, it can be hard to compare the performance between a model with high recall and low precision versus a model with low recall and high precision.F1-score is a metric that summarizes both precision and recall in a single value, by calculating their harmonic mean, which allows it to be used to compare the performance across different models. It's defined as: You can read about Micro F1-score  here: https://peltarion.com/knowledge-center/documentation/evaluation-view/classification-loss-metrics/micro-f1-score",1
How do I use F1-score?,"In theory a good model (one that makes the right predictions) will be one that has both high precision, as well as high recall. In practice however, a model has to make compromises between both metrics. Thus, it can be hard to compare the performance between a model with high recall and low precision versus a model with low recall and high precision.F1-score is a metric that summarizes both precision and recall in a single value, by calculating their harmonic mean, which allows it to be used to compare the performance across different models. It's defined as: You can read about Micro F1-score  here: https://peltarion.com/knowledge-center/documentation/evaluation-view/classification-loss-metrics/micro-f1-score",1
Fall-out,"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.Fall-out is the proportion of examples of class 'B' that was predicted as class 'A', with respect to all examples of class 'B'. In other words, the higher the value of fall-out, the more examples of class 'B' will be misclassified. It's defined as:",1
What is Fall-out,"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.Fall-out is the proportion of examples of class 'B' that was predicted as class 'A', with respect to all examples of class 'B'. In other words, the higher the value of fall-out, the more examples of class 'B' will be misclassified. It's defined as:",1
Can you help me with Fall-out,"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.Fall-out is the proportion of examples of class 'B' that was predicted as class 'A', with respect to all examples of class 'B'. In other words, the higher the value of fall-out, the more examples of class 'B' will be misclassified. It's defined as:",1
What does Fall-out mean?,"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.Fall-out is the proportion of examples of class 'B' that was predicted as class 'A', with respect to all examples of class 'B'. In other words, the higher the value of fall-out, the more examples of class 'B' will be misclassified. It's defined as:",1
How do I use Fall-out?,"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.Fall-out is the proportion of examples of class 'B' that was predicted as class 'A', with respect to all examples of class 'B'. In other words, the higher the value of fall-out, the more examples of class 'B' will be misclassified. It's defined as:",1
False Negatives (FN),"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.False negatives is a field in the confusion matrix which shows the cases when the actual class of the example was 'A' and the predicted class for the same example was 'B'.",1
What is False Negatives (FN),"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.False negatives is a field in the confusion matrix which shows the cases when the actual class of the example was 'A' and the predicted class for the same example was 'B'.",1
Can you help me with False Negatives (FN),"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.False negatives is a field in the confusion matrix which shows the cases when the actual class of the example was 'A' and the predicted class for the same example was 'B'.",1
What does False Negatives (FN) mean?,"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.False negatives is a field in the confusion matrix which shows the cases when the actual class of the example was 'A' and the predicted class for the same example was 'B'.",1
How do I use False Negatives (FN)?,"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.False negatives is a field in the confusion matrix which shows the cases when the actual class of the example was 'A' and the predicted class for the same example was 'B'.",1
False Positive (FP),"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.False positives is a field in the confusion matrix which shows the cases when the actual class of the example was 'B' and the predicted class for the same example was 'A'.",1
What is False Positive (FP),"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.False positives is a field in the confusion matrix which shows the cases when the actual class of the example was 'B' and the predicted class for the same example was 'A'.",1
Can you help me with False Positive (FP),"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.False positives is a field in the confusion matrix which shows the cases when the actual class of the example was 'B' and the predicted class for the same example was 'A'.",1
What does False Positive (FP) mean?,"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.False positives is a field in the confusion matrix which shows the cases when the actual class of the example was 'B' and the predicted class for the same example was 'A'.",1
How do I use False Positive (FP)?,"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.False positives is a field in the confusion matrix which shows the cases when the actual class of the example was 'B' and the predicted class for the same example was 'A'.",1
False positive rate (FPR),See fall-out.,1
What is False positive rate (FPR),See fall-out.,1
Can you help me with False positive rate (FPR),See fall-out.,1
What does False positive rate (FPR) mean?,See fall-out.,1
How do I use False positive rate (FPR)?,See fall-out.,1
Feature,"A feature is an input variable. In the datasets table view it is represented as a column.Multiple features are usually grouped in a Feature sets.Example:
A house can have the following features: number of rooms (numeric), year built (numeric), neighbourhood (categorical), street name (categorical), etc. You can read about Feature distribution  here: https://peltarion.com/knowledge-center/documentation/datasets-view/edit-an-imported-dataset-for-use-in-experiments/feature-distribution",1
What is Feature,"A feature is an input variable. In the datasets table view it is represented as a column.Multiple features are usually grouped in a Feature sets.Example:
A house can have the following features: number of rooms (numeric), year built (numeric), neighbourhood (categorical), street name (categorical), etc. You can read about Feature distribution  here: https://peltarion.com/knowledge-center/documentation/datasets-view/edit-an-imported-dataset-for-use-in-experiments/feature-distribution",1
Can you help me with Feature,"A feature is an input variable. In the datasets table view it is represented as a column.Multiple features are usually grouped in a Feature sets.Example:
A house can have the following features: number of rooms (numeric), year built (numeric), neighbourhood (categorical), street name (categorical), etc. You can read about Feature distribution  here: https://peltarion.com/knowledge-center/documentation/datasets-view/edit-an-imported-dataset-for-use-in-experiments/feature-distribution",1
What does Feature mean?,"A feature is an input variable. In the datasets table view it is represented as a column.Multiple features are usually grouped in a Feature sets.Example:
A house can have the following features: number of rooms (numeric), year built (numeric), neighbourhood (categorical), street name (categorical), etc. You can read about Feature distribution  here: https://peltarion.com/knowledge-center/documentation/datasets-view/edit-an-imported-dataset-for-use-in-experiments/feature-distribution",1
How do I use Feature?,"A feature is an input variable. In the datasets table view it is represented as a column.Multiple features are usually grouped in a Feature sets.Example:
A house can have the following features: number of rooms (numeric), year built (numeric), neighbourhood (categorical), street name (categorical), etc. You can read about Feature distribution  here: https://peltarion.com/knowledge-center/documentation/datasets-view/edit-an-imported-dataset-for-use-in-experiments/feature-distribution",1
Feature set,A feature set is features bundled together. A feature set is used as input or output in a model. This is a Peltarion specific concept. You can read about Feature set here: https://peltarion.com/knowledge-center/documentation/datasets-view/edit-an-imported-dataset-for-use-in-experiments/dataset-features#_feature_set,1
What is Feature set,A feature set is features bundled together. A feature set is used as input or output in a model. This is a Peltarion specific concept. You can read about Feature set here: https://peltarion.com/knowledge-center/documentation/datasets-view/edit-an-imported-dataset-for-use-in-experiments/dataset-features#_feature_set,1
Can you help me with Feature set,A feature set is features bundled together. A feature set is used as input or output in a model. This is a Peltarion specific concept. You can read about Feature set here: https://peltarion.com/knowledge-center/documentation/datasets-view/edit-an-imported-dataset-for-use-in-experiments/dataset-features#_feature_set,1
What does Feature set mean?,A feature set is features bundled together. A feature set is used as input or output in a model. This is a Peltarion specific concept. You can read about Feature set here: https://peltarion.com/knowledge-center/documentation/datasets-view/edit-an-imported-dataset-for-use-in-experiments/dataset-features#_feature_set,1
How do I use Feature set?,A feature set is features bundled together. A feature set is used as input or output in a model. This is a Peltarion specific concept. You can read about Feature set here: https://peltarion.com/knowledge-center/documentation/datasets-view/edit-an-imported-dataset-for-use-in-experiments/dataset-features#_feature_set,1
Filter (convolution),"Filters are the main component of a convolutional layer. They are the 'windows' that slides over the input data to perform the convolution operation with the data coming into the convolutional layer.Mathematically, the filters are nothing more than a set of weights. What values these weights should take is what the convolutional layer learns during training.",1
What is Filter (convolution),"Filters are the main component of a convolutional layer. They are the 'windows' that slides over the input data to perform the convolution operation with the data coming into the convolutional layer.Mathematically, the filters are nothing more than a set of weights. What values these weights should take is what the convolutional layer learns during training.",1
Can you help me with Filter (convolution),"Filters are the main component of a convolutional layer. They are the 'windows' that slides over the input data to perform the convolution operation with the data coming into the convolutional layer.Mathematically, the filters are nothing more than a set of weights. What values these weights should take is what the convolutional layer learns during training.",1
What does Filter (convolution) mean?,"Filters are the main component of a convolutional layer. They are the 'windows' that slides over the input data to perform the convolution operation with the data coming into the convolutional layer.Mathematically, the filters are nothing more than a set of weights. What values these weights should take is what the convolutional layer learns during training.",1
How do I use Filter (convolution)?,"Filters are the main component of a convolutional layer. They are the 'windows' that slides over the input data to perform the convolution operation with the data coming into the convolutional layer.Mathematically, the filters are nothing more than a set of weights. What values these weights should take is what the convolutional layer learns during training.",1
Generalization,"Generalization is the ability of a model to perform well on data / inputs it has never seen before. The goal of any model is to learn good generalization from the training examples, in order to later on perform well on examples it has never seen before. Generalization can thus be thought of as the notion of how well a model has characterized and encoded the signal found in the training examples.A good indication that a model generalizes well is when the training loss is as small as possible, while at the same time keeping the gap between the training and validation loss as small as possible. The final confirmation that the model has generalized well comes from when the test loss is also low, meaning that the model performs well on never before seen examples.",1
What is Generalization,"Generalization is the ability of a model to perform well on data / inputs it has never seen before. The goal of any model is to learn good generalization from the training examples, in order to later on perform well on examples it has never seen before. Generalization can thus be thought of as the notion of how well a model has characterized and encoded the signal found in the training examples.A good indication that a model generalizes well is when the training loss is as small as possible, while at the same time keeping the gap between the training and validation loss as small as possible. The final confirmation that the model has generalized well comes from when the test loss is also low, meaning that the model performs well on never before seen examples.",1
Can you help me with Generalization,"Generalization is the ability of a model to perform well on data / inputs it has never seen before. The goal of any model is to learn good generalization from the training examples, in order to later on perform well on examples it has never seen before. Generalization can thus be thought of as the notion of how well a model has characterized and encoded the signal found in the training examples.A good indication that a model generalizes well is when the training loss is as small as possible, while at the same time keeping the gap between the training and validation loss as small as possible. The final confirmation that the model has generalized well comes from when the test loss is also low, meaning that the model performs well on never before seen examples.",1
What does Generalization mean?,"Generalization is the ability of a model to perform well on data / inputs it has never seen before. The goal of any model is to learn good generalization from the training examples, in order to later on perform well on examples it has never seen before. Generalization can thus be thought of as the notion of how well a model has characterized and encoded the signal found in the training examples.A good indication that a model generalizes well is when the training loss is as small as possible, while at the same time keeping the gap between the training and validation loss as small as possible. The final confirmation that the model has generalized well comes from when the test loss is also low, meaning that the model performs well on never before seen examples.",1
How do I use Generalization?,"Generalization is the ability of a model to perform well on data / inputs it has never seen before. The goal of any model is to learn good generalization from the training examples, in order to later on perform well on examples it has never seen before. Generalization can thus be thought of as the notion of how well a model has characterized and encoded the signal found in the training examples.A good indication that a model generalizes well is when the training loss is as small as possible, while at the same time keeping the gap between the training and validation loss as small as possible. The final confirmation that the model has generalized well comes from when the test loss is also low, meaning that the model performs well on never before seen examples.",1
Glorot uniform initialization,"Glorot uniform initialization (also known as xavier initialization) is a technique used to initialize the weights of your model by assigning them values from the following unifrom distribution:where ni is the number of units in layer i.Glorot uniform initialization helps keep the variance of the inputs, outputs, activations and gradients the same across all the layers of a network, which helps to prevent that activations and the gradient updates vanish or explode in size.Use glorot uniform intialization with dense layers, convolution layers and LSTM units.",1
What is Glorot uniform initialization,"Glorot uniform initialization (also known as xavier initialization) is a technique used to initialize the weights of your model by assigning them values from the following unifrom distribution:where ni is the number of units in layer i.Glorot uniform initialization helps keep the variance of the inputs, outputs, activations and gradients the same across all the layers of a network, which helps to prevent that activations and the gradient updates vanish or explode in size.Use glorot uniform intialization with dense layers, convolution layers and LSTM units.",1
Can you help me with Glorot uniform initialization,"Glorot uniform initialization (also known as xavier initialization) is a technique used to initialize the weights of your model by assigning them values from the following unifrom distribution:where ni is the number of units in layer i.Glorot uniform initialization helps keep the variance of the inputs, outputs, activations and gradients the same across all the layers of a network, which helps to prevent that activations and the gradient updates vanish or explode in size.Use glorot uniform intialization with dense layers, convolution layers and LSTM units.",1
What does Glorot uniform initialization mean?,"Glorot uniform initialization (also known as xavier initialization) is a technique used to initialize the weights of your model by assigning them values from the following unifrom distribution:where ni is the number of units in layer i.Glorot uniform initialization helps keep the variance of the inputs, outputs, activations and gradients the same across all the layers of a network, which helps to prevent that activations and the gradient updates vanish or explode in size.Use glorot uniform intialization with dense layers, convolution layers and LSTM units.",1
How do I use Glorot uniform initialization?,"Glorot uniform initialization (also known as xavier initialization) is a technique used to initialize the weights of your model by assigning them values from the following unifrom distribution:where ni is the number of units in layer i.Glorot uniform initialization helps keep the variance of the inputs, outputs, activations and gradients the same across all the layers of a network, which helps to prevent that activations and the gradient updates vanish or explode in size.Use glorot uniform intialization with dense layers, convolution layers and LSTM units.",1
Gradient descent,Gradient descent is the basic algorithm used to minimize the loss based on the training set. It's an iterative process through which the parameters of your model are adjusted and thereby gradually finding the best combination to minimize the loss. It does this by computing the gradient (or the 'slope') of the loss function and then 'descending' down it (or taking a step down the 'slope') towards a lower loss value.,1
What is Gradient descent,Gradient descent is the basic algorithm used to minimize the loss based on the training set. It's an iterative process through which the parameters of your model are adjusted and thereby gradually finding the best combination to minimize the loss. It does this by computing the gradient (or the 'slope') of the loss function and then 'descending' down it (or taking a step down the 'slope') towards a lower loss value.,1
Can you help me with Gradient descent,Gradient descent is the basic algorithm used to minimize the loss based on the training set. It's an iterative process through which the parameters of your model are adjusted and thereby gradually finding the best combination to minimize the loss. It does this by computing the gradient (or the 'slope') of the loss function and then 'descending' down it (or taking a step down the 'slope') towards a lower loss value.,1
What does Gradient descent mean?,Gradient descent is the basic algorithm used to minimize the loss based on the training set. It's an iterative process through which the parameters of your model are adjusted and thereby gradually finding the best combination to minimize the loss. It does this by computing the gradient (or the 'slope') of the loss function and then 'descending' down it (or taking a step down the 'slope') towards a lower loss value.,1
How do I use Gradient descent?,Gradient descent is the basic algorithm used to minimize the loss based on the training set. It's an iterative process through which the parameters of your model are adjusted and thereby gradually finding the best combination to minimize the loss. It does this by computing the gradient (or the 'slope') of the loss function and then 'descending' down it (or taking a step down the 'slope') towards a lower loss value.,1
Gradient norm,"Gradient norm indicates how much your model's weights are adjusted during training. If this is high, it means that the weights are being adjusted a lot. If it's low, it indicates that the model might have reached a local optimum.",1
What is Gradient norm,"Gradient norm indicates how much your model's weights are adjusted during training. If this is high, it means that the weights are being adjusted a lot. If it's low, it indicates that the model might have reached a local optimum.",1
Can you help me with Gradient norm,"Gradient norm indicates how much your model's weights are adjusted during training. If this is high, it means that the weights are being adjusted a lot. If it's low, it indicates that the model might have reached a local optimum.",1
What does Gradient norm mean?,"Gradient norm indicates how much your model's weights are adjusted during training. If this is high, it means that the weights are being adjusted a lot. If it's low, it indicates that the model might have reached a local optimum.",1
How do I use Gradient norm?,"Gradient norm indicates how much your model's weights are adjusted during training. If this is high, it means that the weights are being adjusted a lot. If it's low, it indicates that the model might have reached a local optimum.",1
Hidden layer,A hidden layer is any layer in a neural network between the input layer and the target.,1
What is Hidden layer,A hidden layer is any layer in a neural network between the input layer and the target.,1
Can you help me with Hidden layer,A hidden layer is any layer in a neural network between the input layer and the target.,1
What does Hidden layer mean?,A hidden layer is any layer in a neural network between the input layer and the target.,1
How do I use Hidden layer?,A hidden layer is any layer in a neural network between the input layer and the target.,1
Hyperparameter,"A hyperparameter is any parameter of a model or training process that has to be set / fixed before starting the training process, i.e., they are not automatically adjusted during the training. Examples of hyperparameters include: drop rate (dropout), batch size, learning rate, number of layers, number of filters, etc.",1
What is Hyperparameter,"A hyperparameter is any parameter of a model or training process that has to be set / fixed before starting the training process, i.e., they are not automatically adjusted during the training. Examples of hyperparameters include: drop rate (dropout), batch size, learning rate, number of layers, number of filters, etc.",1
Can you help me with Hyperparameter,"A hyperparameter is any parameter of a model or training process that has to be set / fixed before starting the training process, i.e., they are not automatically adjusted during the training. Examples of hyperparameters include: drop rate (dropout), batch size, learning rate, number of layers, number of filters, etc.",1
What does Hyperparameter mean?,"A hyperparameter is any parameter of a model or training process that has to be set / fixed before starting the training process, i.e., they are not automatically adjusted during the training. Examples of hyperparameters include: drop rate (dropout), batch size, learning rate, number of layers, number of filters, etc.",1
How do I use Hyperparameter?,"A hyperparameter is any parameter of a model or training process that has to be set / fixed before starting the training process, i.e., they are not automatically adjusted during the training. Examples of hyperparameters include: drop rate (dropout), batch size, learning rate, number of layers, number of filters, etc.",1
Imbalanced dataset,"An imbalanced dataset is a dataset that contains a very different amount of examples for each of its classes.
Training on such datasets generally leads to biased models, since each class affects the loss proportionally to its frequency.A common way to improve results on infrequent classes is to create a new dataset and balance it by oversampling or undersampling examples.
Class weighting can also be used if the imbalance occurs in a categorical feature which is the model's target; for instance, when learning to identify normal and anomalous classes from a dataset having many more normal examples than abnormal ones.",1
What is Imbalanced dataset,"An imbalanced dataset is a dataset that contains a very different amount of examples for each of its classes.
Training on such datasets generally leads to biased models, since each class affects the loss proportionally to its frequency.A common way to improve results on infrequent classes is to create a new dataset and balance it by oversampling or undersampling examples.
Class weighting can also be used if the imbalance occurs in a categorical feature which is the model's target; for instance, when learning to identify normal and anomalous classes from a dataset having many more normal examples than abnormal ones.",1
Can you help me with Imbalanced dataset,"An imbalanced dataset is a dataset that contains a very different amount of examples for each of its classes.
Training on such datasets generally leads to biased models, since each class affects the loss proportionally to its frequency.A common way to improve results on infrequent classes is to create a new dataset and balance it by oversampling or undersampling examples.
Class weighting can also be used if the imbalance occurs in a categorical feature which is the model's target; for instance, when learning to identify normal and anomalous classes from a dataset having many more normal examples than abnormal ones.",1
What does Imbalanced dataset mean?,"An imbalanced dataset is a dataset that contains a very different amount of examples for each of its classes.
Training on such datasets generally leads to biased models, since each class affects the loss proportionally to its frequency.A common way to improve results on infrequent classes is to create a new dataset and balance it by oversampling or undersampling examples.
Class weighting can also be used if the imbalance occurs in a categorical feature which is the model's target; for instance, when learning to identify normal and anomalous classes from a dataset having many more normal examples than abnormal ones.",1
How do I use Imbalanced dataset?,"An imbalanced dataset is a dataset that contains a very different amount of examples for each of its classes.
Training on such datasets generally leads to biased models, since each class affects the loss proportionally to its frequency.A common way to improve results on infrequent classes is to create a new dataset and balance it by oversampling or undersampling examples.
Class weighting can also be used if the imbalance occurs in a categorical feature which is the model's target; for instance, when learning to identify normal and anomalous classes from a dataset having many more normal examples than abnormal ones.",1
Index,"An index is a table with all embedding vectors from an Output block.
The Output block is used to get values from intermediate layers in a model.With image similarity, you want to compare a new image with all the images you have in your dataset to find the most similar images.First you use a deep learning model to convert each image in your existing dataset into an embedding vector.
You take the vectors from an Output block.
All images' vectors are saved into a large table, the Index.To find similar images to a new image, you transform that image into a vector with the same deep learning model, then you compare that vector with every vector in the index to pick the most similar ones.",1
What is Index,"An index is a table with all embedding vectors from an Output block.
The Output block is used to get values from intermediate layers in a model.With image similarity, you want to compare a new image with all the images you have in your dataset to find the most similar images.First you use a deep learning model to convert each image in your existing dataset into an embedding vector.
You take the vectors from an Output block.
All images' vectors are saved into a large table, the Index.To find similar images to a new image, you transform that image into a vector with the same deep learning model, then you compare that vector with every vector in the index to pick the most similar ones.",1
Can you help me with Index,"An index is a table with all embedding vectors from an Output block.
The Output block is used to get values from intermediate layers in a model.With image similarity, you want to compare a new image with all the images you have in your dataset to find the most similar images.First you use a deep learning model to convert each image in your existing dataset into an embedding vector.
You take the vectors from an Output block.
All images' vectors are saved into a large table, the Index.To find similar images to a new image, you transform that image into a vector with the same deep learning model, then you compare that vector with every vector in the index to pick the most similar ones.",1
What does Index mean?,"An index is a table with all embedding vectors from an Output block.
The Output block is used to get values from intermediate layers in a model.With image similarity, you want to compare a new image with all the images you have in your dataset to find the most similar images.First you use a deep learning model to convert each image in your existing dataset into an embedding vector.
You take the vectors from an Output block.
All images' vectors are saved into a large table, the Index.To find similar images to a new image, you transform that image into a vector with the same deep learning model, then you compare that vector with every vector in the index to pick the most similar ones.",1
How do I use Index?,"An index is a table with all embedding vectors from an Output block.
The Output block is used to get values from intermediate layers in a model.With image similarity, you want to compare a new image with all the images you have in your dataset to find the most similar images.First you use a deep learning model to convert each image in your existing dataset into an embedding vector.
You take the vectors from an Output block.
All images' vectors are saved into a large table, the Index.To find similar images to a new image, you transform that image into a vector with the same deep learning model, then you compare that vector with every vector in the index to pick the most similar ones.",1
Initializer,See weight initialization,1
What is Initializer,See weight initialization,1
Can you help me with Initializer,See weight initialization,1
What does Initializer mean?,See weight initialization,1
How do I use Initializer?,See weight initialization,1
Input,Input is the series of examples fed to a layer. You can read about Input data here: https://peltarion.com/knowledge-center/documentation/deployment-view/deploy-to-api-limitations#_input_data,1
What is Input,Input is the series of examples fed to a layer. You can read about Input data here: https://peltarion.com/knowledge-center/documentation/deployment-view/deploy-to-api-limitations#_input_data,1
Can you help me with Input,Input is the series of examples fed to a layer. You can read about Input data here: https://peltarion.com/knowledge-center/documentation/deployment-view/deploy-to-api-limitations#_input_data,1
What does Input mean?,Input is the series of examples fed to a layer. You can read about Input data here: https://peltarion.com/knowledge-center/documentation/deployment-view/deploy-to-api-limitations#_input_data,1
How do I use Input?,Input is the series of examples fed to a layer. You can read about Input data here: https://peltarion.com/knowledge-center/documentation/deployment-view/deploy-to-api-limitations#_input_data,1
Input layer,"The input layer is the first layer of a neural network and is the one which take the individual examples of your training set as input to the model. On the Peltarion Platform this layer is represented by the Input block. You can think of the Input block as a 'placeholder' for the data that is going to be fed into the model.All your models will need an input layer (i.e.,Input block). You can read about Input here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/input",1
What is Input layer,"The input layer is the first layer of a neural network and is the one which take the individual examples of your training set as input to the model. On the Peltarion Platform this layer is represented by the Input block. You can think of the Input block as a 'placeholder' for the data that is going to be fed into the model.All your models will need an input layer (i.e.,Input block). You can read about Input here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/input",1
Can you help me with Input layer,"The input layer is the first layer of a neural network and is the one which take the individual examples of your training set as input to the model. On the Peltarion Platform this layer is represented by the Input block. You can think of the Input block as a 'placeholder' for the data that is going to be fed into the model.All your models will need an input layer (i.e.,Input block). You can read about Input here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/input",1
What does Input layer mean?,"The input layer is the first layer of a neural network and is the one which take the individual examples of your training set as input to the model. On the Peltarion Platform this layer is represented by the Input block. You can think of the Input block as a 'placeholder' for the data that is going to be fed into the model.All your models will need an input layer (i.e.,Input block). You can read about Input here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/input",1
How do I use Input layer?,"The input layer is the first layer of a neural network and is the one which take the individual examples of your training set as input to the model. On the Peltarion Platform this layer is represented by the Input block. You can think of the Input block as a 'placeholder' for the data that is going to be fed into the model.All your models will need an input layer (i.e.,Input block). You can read about Input here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/input",1
Kernel (convolution),See filter (convolution),1
What is Kernel (convolution),See filter (convolution),1
Can you help me with Kernel (convolution),See filter (convolution),1
What does Kernel (convolution) mean?,See filter (convolution),1
How do I use Kernel (convolution)?,See filter (convolution),1
Label,"A label is a class (in classification) or a target (in regression) assigned to examples in a dataset. When training a model, labels are how you say what you want them to predict. For example, in image classification: ""See an apple, say 'apple'""",1
What is Label,"A label is a class (in classification) or a target (in regression) assigned to examples in a dataset. When training a model, labels are how you say what you want them to predict. For example, in image classification: ""See an apple, say 'apple'""",1
Can you help me with Label,"A label is a class (in classification) or a target (in regression) assigned to examples in a dataset. When training a model, labels are how you say what you want them to predict. For example, in image classification: ""See an apple, say 'apple'""",1
What does Label mean?,"A label is a class (in classification) or a target (in regression) assigned to examples in a dataset. When training a model, labels are how you say what you want them to predict. For example, in image classification: ""See an apple, say 'apple'""",1
How do I use Label?,"A label is a class (in classification) or a target (in regression) assigned to examples in a dataset. When training a model, labels are how you say what you want them to predict. For example, in image classification: ""See an apple, say 'apple'""",1
Learning,"Learning, in the context of deep learning, is the process of automatically setting (i.e. learning) a model for a specific dataset through the use of statistical and mathematical optimization techniques. You can read about Learning rate schedule here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/optimization-principles-(in-deep-learning)/learning-rate-schedule",1
What is Learning,"Learning, in the context of deep learning, is the process of automatically setting (i.e. learning) a model for a specific dataset through the use of statistical and mathematical optimization techniques. You can read about Learning rate schedule here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/optimization-principles-(in-deep-learning)/learning-rate-schedule",1
Can you help me with Learning,"Learning, in the context of deep learning, is the process of automatically setting (i.e. learning) a model for a specific dataset through the use of statistical and mathematical optimization techniques. You can read about Learning rate schedule here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/optimization-principles-(in-deep-learning)/learning-rate-schedule",1
What does Learning mean?,"Learning, in the context of deep learning, is the process of automatically setting (i.e. learning) a model for a specific dataset through the use of statistical and mathematical optimization techniques. You can read about Learning rate schedule here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/optimization-principles-(in-deep-learning)/learning-rate-schedule",1
How do I use Learning?,"Learning, in the context of deep learning, is the process of automatically setting (i.e. learning) a model for a specific dataset through the use of statistical and mathematical optimization techniques. You can read about Learning rate schedule here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/optimization-principles-(in-deep-learning)/learning-rate-schedule",1
Learning rate,"The learning rate is a hyperparameter of gradient descent. It's a scalar which controls the size of the update steps along the gradient.Choosing the right learning rate is crucial for optimal gradient descent and thus, for optimal training. Too small and gradient descent will only take small steps in each iteration, meaning model training will be slow. Too big and gradient descent will take too large of a step, potentially ending up 'bouncing around' the loss surface, making training unstable. You can read about Learning rate schedule here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/optimization-principles-(in-deep-learning)/learning-rate-schedule",1
What is Learning rate,"The learning rate is a hyperparameter of gradient descent. It's a scalar which controls the size of the update steps along the gradient.Choosing the right learning rate is crucial for optimal gradient descent and thus, for optimal training. Too small and gradient descent will only take small steps in each iteration, meaning model training will be slow. Too big and gradient descent will take too large of a step, potentially ending up 'bouncing around' the loss surface, making training unstable. You can read about Learning rate schedule here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/optimization-principles-(in-deep-learning)/learning-rate-schedule",1
Can you help me with Learning rate,"The learning rate is a hyperparameter of gradient descent. It's a scalar which controls the size of the update steps along the gradient.Choosing the right learning rate is crucial for optimal gradient descent and thus, for optimal training. Too small and gradient descent will only take small steps in each iteration, meaning model training will be slow. Too big and gradient descent will take too large of a step, potentially ending up 'bouncing around' the loss surface, making training unstable. You can read about Learning rate schedule here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/optimization-principles-(in-deep-learning)/learning-rate-schedule",1
What does Learning rate mean?,"The learning rate is a hyperparameter of gradient descent. It's a scalar which controls the size of the update steps along the gradient.Choosing the right learning rate is crucial for optimal gradient descent and thus, for optimal training. Too small and gradient descent will only take small steps in each iteration, meaning model training will be slow. Too big and gradient descent will take too large of a step, potentially ending up 'bouncing around' the loss surface, making training unstable. You can read about Learning rate schedule here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/optimization-principles-(in-deep-learning)/learning-rate-schedule",1
How do I use Learning rate?,"The learning rate is a hyperparameter of gradient descent. It's a scalar which controls the size of the update steps along the gradient.Choosing the right learning rate is crucial for optimal gradient descent and thus, for optimal training. Too small and gradient descent will only take small steps in each iteration, meaning model training will be slow. Too big and gradient descent will take too large of a step, potentially ending up 'bouncing around' the loss surface, making training unstable. You can read about Learning rate schedule here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/optimization-principles-(in-deep-learning)/learning-rate-schedule",1
Linear activation function,"The linear activation_function is a straight line function where the node's activation is proportional to the input.Use in the last layer of a regression model, if the output variable does not have known upper and lower bounds.Range: -∞ to +∞ You can read about Linear here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/activations/linear",1
What is Linear activation function,"The linear activation_function is a straight line function where the node's activation is proportional to the input.Use in the last layer of a regression model, if the output variable does not have known upper and lower bounds.Range: -∞ to +∞ You can read about Linear here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/activations/linear",1
Can you help me with Linear activation function,"The linear activation_function is a straight line function where the node's activation is proportional to the input.Use in the last layer of a regression model, if the output variable does not have known upper and lower bounds.Range: -∞ to +∞ You can read about Linear here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/activations/linear",1
What does Linear activation function mean?,"The linear activation_function is a straight line function where the node's activation is proportional to the input.Use in the last layer of a regression model, if the output variable does not have known upper and lower bounds.Range: -∞ to +∞ You can read about Linear here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/activations/linear",1
How do I use Linear activation function?,"The linear activation_function is a straight line function where the node's activation is proportional to the input.Use in the last layer of a regression model, if the output variable does not have known upper and lower bounds.Range: -∞ to +∞ You can read about Linear here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/activations/linear",1
Loss,"Loss is a measure of how well your algorithm models your dataset. It's a numeric value which is computed by the loss function. The lower the loss, the better the performance of your model. You can read about First evaluation - A low Loss is good here: https://peltarion.com/knowledge-center/documentation/improve-experiments/tips-to-improve-for-beginners#_first_evaluation_a_low_loss_is_good",1
What is Loss,"Loss is a measure of how well your algorithm models your dataset. It's a numeric value which is computed by the loss function. The lower the loss, the better the performance of your model. You can read about First evaluation - A low Loss is good here: https://peltarion.com/knowledge-center/documentation/improve-experiments/tips-to-improve-for-beginners#_first_evaluation_a_low_loss_is_good",1
Can you help me with Loss,"Loss is a measure of how well your algorithm models your dataset. It's a numeric value which is computed by the loss function. The lower the loss, the better the performance of your model. You can read about First evaluation - A low Loss is good here: https://peltarion.com/knowledge-center/documentation/improve-experiments/tips-to-improve-for-beginners#_first_evaluation_a_low_loss_is_good",1
What does Loss mean?,"Loss is a measure of how well your algorithm models your dataset. It's a numeric value which is computed by the loss function. The lower the loss, the better the performance of your model. You can read about First evaluation - A low Loss is good here: https://peltarion.com/knowledge-center/documentation/improve-experiments/tips-to-improve-for-beginners#_first_evaluation_a_low_loss_is_good",1
How do I use Loss?,"Loss is a measure of how well your algorithm models your dataset. It's a numeric value which is computed by the loss function. The lower the loss, the better the performance of your model. You can read about First evaluation - A low Loss is good here: https://peltarion.com/knowledge-center/documentation/improve-experiments/tips-to-improve-for-beginners#_first_evaluation_a_low_loss_is_good",1
Loss function,A loss function is a function that determines how errors are penalized. The goal of the loss function is to capture in a single number the total amount of errors across all training example. You can read about Loss functions  here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions,1
What is Loss function,A loss function is a function that determines how errors are penalized. The goal of the loss function is to capture in a single number the total amount of errors across all training example. You can read about Loss functions  here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions,1
Can you help me with Loss function,A loss function is a function that determines how errors are penalized. The goal of the loss function is to capture in a single number the total amount of errors across all training example. You can read about Loss functions  here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions,1
What does Loss function mean?,A loss function is a function that determines how errors are penalized. The goal of the loss function is to capture in a single number the total amount of errors across all training example. You can read about Loss functions  here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions,1
How do I use Loss function?,A loss function is a function that determines how errors are penalized. The goal of the loss function is to capture in a single number the total amount of errors across all training example. You can read about Loss functions  here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions,1
LSTM unit,"A long short term memory unit is a special kind of recurrent neural network building block that has a build in ability to 'remember' or 'forget' parts of sequential data. This ability allows a RNN using LSTM units to learn very long range connections in sequential data, by keeping relevant information 'stored' in the unit.Use in recurrent neural networks.",1
What is LSTM unit,"A long short term memory unit is a special kind of recurrent neural network building block that has a build in ability to 'remember' or 'forget' parts of sequential data. This ability allows a RNN using LSTM units to learn very long range connections in sequential data, by keeping relevant information 'stored' in the unit.Use in recurrent neural networks.",1
Can you help me with LSTM unit,"A long short term memory unit is a special kind of recurrent neural network building block that has a build in ability to 'remember' or 'forget' parts of sequential data. This ability allows a RNN using LSTM units to learn very long range connections in sequential data, by keeping relevant information 'stored' in the unit.Use in recurrent neural networks.",1
What does LSTM unit mean?,"A long short term memory unit is a special kind of recurrent neural network building block that has a build in ability to 'remember' or 'forget' parts of sequential data. This ability allows a RNN using LSTM units to learn very long range connections in sequential data, by keeping relevant information 'stored' in the unit.Use in recurrent neural networks.",1
How do I use LSTM unit?,"A long short term memory unit is a special kind of recurrent neural network building block that has a build in ability to 'remember' or 'forget' parts of sequential data. This ability allows a RNN using LSTM units to learn very long range connections in sequential data, by keeping relevant information 'stored' in the unit.Use in recurrent neural networks.",1
Mean absolute error (MAE),"Mean absolute error (MAE) is a loss function used for regression. The loss is the mean over seen data of the absolute differences between true and predicted values, or writing it a a formula:where ŷ is the predicted expected value and y is the observed value.MAE is not sensitive towards outliers and given several examples with the same input feature values, the optimal prediction will be their median target value. This should be compared with mean squared error, where the optimal prediction is the mean. A disadvantage of MAE is that the gradient magnitude is not dependent on the error size, only on the sign of yi - ŷi. This leads to that the gradient magnitude will be large even when the error is small, which in turn can lead to convergence problems.Use mean absolute error when you are doing regression and don't want outliers to play a big role. It can also be useful if you know that your distribution is multimodal, and it's desirable to have predictions at one of the modes, rather than at the mean of them. MAE is can also be used as a performance metric, since it's easy to interpret. You can read about Mean absolute error here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/mean-absolute-error",1
What is Mean absolute error (MAE),"Mean absolute error (MAE) is a loss function used for regression. The loss is the mean over seen data of the absolute differences between true and predicted values, or writing it a a formula:where ŷ is the predicted expected value and y is the observed value.MAE is not sensitive towards outliers and given several examples with the same input feature values, the optimal prediction will be their median target value. This should be compared with mean squared error, where the optimal prediction is the mean. A disadvantage of MAE is that the gradient magnitude is not dependent on the error size, only on the sign of yi - ŷi. This leads to that the gradient magnitude will be large even when the error is small, which in turn can lead to convergence problems.Use mean absolute error when you are doing regression and don't want outliers to play a big role. It can also be useful if you know that your distribution is multimodal, and it's desirable to have predictions at one of the modes, rather than at the mean of them. MAE is can also be used as a performance metric, since it's easy to interpret. You can read about Mean absolute error here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/mean-absolute-error",1
Can you help me with Mean absolute error (MAE),"Mean absolute error (MAE) is a loss function used for regression. The loss is the mean over seen data of the absolute differences between true and predicted values, or writing it a a formula:where ŷ is the predicted expected value and y is the observed value.MAE is not sensitive towards outliers and given several examples with the same input feature values, the optimal prediction will be their median target value. This should be compared with mean squared error, where the optimal prediction is the mean. A disadvantage of MAE is that the gradient magnitude is not dependent on the error size, only on the sign of yi - ŷi. This leads to that the gradient magnitude will be large even when the error is small, which in turn can lead to convergence problems.Use mean absolute error when you are doing regression and don't want outliers to play a big role. It can also be useful if you know that your distribution is multimodal, and it's desirable to have predictions at one of the modes, rather than at the mean of them. MAE is can also be used as a performance metric, since it's easy to interpret. You can read about Mean absolute error here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/mean-absolute-error",1
What does Mean absolute error (MAE) mean?,"Mean absolute error (MAE) is a loss function used for regression. The loss is the mean over seen data of the absolute differences between true and predicted values, or writing it a a formula:where ŷ is the predicted expected value and y is the observed value.MAE is not sensitive towards outliers and given several examples with the same input feature values, the optimal prediction will be their median target value. This should be compared with mean squared error, where the optimal prediction is the mean. A disadvantage of MAE is that the gradient magnitude is not dependent on the error size, only on the sign of yi - ŷi. This leads to that the gradient magnitude will be large even when the error is small, which in turn can lead to convergence problems.Use mean absolute error when you are doing regression and don't want outliers to play a big role. It can also be useful if you know that your distribution is multimodal, and it's desirable to have predictions at one of the modes, rather than at the mean of them. MAE is can also be used as a performance metric, since it's easy to interpret. You can read about Mean absolute error here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/mean-absolute-error",1
How do I use Mean absolute error (MAE)?,"Mean absolute error (MAE) is a loss function used for regression. The loss is the mean over seen data of the absolute differences between true and predicted values, or writing it a a formula:where ŷ is the predicted expected value and y is the observed value.MAE is not sensitive towards outliers and given several examples with the same input feature values, the optimal prediction will be their median target value. This should be compared with mean squared error, where the optimal prediction is the mean. A disadvantage of MAE is that the gradient magnitude is not dependent on the error size, only on the sign of yi - ŷi. This leads to that the gradient magnitude will be large even when the error is small, which in turn can lead to convergence problems.Use mean absolute error when you are doing regression and don't want outliers to play a big role. It can also be useful if you know that your distribution is multimodal, and it's desirable to have predictions at one of the modes, rather than at the mean of them. MAE is can also be used as a performance metric, since it's easy to interpret. You can read about Mean absolute error here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/mean-absolute-error",1
Mean squared error (MSE),"Mean squared error (MSE) is the most commonly used loss function for regression. The loss is the mean over seen data of the squared differences between true and predicted values, or writing it as a formula:where ŷ is the predicted expected value and y is the observed value.Minimizing MSE is equivalent of maximizing the likelihood of the data under the assumption that the target comes from a normal distribution, conditioned on the input.MSE is sensitive towards outliers and given several examples with the same input feature values, the optimal prediction will be their mean target value. This should be compared with mean absolute error, where the optimal prediction is the median. MSE is thus good to use if you believe that your target data, conditioned on the input, is normally distributed around a mean value, and when it's important to penalize outliers extra much.Use MSE when doing regression, believing that your target, conditioned on the input, is normally distributed, and want large errors to be significantly (quadratically) more penalized than small ones. You can read about Mean squared error here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/mean-squared-error",1
What is Mean squared error (MSE),"Mean squared error (MSE) is the most commonly used loss function for regression. The loss is the mean over seen data of the squared differences between true and predicted values, or writing it as a formula:where ŷ is the predicted expected value and y is the observed value.Minimizing MSE is equivalent of maximizing the likelihood of the data under the assumption that the target comes from a normal distribution, conditioned on the input.MSE is sensitive towards outliers and given several examples with the same input feature values, the optimal prediction will be their mean target value. This should be compared with mean absolute error, where the optimal prediction is the median. MSE is thus good to use if you believe that your target data, conditioned on the input, is normally distributed around a mean value, and when it's important to penalize outliers extra much.Use MSE when doing regression, believing that your target, conditioned on the input, is normally distributed, and want large errors to be significantly (quadratically) more penalized than small ones. You can read about Mean squared error here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/mean-squared-error",1
Can you help me with Mean squared error (MSE),"Mean squared error (MSE) is the most commonly used loss function for regression. The loss is the mean over seen data of the squared differences between true and predicted values, or writing it as a formula:where ŷ is the predicted expected value and y is the observed value.Minimizing MSE is equivalent of maximizing the likelihood of the data under the assumption that the target comes from a normal distribution, conditioned on the input.MSE is sensitive towards outliers and given several examples with the same input feature values, the optimal prediction will be their mean target value. This should be compared with mean absolute error, where the optimal prediction is the median. MSE is thus good to use if you believe that your target data, conditioned on the input, is normally distributed around a mean value, and when it's important to penalize outliers extra much.Use MSE when doing regression, believing that your target, conditioned on the input, is normally distributed, and want large errors to be significantly (quadratically) more penalized than small ones. You can read about Mean squared error here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/mean-squared-error",1
What does Mean squared error (MSE) mean?,"Mean squared error (MSE) is the most commonly used loss function for regression. The loss is the mean over seen data of the squared differences between true and predicted values, or writing it as a formula:where ŷ is the predicted expected value and y is the observed value.Minimizing MSE is equivalent of maximizing the likelihood of the data under the assumption that the target comes from a normal distribution, conditioned on the input.MSE is sensitive towards outliers and given several examples with the same input feature values, the optimal prediction will be their mean target value. This should be compared with mean absolute error, where the optimal prediction is the median. MSE is thus good to use if you believe that your target data, conditioned on the input, is normally distributed around a mean value, and when it's important to penalize outliers extra much.Use MSE when doing regression, believing that your target, conditioned on the input, is normally distributed, and want large errors to be significantly (quadratically) more penalized than small ones. You can read about Mean squared error here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/mean-squared-error",1
How do I use Mean squared error (MSE)?,"Mean squared error (MSE) is the most commonly used loss function for regression. The loss is the mean over seen data of the squared differences between true and predicted values, or writing it as a formula:where ŷ is the predicted expected value and y is the observed value.Minimizing MSE is equivalent of maximizing the likelihood of the data under the assumption that the target comes from a normal distribution, conditioned on the input.MSE is sensitive towards outliers and given several examples with the same input feature values, the optimal prediction will be their mean target value. This should be compared with mean absolute error, where the optimal prediction is the median. MSE is thus good to use if you believe that your target data, conditioned on the input, is normally distributed around a mean value, and when it's important to penalize outliers extra much.Use MSE when doing regression, believing that your target, conditioned on the input, is normally distributed, and want large errors to be significantly (quadratically) more penalized than small ones. You can read about Mean squared error here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/mean-squared-error",1
Mean squared logarithmic error (MSLE),"Mean squared logarithmic error (MSLE) is, as the name suggests, a variation of the Mean Squared Error. The loss is the mean over the seen data of the squared differences between the log-transformed true and predicted values, or writing it as a formula:where ŷ is the predicted expected value and y is the observed value.This loss can be interpreted as a measure of the ratio between the true and predicted values, since:The introduction of the logarithm makes MSLE only care about the relative difference between the real and the predicted value, or in other words, it only cares about the porcentual difference between them. This means that MSLE will treat small differences between small true and predicted values approximately the same as big differences between large true and predicted values. MSLE also penalizes underestimates more than overestimates, introducing an asymmetry in the error curve.Use MSLE when doing regression, believing that your target, conditioned on the input, is normally distributed, and you don't want large errors to be significantly more penalized than small ones, in those cases where the range of the target value is large. You can read about Mean squared logarithmic error (MSLE) here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/mean-squared-logarithmic-error-(msle)",1
What is Mean squared logarithmic error (MSLE),"Mean squared logarithmic error (MSLE) is, as the name suggests, a variation of the Mean Squared Error. The loss is the mean over the seen data of the squared differences between the log-transformed true and predicted values, or writing it as a formula:where ŷ is the predicted expected value and y is the observed value.This loss can be interpreted as a measure of the ratio between the true and predicted values, since:The introduction of the logarithm makes MSLE only care about the relative difference between the real and the predicted value, or in other words, it only cares about the porcentual difference between them. This means that MSLE will treat small differences between small true and predicted values approximately the same as big differences between large true and predicted values. MSLE also penalizes underestimates more than overestimates, introducing an asymmetry in the error curve.Use MSLE when doing regression, believing that your target, conditioned on the input, is normally distributed, and you don't want large errors to be significantly more penalized than small ones, in those cases where the range of the target value is large. You can read about Mean squared logarithmic error (MSLE) here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/mean-squared-logarithmic-error-(msle)",1
Can you help me with Mean squared logarithmic error (MSLE),"Mean squared logarithmic error (MSLE) is, as the name suggests, a variation of the Mean Squared Error. The loss is the mean over the seen data of the squared differences between the log-transformed true and predicted values, or writing it as a formula:where ŷ is the predicted expected value and y is the observed value.This loss can be interpreted as a measure of the ratio between the true and predicted values, since:The introduction of the logarithm makes MSLE only care about the relative difference between the real and the predicted value, or in other words, it only cares about the porcentual difference between them. This means that MSLE will treat small differences between small true and predicted values approximately the same as big differences between large true and predicted values. MSLE also penalizes underestimates more than overestimates, introducing an asymmetry in the error curve.Use MSLE when doing regression, believing that your target, conditioned on the input, is normally distributed, and you don't want large errors to be significantly more penalized than small ones, in those cases where the range of the target value is large. You can read about Mean squared logarithmic error (MSLE) here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/mean-squared-logarithmic-error-(msle)",1
What does Mean squared logarithmic error (MSLE) mean?,"Mean squared logarithmic error (MSLE) is, as the name suggests, a variation of the Mean Squared Error. The loss is the mean over the seen data of the squared differences between the log-transformed true and predicted values, or writing it as a formula:where ŷ is the predicted expected value and y is the observed value.This loss can be interpreted as a measure of the ratio between the true and predicted values, since:The introduction of the logarithm makes MSLE only care about the relative difference between the real and the predicted value, or in other words, it only cares about the porcentual difference between them. This means that MSLE will treat small differences between small true and predicted values approximately the same as big differences between large true and predicted values. MSLE also penalizes underestimates more than overestimates, introducing an asymmetry in the error curve.Use MSLE when doing regression, believing that your target, conditioned on the input, is normally distributed, and you don't want large errors to be significantly more penalized than small ones, in those cases where the range of the target value is large. You can read about Mean squared logarithmic error (MSLE) here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/mean-squared-logarithmic-error-(msle)",1
How do I use Mean squared logarithmic error (MSLE)?,"Mean squared logarithmic error (MSLE) is, as the name suggests, a variation of the Mean Squared Error. The loss is the mean over the seen data of the squared differences between the log-transformed true and predicted values, or writing it as a formula:where ŷ is the predicted expected value and y is the observed value.This loss can be interpreted as a measure of the ratio between the true and predicted values, since:The introduction of the logarithm makes MSLE only care about the relative difference between the real and the predicted value, or in other words, it only cares about the porcentual difference between them. This means that MSLE will treat small differences between small true and predicted values approximately the same as big differences between large true and predicted values. MSLE also penalizes underestimates more than overestimates, introducing an asymmetry in the error curve.Use MSLE when doing regression, believing that your target, conditioned on the input, is normally distributed, and you don't want large errors to be significantly more penalized than small ones, in those cases where the range of the target value is large. You can read about Mean squared logarithmic error (MSLE) here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/mean-squared-logarithmic-error-(msle)",1
Min-Max Normalization,"Min-max normalization performs a linear rescaling of your data. It transforms the lowest value of an input feature to 0, and the highest value 1. Every other value in between the min and max values is transformed to a decimal between 0 and 1.Applied across your Combined feature, it will guarantee that all values are between 0 and 1, which makes it easier for a network to train since all the values are within the same range. It's also a computationally efficient way to normalize your features when they have a bounded range of values and when they don't have large outliers.Use min-max normalization to normalize your data when it's bounded (e.g., pixel values in an image) and when it doesn't contain any large outliers. (If your dataset has large outliers use standardization instead). You can read about Normalization here: https://peltarion.com/knowledge-center/documentation/datasets-view/edit-an-imported-dataset-for-use-in-experiments/feature-encoding/normalization",1
What is Min-Max Normalization,"Min-max normalization performs a linear rescaling of your data. It transforms the lowest value of an input feature to 0, and the highest value 1. Every other value in between the min and max values is transformed to a decimal between 0 and 1.Applied across your Combined feature, it will guarantee that all values are between 0 and 1, which makes it easier for a network to train since all the values are within the same range. It's also a computationally efficient way to normalize your features when they have a bounded range of values and when they don't have large outliers.Use min-max normalization to normalize your data when it's bounded (e.g., pixel values in an image) and when it doesn't contain any large outliers. (If your dataset has large outliers use standardization instead). You can read about Normalization here: https://peltarion.com/knowledge-center/documentation/datasets-view/edit-an-imported-dataset-for-use-in-experiments/feature-encoding/normalization",1
Can you help me with Min-Max Normalization,"Min-max normalization performs a linear rescaling of your data. It transforms the lowest value of an input feature to 0, and the highest value 1. Every other value in between the min and max values is transformed to a decimal between 0 and 1.Applied across your Combined feature, it will guarantee that all values are between 0 and 1, which makes it easier for a network to train since all the values are within the same range. It's also a computationally efficient way to normalize your features when they have a bounded range of values and when they don't have large outliers.Use min-max normalization to normalize your data when it's bounded (e.g., pixel values in an image) and when it doesn't contain any large outliers. (If your dataset has large outliers use standardization instead). You can read about Normalization here: https://peltarion.com/knowledge-center/documentation/datasets-view/edit-an-imported-dataset-for-use-in-experiments/feature-encoding/normalization",1
What does Min-Max Normalization mean?,"Min-max normalization performs a linear rescaling of your data. It transforms the lowest value of an input feature to 0, and the highest value 1. Every other value in between the min and max values is transformed to a decimal between 0 and 1.Applied across your Combined feature, it will guarantee that all values are between 0 and 1, which makes it easier for a network to train since all the values are within the same range. It's also a computationally efficient way to normalize your features when they have a bounded range of values and when they don't have large outliers.Use min-max normalization to normalize your data when it's bounded (e.g., pixel values in an image) and when it doesn't contain any large outliers. (If your dataset has large outliers use standardization instead). You can read about Normalization here: https://peltarion.com/knowledge-center/documentation/datasets-view/edit-an-imported-dataset-for-use-in-experiments/feature-encoding/normalization",1
How do I use Min-Max Normalization?,"Min-max normalization performs a linear rescaling of your data. It transforms the lowest value of an input feature to 0, and the highest value 1. Every other value in between the min and max values is transformed to a decimal between 0 and 1.Applied across your Combined feature, it will guarantee that all values are between 0 and 1, which makes it easier for a network to train since all the values are within the same range. It's also a computationally efficient way to normalize your features when they have a bounded range of values and when they don't have large outliers.Use min-max normalization to normalize your data when it's bounded (e.g., pixel values in an image) and when it doesn't contain any large outliers. (If your dataset has large outliers use standardization instead). You can read about Normalization here: https://peltarion.com/knowledge-center/documentation/datasets-view/edit-an-imported-dataset-for-use-in-experiments/feature-encoding/normalization",1
Mini-batch,A batch can be subdivided into smaller mini-batches.Mini-batches are used as a way to speed up gradient descent through mini-batch gradient descent.,1
What is Mini-batch,A batch can be subdivided into smaller mini-batches.Mini-batches are used as a way to speed up gradient descent through mini-batch gradient descent.,1
Can you help me with Mini-batch,A batch can be subdivided into smaller mini-batches.Mini-batches are used as a way to speed up gradient descent through mini-batch gradient descent.,1
What does Mini-batch mean?,A batch can be subdivided into smaller mini-batches.Mini-batches are used as a way to speed up gradient descent through mini-batch gradient descent.,1
How do I use Mini-batch?,A batch can be subdivided into smaller mini-batches.Mini-batches are used as a way to speed up gradient descent through mini-batch gradient descent.,1
Mini-batch (stochastic) gradient descent,"Mini-batch gradient descent is an implementation of gradient descent which approximates the real gradient of the loss function, which is computed by taking into account all the training examples, with an approximated gradient, which is calculated by iteratively taking into account all the training examples in a mini-batch, until it has gone through all mini-batches.Mini-batch gradient descent tries to take the best of batch gradient descent and stochastic gradient descent. It's much faster than batch gradient descent, but avoids the extreme fluctuations in the parameter updates of SGD (i.e., it's more stable than SGD), thus making model training faster without any significant downsides.Mini-batch gradient descent is the algorithm of choice for training deep learning models.",1
What is Mini-batch (stochastic) gradient descent,"Mini-batch gradient descent is an implementation of gradient descent which approximates the real gradient of the loss function, which is computed by taking into account all the training examples, with an approximated gradient, which is calculated by iteratively taking into account all the training examples in a mini-batch, until it has gone through all mini-batches.Mini-batch gradient descent tries to take the best of batch gradient descent and stochastic gradient descent. It's much faster than batch gradient descent, but avoids the extreme fluctuations in the parameter updates of SGD (i.e., it's more stable than SGD), thus making model training faster without any significant downsides.Mini-batch gradient descent is the algorithm of choice for training deep learning models.",1
Can you help me with Mini-batch (stochastic) gradient descent,"Mini-batch gradient descent is an implementation of gradient descent which approximates the real gradient of the loss function, which is computed by taking into account all the training examples, with an approximated gradient, which is calculated by iteratively taking into account all the training examples in a mini-batch, until it has gone through all mini-batches.Mini-batch gradient descent tries to take the best of batch gradient descent and stochastic gradient descent. It's much faster than batch gradient descent, but avoids the extreme fluctuations in the parameter updates of SGD (i.e., it's more stable than SGD), thus making model training faster without any significant downsides.Mini-batch gradient descent is the algorithm of choice for training deep learning models.",1
What does Mini-batch (stochastic) gradient descent mean?,"Mini-batch gradient descent is an implementation of gradient descent which approximates the real gradient of the loss function, which is computed by taking into account all the training examples, with an approximated gradient, which is calculated by iteratively taking into account all the training examples in a mini-batch, until it has gone through all mini-batches.Mini-batch gradient descent tries to take the best of batch gradient descent and stochastic gradient descent. It's much faster than batch gradient descent, but avoids the extreme fluctuations in the parameter updates of SGD (i.e., it's more stable than SGD), thus making model training faster without any significant downsides.Mini-batch gradient descent is the algorithm of choice for training deep learning models.",1
How do I use Mini-batch (stochastic) gradient descent?,"Mini-batch gradient descent is an implementation of gradient descent which approximates the real gradient of the loss function, which is computed by taking into account all the training examples, with an approximated gradient, which is calculated by iteratively taking into account all the training examples in a mini-batch, until it has gone through all mini-batches.Mini-batch gradient descent tries to take the best of batch gradient descent and stochastic gradient descent. It's much faster than batch gradient descent, but avoids the extreme fluctuations in the parameter updates of SGD (i.e., it's more stable than SGD), thus making model training faster without any significant downsides.Mini-batch gradient descent is the algorithm of choice for training deep learning models.",1
Model,"Model can have two meanings:It's the combination of your neural network architecture and your specific hyperparameter settings. On the Peltarion Platform, a model is a sequence of blocks that have been strung together to achieve the desired model architecture.It's the (mathematical) representation that the neural network has learned after having been trained on the training set. You can read about Modeling view here: /knowledge-center/documentation/modeling-view",1
What is Model,"Model can have two meanings:It's the combination of your neural network architecture and your specific hyperparameter settings. On the Peltarion Platform, a model is a sequence of blocks that have been strung together to achieve the desired model architecture.It's the (mathematical) representation that the neural network has learned after having been trained on the training set. You can read about Modeling view here: /knowledge-center/documentation/modeling-view",1
Can you help me with Model,"Model can have two meanings:It's the combination of your neural network architecture and your specific hyperparameter settings. On the Peltarion Platform, a model is a sequence of blocks that have been strung together to achieve the desired model architecture.It's the (mathematical) representation that the neural network has learned after having been trained on the training set. You can read about Modeling view here: /knowledge-center/documentation/modeling-view",1
What does Model mean?,"Model can have two meanings:It's the combination of your neural network architecture and your specific hyperparameter settings. On the Peltarion Platform, a model is a sequence of blocks that have been strung together to achieve the desired model architecture.It's the (mathematical) representation that the neural network has learned after having been trained on the training set. You can read about Modeling view here: /knowledge-center/documentation/modeling-view",1
How do I use Model?,"Model can have two meanings:It's the combination of your neural network architecture and your specific hyperparameter settings. On the Peltarion Platform, a model is a sequence of blocks that have been strung together to achieve the desired model architecture.It's the (mathematical) representation that the neural network has learned after having been trained on the training set. You can read about Modeling view here: /knowledge-center/documentation/modeling-view",1
Momentum,"Momentum compares the gradient of the previous iteration with the gradient of the current iteration and then taking bigger steps for the dimensions for which the gradients point in the same direction and smaller steps for the dimensions in which they don't. In other words, SGD 'gains momentum' in those directions where the gradient (or the 'slope') are pointing in the same direction in subsequent iterations. In the analogy of gradient descent being equal to a ball rolling down a hill, momentum would be equal to adding 'inertia' to the ball or similarly using a heavier ball to go down the same hill.Momentum helps dampen the fluctuations of SGD and helps it accelerate towards the relevant gradient direction. You can read about Momentum here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/optimization-principles-(in-deep-learning)#Momentum",1
What is Momentum,"Momentum compares the gradient of the previous iteration with the gradient of the current iteration and then taking bigger steps for the dimensions for which the gradients point in the same direction and smaller steps for the dimensions in which they don't. In other words, SGD 'gains momentum' in those directions where the gradient (or the 'slope') are pointing in the same direction in subsequent iterations. In the analogy of gradient descent being equal to a ball rolling down a hill, momentum would be equal to adding 'inertia' to the ball or similarly using a heavier ball to go down the same hill.Momentum helps dampen the fluctuations of SGD and helps it accelerate towards the relevant gradient direction. You can read about Momentum here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/optimization-principles-(in-deep-learning)#Momentum",1
Can you help me with Momentum,"Momentum compares the gradient of the previous iteration with the gradient of the current iteration and then taking bigger steps for the dimensions for which the gradients point in the same direction and smaller steps for the dimensions in which they don't. In other words, SGD 'gains momentum' in those directions where the gradient (or the 'slope') are pointing in the same direction in subsequent iterations. In the analogy of gradient descent being equal to a ball rolling down a hill, momentum would be equal to adding 'inertia' to the ball or similarly using a heavier ball to go down the same hill.Momentum helps dampen the fluctuations of SGD and helps it accelerate towards the relevant gradient direction. You can read about Momentum here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/optimization-principles-(in-deep-learning)#Momentum",1
What does Momentum mean?,"Momentum compares the gradient of the previous iteration with the gradient of the current iteration and then taking bigger steps for the dimensions for which the gradients point in the same direction and smaller steps for the dimensions in which they don't. In other words, SGD 'gains momentum' in those directions where the gradient (or the 'slope') are pointing in the same direction in subsequent iterations. In the analogy of gradient descent being equal to a ball rolling down a hill, momentum would be equal to adding 'inertia' to the ball or similarly using a heavier ball to go down the same hill.Momentum helps dampen the fluctuations of SGD and helps it accelerate towards the relevant gradient direction. You can read about Momentum here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/optimization-principles-(in-deep-learning)#Momentum",1
How do I use Momentum?,"Momentum compares the gradient of the previous iteration with the gradient of the current iteration and then taking bigger steps for the dimensions for which the gradients point in the same direction and smaller steps for the dimensions in which they don't. In other words, SGD 'gains momentum' in those directions where the gradient (or the 'slope') are pointing in the same direction in subsequent iterations. In the analogy of gradient descent being equal to a ball rolling down a hill, momentum would be equal to adding 'inertia' to the ball or similarly using a heavier ball to go down the same hill.Momentum helps dampen the fluctuations of SGD and helps it accelerate towards the relevant gradient direction. You can read about Momentum here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/optimization-principles-(in-deep-learning)#Momentum",1
Multilayer Perceptron,A multilayer perceptron (also known as a feedforward neural network) is a type of neural network that only makes use of dense layers. It is the classical type of neural network.MLPs are very flexible in nature and work well on any number of prediction or classification problems that involved tabular data.Use MLPs when you're working with tabular data.,1
What is Multilayer Perceptron,A multilayer perceptron (also known as a feedforward neural network) is a type of neural network that only makes use of dense layers. It is the classical type of neural network.MLPs are very flexible in nature and work well on any number of prediction or classification problems that involved tabular data.Use MLPs when you're working with tabular data.,1
Can you help me with Multilayer Perceptron,A multilayer perceptron (also known as a feedforward neural network) is a type of neural network that only makes use of dense layers. It is the classical type of neural network.MLPs are very flexible in nature and work well on any number of prediction or classification problems that involved tabular data.Use MLPs when you're working with tabular data.,1
What does Multilayer Perceptron mean?,A multilayer perceptron (also known as a feedforward neural network) is a type of neural network that only makes use of dense layers. It is the classical type of neural network.MLPs are very flexible in nature and work well on any number of prediction or classification problems that involved tabular data.Use MLPs when you're working with tabular data.,1
How do I use Multilayer Perceptron?,A multilayer perceptron (also known as a feedforward neural network) is a type of neural network that only makes use of dense layers. It is the classical type of neural network.MLPs are very flexible in nature and work well on any number of prediction or classification problems that involved tabular data.Use MLPs when you're working with tabular data.,1
Natural language processing (NLP),"Natural language processing (NLP) techniques aim to automatically process, analyze and manipulate (large amounts) of language data like speech and text. You can read about NLP here: https://peltarion.com/nlp",1
What is Natural language processing (NLP),"Natural language processing (NLP) techniques aim to automatically process, analyze and manipulate (large amounts) of language data like speech and text. You can read about NLP here: https://peltarion.com/nlp",1
Can you help me with Natural language processing (NLP),"Natural language processing (NLP) techniques aim to automatically process, analyze and manipulate (large amounts) of language data like speech and text. You can read about NLP here: https://peltarion.com/nlp",1
What does Natural language processing (NLP) mean?,"Natural language processing (NLP) techniques aim to automatically process, analyze and manipulate (large amounts) of language data like speech and text. You can read about NLP here: https://peltarion.com/nlp",1
How do I use Natural language processing (NLP)?,"Natural language processing (NLP) techniques aim to automatically process, analyze and manipulate (large amounts) of language data like speech and text. You can read about NLP here: https://peltarion.com/nlp",1
Nesterov accelerated gradient (NAG),"Nesterov accelerated gradient is a modification of momentum which introduces and additional term that 'looks ahead' at the upcoming iteration and approximates the expected parameter update. It uses this approximation to tune the amount of 'momentum that momentum imparts on SGD. If the parameters of the upcoming iteration show that the gradient (or 'slope') is increasing, NAG will reduce the amount of 'momentum' in anticipation.NAG helps dampen the fluctuations of SGD and helps it accelerate towards the relevant gradient direction. It's anticipatory nature results in increased performance of SGD on complex loss surfaces.",1
What is Nesterov accelerated gradient (NAG),"Nesterov accelerated gradient is a modification of momentum which introduces and additional term that 'looks ahead' at the upcoming iteration and approximates the expected parameter update. It uses this approximation to tune the amount of 'momentum that momentum imparts on SGD. If the parameters of the upcoming iteration show that the gradient (or 'slope') is increasing, NAG will reduce the amount of 'momentum' in anticipation.NAG helps dampen the fluctuations of SGD and helps it accelerate towards the relevant gradient direction. It's anticipatory nature results in increased performance of SGD on complex loss surfaces.",1
Can you help me with Nesterov accelerated gradient (NAG),"Nesterov accelerated gradient is a modification of momentum which introduces and additional term that 'looks ahead' at the upcoming iteration and approximates the expected parameter update. It uses this approximation to tune the amount of 'momentum that momentum imparts on SGD. If the parameters of the upcoming iteration show that the gradient (or 'slope') is increasing, NAG will reduce the amount of 'momentum' in anticipation.NAG helps dampen the fluctuations of SGD and helps it accelerate towards the relevant gradient direction. It's anticipatory nature results in increased performance of SGD on complex loss surfaces.",1
What does Nesterov accelerated gradient (NAG) mean?,"Nesterov accelerated gradient is a modification of momentum which introduces and additional term that 'looks ahead' at the upcoming iteration and approximates the expected parameter update. It uses this approximation to tune the amount of 'momentum that momentum imparts on SGD. If the parameters of the upcoming iteration show that the gradient (or 'slope') is increasing, NAG will reduce the amount of 'momentum' in anticipation.NAG helps dampen the fluctuations of SGD and helps it accelerate towards the relevant gradient direction. It's anticipatory nature results in increased performance of SGD on complex loss surfaces.",1
How do I use Nesterov accelerated gradient (NAG)?,"Nesterov accelerated gradient is a modification of momentum which introduces and additional term that 'looks ahead' at the upcoming iteration and approximates the expected parameter update. It uses this approximation to tune the amount of 'momentum that momentum imparts on SGD. If the parameters of the upcoming iteration show that the gradient (or 'slope') is increasing, NAG will reduce the amount of 'momentum' in anticipation.NAG helps dampen the fluctuations of SGD and helps it accelerate towards the relevant gradient direction. It's anticipatory nature results in increased performance of SGD on complex loss surfaces.",1
Neural network,A neural network is composed of a large number of processing units called nodes that are highly interconnected with each other and arranged in structures called layers. These networks of nodes are able to process information in such a way that is able to solve problems such as pattern recognition and data classification through a learning process.,1
What is Neural network,A neural network is composed of a large number of processing units called nodes that are highly interconnected with each other and arranged in structures called layers. These networks of nodes are able to process information in such a way that is able to solve problems such as pattern recognition and data classification through a learning process.,1
Can you help me with Neural network,A neural network is composed of a large number of processing units called nodes that are highly interconnected with each other and arranged in structures called layers. These networks of nodes are able to process information in such a way that is able to solve problems such as pattern recognition and data classification through a learning process.,1
What does Neural network mean?,A neural network is composed of a large number of processing units called nodes that are highly interconnected with each other and arranged in structures called layers. These networks of nodes are able to process information in such a way that is able to solve problems such as pattern recognition and data classification through a learning process.,1
How do I use Neural network?,A neural network is composed of a large number of processing units called nodes that are highly interconnected with each other and arranged in structures called layers. These networks of nodes are able to process information in such a way that is able to solve problems such as pattern recognition and data classification through a learning process.,1
Neuron,See Node,1
What is Neuron,See Node,1
Can you help me with Neuron,See Node,1
What does Neuron mean?,See Node,1
How do I use Neuron?,See Node,1
Node,A node is the basic computation unit of a neural network. It takes the weighted sum of all of its inputs and feeds the result to an activation function to produce a single output.,1
What is Node,A node is the basic computation unit of a neural network. It takes the weighted sum of all of its inputs and feeds the result to an activation function to produce a single output.,1
Can you help me with Node,A node is the basic computation unit of a neural network. It takes the weighted sum of all of its inputs and feeds the result to an activation function to produce a single output.,1
What does Node mean?,A node is the basic computation unit of a neural network. It takes the weighted sum of all of its inputs and feeds the result to an activation function to produce a single output.,1
How do I use Node?,A node is the basic computation unit of a neural network. It takes the weighted sum of all of its inputs and feeds the result to an activation function to produce a single output.,1
Noise,"Noise is anything that is not the signal. Thus, noise in this sense doesn't refer to the everyday notion of noise, like ""noise in a photo caused due to poor lighting conditions"". Instead it's the abstract notion of any information contained in the data that is not relevant to modelling the relationships between the input data and the target one wishes to learn.",1
What is Noise,"Noise is anything that is not the signal. Thus, noise in this sense doesn't refer to the everyday notion of noise, like ""noise in a photo caused due to poor lighting conditions"". Instead it's the abstract notion of any information contained in the data that is not relevant to modelling the relationships between the input data and the target one wishes to learn.",1
Can you help me with Noise,"Noise is anything that is not the signal. Thus, noise in this sense doesn't refer to the everyday notion of noise, like ""noise in a photo caused due to poor lighting conditions"". Instead it's the abstract notion of any information contained in the data that is not relevant to modelling the relationships between the input data and the target one wishes to learn.",1
What does Noise mean?,"Noise is anything that is not the signal. Thus, noise in this sense doesn't refer to the everyday notion of noise, like ""noise in a photo caused due to poor lighting conditions"". Instead it's the abstract notion of any information contained in the data that is not relevant to modelling the relationships between the input data and the target one wishes to learn.",1
How do I use Noise?,"Noise is anything that is not the signal. Thus, noise in this sense doesn't refer to the everyday notion of noise, like ""noise in a photo caused due to poor lighting conditions"". Instead it's the abstract notion of any information contained in the data that is not relevant to modelling the relationships between the input data and the target one wishes to learn.",1
Normalization (concept),"Normalization is the process of 'resizing' values (e.g., the outputs of a layer) from their actual numeric range into a standard range of values.This process makes all the values across features be more consistent with each other, which can be interpreted as making all the values across features of equal importance. This helps speed up the training of the network.You should always normalize your data before you start training your network. You can read about Normalization here: https://peltarion.com/knowledge-center/documentation/datasets-view/edit-an-imported-dataset-for-use-in-experiments/feature-encoding/normalization",1
What is Normalization (concept),"Normalization is the process of 'resizing' values (e.g., the outputs of a layer) from their actual numeric range into a standard range of values.This process makes all the values across features be more consistent with each other, which can be interpreted as making all the values across features of equal importance. This helps speed up the training of the network.You should always normalize your data before you start training your network. You can read about Normalization here: https://peltarion.com/knowledge-center/documentation/datasets-view/edit-an-imported-dataset-for-use-in-experiments/feature-encoding/normalization",1
Can you help me with Normalization (concept),"Normalization is the process of 'resizing' values (e.g., the outputs of a layer) from their actual numeric range into a standard range of values.This process makes all the values across features be more consistent with each other, which can be interpreted as making all the values across features of equal importance. This helps speed up the training of the network.You should always normalize your data before you start training your network. You can read about Normalization here: https://peltarion.com/knowledge-center/documentation/datasets-view/edit-an-imported-dataset-for-use-in-experiments/feature-encoding/normalization",1
What does Normalization (concept) mean?,"Normalization is the process of 'resizing' values (e.g., the outputs of a layer) from their actual numeric range into a standard range of values.This process makes all the values across features be more consistent with each other, which can be interpreted as making all the values across features of equal importance. This helps speed up the training of the network.You should always normalize your data before you start training your network. You can read about Normalization here: https://peltarion.com/knowledge-center/documentation/datasets-view/edit-an-imported-dataset-for-use-in-experiments/feature-encoding/normalization",1
How do I use Normalization (concept)?,"Normalization is the process of 'resizing' values (e.g., the outputs of a layer) from their actual numeric range into a standard range of values.This process makes all the values across features be more consistent with each other, which can be interpreted as making all the values across features of equal importance. This helps speed up the training of the network.You should always normalize your data before you start training your network. You can read about Normalization here: https://peltarion.com/knowledge-center/documentation/datasets-view/edit-an-imported-dataset-for-use-in-experiments/feature-encoding/normalization",1
One-hot encoding,"One-hot encoding is a method which allows you to convert a categorical feature into a binary vector. For example, if your variable is 'apple_color' and the possible values it can take are 'Red', 'Yellow' and 'Green', the feature values can be encoded as follows:One-hot encoding is a simple form of embedding. Categorical encoding in the Datasets view is the same thing as one-hot encodingMany deep / machine learning algorithms require their input and output data to be numeric. By transforming a categorical feature into a numeric value using one-hot encoding, it can be used by a deep / machine learning algorithm, either as a feature or target value, to train a model.Use categorical encoding with categorical features in your dataset (e.g., labels) that have a relatively small number of categories.",1
What is One-hot encoding,"One-hot encoding is a method which allows you to convert a categorical feature into a binary vector. For example, if your variable is 'apple_color' and the possible values it can take are 'Red', 'Yellow' and 'Green', the feature values can be encoded as follows:One-hot encoding is a simple form of embedding. Categorical encoding in the Datasets view is the same thing as one-hot encodingMany deep / machine learning algorithms require their input and output data to be numeric. By transforming a categorical feature into a numeric value using one-hot encoding, it can be used by a deep / machine learning algorithm, either as a feature or target value, to train a model.Use categorical encoding with categorical features in your dataset (e.g., labels) that have a relatively small number of categories.",1
Can you help me with One-hot encoding,"One-hot encoding is a method which allows you to convert a categorical feature into a binary vector. For example, if your variable is 'apple_color' and the possible values it can take are 'Red', 'Yellow' and 'Green', the feature values can be encoded as follows:One-hot encoding is a simple form of embedding. Categorical encoding in the Datasets view is the same thing as one-hot encodingMany deep / machine learning algorithms require their input and output data to be numeric. By transforming a categorical feature into a numeric value using one-hot encoding, it can be used by a deep / machine learning algorithm, either as a feature or target value, to train a model.Use categorical encoding with categorical features in your dataset (e.g., labels) that have a relatively small number of categories.",1
What does One-hot encoding mean?,"One-hot encoding is a method which allows you to convert a categorical feature into a binary vector. For example, if your variable is 'apple_color' and the possible values it can take are 'Red', 'Yellow' and 'Green', the feature values can be encoded as follows:One-hot encoding is a simple form of embedding. Categorical encoding in the Datasets view is the same thing as one-hot encodingMany deep / machine learning algorithms require their input and output data to be numeric. By transforming a categorical feature into a numeric value using one-hot encoding, it can be used by a deep / machine learning algorithm, either as a feature or target value, to train a model.Use categorical encoding with categorical features in your dataset (e.g., labels) that have a relatively small number of categories.",1
How do I use One-hot encoding?,"One-hot encoding is a method which allows you to convert a categorical feature into a binary vector. For example, if your variable is 'apple_color' and the possible values it can take are 'Red', 'Yellow' and 'Green', the feature values can be encoded as follows:One-hot encoding is a simple form of embedding. Categorical encoding in the Datasets view is the same thing as one-hot encodingMany deep / machine learning algorithms require their input and output data to be numeric. By transforming a categorical feature into a numeric value using one-hot encoding, it can be used by a deep / machine learning algorithm, either as a feature or target value, to train a model.Use categorical encoding with categorical features in your dataset (e.g., labels) that have a relatively small number of categories.",1
Optimizer (gradient descent),"An optimizer is a specific implementation of gradient descent which improve the performance of the basic gradient descent algorithm.Optimizers aim to mitigate some of the challenges that are characteristic of gradient descent like: convergence to suboptimal local minima and setting the starting learning rate and it's decay.In practice, using a gradient descent optimizer is the go-to choice for training deep learning models.",1
What is Optimizer (gradient descent),"An optimizer is a specific implementation of gradient descent which improve the performance of the basic gradient descent algorithm.Optimizers aim to mitigate some of the challenges that are characteristic of gradient descent like: convergence to suboptimal local minima and setting the starting learning rate and it's decay.In practice, using a gradient descent optimizer is the go-to choice for training deep learning models.",1
Can you help me with Optimizer (gradient descent),"An optimizer is a specific implementation of gradient descent which improve the performance of the basic gradient descent algorithm.Optimizers aim to mitigate some of the challenges that are characteristic of gradient descent like: convergence to suboptimal local minima and setting the starting learning rate and it's decay.In practice, using a gradient descent optimizer is the go-to choice for training deep learning models.",1
What does Optimizer (gradient descent) mean?,"An optimizer is a specific implementation of gradient descent which improve the performance of the basic gradient descent algorithm.Optimizers aim to mitigate some of the challenges that are characteristic of gradient descent like: convergence to suboptimal local minima and setting the starting learning rate and it's decay.In practice, using a gradient descent optimizer is the go-to choice for training deep learning models.",1
How do I use Optimizer (gradient descent)?,"An optimizer is a specific implementation of gradient descent which improve the performance of the basic gradient descent algorithm.Optimizers aim to mitigate some of the challenges that are characteristic of gradient descent like: convergence to suboptimal local minima and setting the starting learning rate and it's decay.In practice, using a gradient descent optimizer is the go-to choice for training deep learning models.",1
Overfitting,"Overfitting is the phenomenon of a model not performing well, i.e., not making good predictions, because it captured the noise as well as the signal in the training set. In other words, the model is generalizing too little and instead of just characterizing and encoding the signal it's encoding too much of the noise found in the training set as well. (Another way to think about this is that the model is trying to fit 'too much' to the training data).This means that the model performs well when it's shown a training example (resulting in a low training loss), but badly when it's shown a new example it hasn't seen before (resulting in a high validation loss).",1
What is Overfitting,"Overfitting is the phenomenon of a model not performing well, i.e., not making good predictions, because it captured the noise as well as the signal in the training set. In other words, the model is generalizing too little and instead of just characterizing and encoding the signal it's encoding too much of the noise found in the training set as well. (Another way to think about this is that the model is trying to fit 'too much' to the training data).This means that the model performs well when it's shown a training example (resulting in a low training loss), but badly when it's shown a new example it hasn't seen before (resulting in a high validation loss).",1
Can you help me with Overfitting,"Overfitting is the phenomenon of a model not performing well, i.e., not making good predictions, because it captured the noise as well as the signal in the training set. In other words, the model is generalizing too little and instead of just characterizing and encoding the signal it's encoding too much of the noise found in the training set as well. (Another way to think about this is that the model is trying to fit 'too much' to the training data).This means that the model performs well when it's shown a training example (resulting in a low training loss), but badly when it's shown a new example it hasn't seen before (resulting in a high validation loss).",1
What does Overfitting mean?,"Overfitting is the phenomenon of a model not performing well, i.e., not making good predictions, because it captured the noise as well as the signal in the training set. In other words, the model is generalizing too little and instead of just characterizing and encoding the signal it's encoding too much of the noise found in the training set as well. (Another way to think about this is that the model is trying to fit 'too much' to the training data).This means that the model performs well when it's shown a training example (resulting in a low training loss), but badly when it's shown a new example it hasn't seen before (resulting in a high validation loss).",1
How do I use Overfitting?,"Overfitting is the phenomenon of a model not performing well, i.e., not making good predictions, because it captured the noise as well as the signal in the training set. In other words, the model is generalizing too little and instead of just characterizing and encoding the signal it's encoding too much of the noise found in the training set as well. (Another way to think about this is that the model is trying to fit 'too much' to the training data).This means that the model performs well when it's shown a training example (resulting in a low training loss), but badly when it's shown a new example it hasn't seen before (resulting in a high validation loss).",1
Oversampling,"It's the process of balancing a dataset by reusing examples of the underrepresented classes so that every class of the dataset has an equal amount of examples.A balanced dataset allows a model to learn equal amounts of characteristics from each of the classes represented in the dataset, as opposed to one class dominating what the model learns.Use when you have an imbalanced dataset. Oversampling is usually preferred to undersampling as data is rarely overabundant.",1
What is Oversampling,"It's the process of balancing a dataset by reusing examples of the underrepresented classes so that every class of the dataset has an equal amount of examples.A balanced dataset allows a model to learn equal amounts of characteristics from each of the classes represented in the dataset, as opposed to one class dominating what the model learns.Use when you have an imbalanced dataset. Oversampling is usually preferred to undersampling as data is rarely overabundant.",1
Can you help me with Oversampling,"It's the process of balancing a dataset by reusing examples of the underrepresented classes so that every class of the dataset has an equal amount of examples.A balanced dataset allows a model to learn equal amounts of characteristics from each of the classes represented in the dataset, as opposed to one class dominating what the model learns.Use when you have an imbalanced dataset. Oversampling is usually preferred to undersampling as data is rarely overabundant.",1
What does Oversampling mean?,"It's the process of balancing a dataset by reusing examples of the underrepresented classes so that every class of the dataset has an equal amount of examples.A balanced dataset allows a model to learn equal amounts of characteristics from each of the classes represented in the dataset, as opposed to one class dominating what the model learns.Use when you have an imbalanced dataset. Oversampling is usually preferred to undersampling as data is rarely overabundant.",1
How do I use Oversampling?,"It's the process of balancing a dataset by reusing examples of the underrepresented classes so that every class of the dataset has an equal amount of examples.A balanced dataset allows a model to learn equal amounts of characteristics from each of the classes represented in the dataset, as opposed to one class dominating what the model learns.Use when you have an imbalanced dataset. Oversampling is usually preferred to undersampling as data is rarely overabundant.",1
Padding,"Padding is the process of adding one or more pixels of zeros all around the boundaries of an image, in order to increase its effective size.Convolutional layers return by default a smaller image than the input. If a lot of convolutional layers are strung together, the output image is progressively reduced in size until, eventually, it might become unusable. By padding an image (i.e., ""increasing"" its size) before a convolutional layer, this effect can be mitigated. The relationship between padding and the output of a convolutional layer is given by:Use padding in convolutional neural networks.",1
What is Padding,"Padding is the process of adding one or more pixels of zeros all around the boundaries of an image, in order to increase its effective size.Convolutional layers return by default a smaller image than the input. If a lot of convolutional layers are strung together, the output image is progressively reduced in size until, eventually, it might become unusable. By padding an image (i.e., ""increasing"" its size) before a convolutional layer, this effect can be mitigated. The relationship between padding and the output of a convolutional layer is given by:Use padding in convolutional neural networks.",1
Can you help me with Padding,"Padding is the process of adding one or more pixels of zeros all around the boundaries of an image, in order to increase its effective size.Convolutional layers return by default a smaller image than the input. If a lot of convolutional layers are strung together, the output image is progressively reduced in size until, eventually, it might become unusable. By padding an image (i.e., ""increasing"" its size) before a convolutional layer, this effect can be mitigated. The relationship between padding and the output of a convolutional layer is given by:Use padding in convolutional neural networks.",1
What does Padding mean?,"Padding is the process of adding one or more pixels of zeros all around the boundaries of an image, in order to increase its effective size.Convolutional layers return by default a smaller image than the input. If a lot of convolutional layers are strung together, the output image is progressively reduced in size until, eventually, it might become unusable. By padding an image (i.e., ""increasing"" its size) before a convolutional layer, this effect can be mitigated. The relationship between padding and the output of a convolutional layer is given by:Use padding in convolutional neural networks.",1
How do I use Padding?,"Padding is the process of adding one or more pixels of zeros all around the boundaries of an image, in order to increase its effective size.Convolutional layers return by default a smaller image than the input. If a lot of convolutional layers are strung together, the output image is progressively reduced in size until, eventually, it might become unusable. By padding an image (i.e., ""increasing"" its size) before a convolutional layer, this effect can be mitigated. The relationship between padding and the output of a convolutional layer is given by:Use padding in convolutional neural networks.",1
Parameter,A parameter is any internal variable of your model that is automatically adjusted during training in order to minimize the loss function. An example of parameters are each of the weights in a neural network. You can read about Parameters here: https://peltarion.com/knowledge-center/documentation/deployment-view#deployment_parameters,1
What is Parameter,A parameter is any internal variable of your model that is automatically adjusted during training in order to minimize the loss function. An example of parameters are each of the weights in a neural network. You can read about Parameters here: https://peltarion.com/knowledge-center/documentation/deployment-view#deployment_parameters,1
Can you help me with Parameter,A parameter is any internal variable of your model that is automatically adjusted during training in order to minimize the loss function. An example of parameters are each of the weights in a neural network. You can read about Parameters here: https://peltarion.com/knowledge-center/documentation/deployment-view#deployment_parameters,1
What does Parameter mean?,A parameter is any internal variable of your model that is automatically adjusted during training in order to minimize the loss function. An example of parameters are each of the weights in a neural network. You can read about Parameters here: https://peltarion.com/knowledge-center/documentation/deployment-view#deployment_parameters,1
How do I use Parameter?,A parameter is any internal variable of your model that is automatically adjusted during training in order to minimize the loss function. An example of parameters are each of the weights in a neural network. You can read about Parameters here: https://peltarion.com/knowledge-center/documentation/deployment-view#deployment_parameters,1
Poisson loss,"The poisson loss is a loss function used for regression when modelling count data. The loss takes the form of:where ŷ is the predicted expected value, and y is the observed value.Minimizing the poisson loss is equivalent of maximizing the likelihood of the data under the assumption that the target comes from a poisson distribution, conditioned on the input.The poisson loss is a specifically tailored for data follows the poisson distribution. Examples of this are number of customers that will enter a store on a given day, number of emails that will arrive within the next hour, or how many customers that will churn next week.Use the poisson loss when you believe that the target value comes from a poisson distribution and want to model the rate parameter conditioned on some input. You can read about Poisson here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/poisson",1
What is Poisson loss,"The poisson loss is a loss function used for regression when modelling count data. The loss takes the form of:where ŷ is the predicted expected value, and y is the observed value.Minimizing the poisson loss is equivalent of maximizing the likelihood of the data under the assumption that the target comes from a poisson distribution, conditioned on the input.The poisson loss is a specifically tailored for data follows the poisson distribution. Examples of this are number of customers that will enter a store on a given day, number of emails that will arrive within the next hour, or how many customers that will churn next week.Use the poisson loss when you believe that the target value comes from a poisson distribution and want to model the rate parameter conditioned on some input. You can read about Poisson here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/poisson",1
Can you help me with Poisson loss,"The poisson loss is a loss function used for regression when modelling count data. The loss takes the form of:where ŷ is the predicted expected value, and y is the observed value.Minimizing the poisson loss is equivalent of maximizing the likelihood of the data under the assumption that the target comes from a poisson distribution, conditioned on the input.The poisson loss is a specifically tailored for data follows the poisson distribution. Examples of this are number of customers that will enter a store on a given day, number of emails that will arrive within the next hour, or how many customers that will churn next week.Use the poisson loss when you believe that the target value comes from a poisson distribution and want to model the rate parameter conditioned on some input. You can read about Poisson here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/poisson",1
What does Poisson loss mean?,"The poisson loss is a loss function used for regression when modelling count data. The loss takes the form of:where ŷ is the predicted expected value, and y is the observed value.Minimizing the poisson loss is equivalent of maximizing the likelihood of the data under the assumption that the target comes from a poisson distribution, conditioned on the input.The poisson loss is a specifically tailored for data follows the poisson distribution. Examples of this are number of customers that will enter a store on a given day, number of emails that will arrive within the next hour, or how many customers that will churn next week.Use the poisson loss when you believe that the target value comes from a poisson distribution and want to model the rate parameter conditioned on some input. You can read about Poisson here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/poisson",1
How do I use Poisson loss?,"The poisson loss is a loss function used for regression when modelling count data. The loss takes the form of:where ŷ is the predicted expected value, and y is the observed value.Minimizing the poisson loss is equivalent of maximizing the likelihood of the data under the assumption that the target comes from a poisson distribution, conditioned on the input.The poisson loss is a specifically tailored for data follows the poisson distribution. Examples of this are number of customers that will enter a store on a given day, number of emails that will arrive within the next hour, or how many customers that will churn next week.Use the poisson loss when you believe that the target value comes from a poisson distribution and want to model the rate parameter conditioned on some input. You can read about Poisson here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/poisson",1
Pooling,"Pooling is the process of summarizing or aggregating sections of a given data sample (usually the matrix resulting from a convolution operation) into a single number. This is usually done by either taking the maximum or the average value of said sections.This operation helps you reduce the number of parameters of your model and introduces translational invariance in the features extracted by your model (i.e., your model will be less sensitive to small translations of the input data).Use pooling in convolutional neural networks.",1
What is Pooling,"Pooling is the process of summarizing or aggregating sections of a given data sample (usually the matrix resulting from a convolution operation) into a single number. This is usually done by either taking the maximum or the average value of said sections.This operation helps you reduce the number of parameters of your model and introduces translational invariance in the features extracted by your model (i.e., your model will be less sensitive to small translations of the input data).Use pooling in convolutional neural networks.",1
Can you help me with Pooling,"Pooling is the process of summarizing or aggregating sections of a given data sample (usually the matrix resulting from a convolution operation) into a single number. This is usually done by either taking the maximum or the average value of said sections.This operation helps you reduce the number of parameters of your model and introduces translational invariance in the features extracted by your model (i.e., your model will be less sensitive to small translations of the input data).Use pooling in convolutional neural networks.",1
What does Pooling mean?,"Pooling is the process of summarizing or aggregating sections of a given data sample (usually the matrix resulting from a convolution operation) into a single number. This is usually done by either taking the maximum or the average value of said sections.This operation helps you reduce the number of parameters of your model and introduces translational invariance in the features extracted by your model (i.e., your model will be less sensitive to small translations of the input data).Use pooling in convolutional neural networks.",1
How do I use Pooling?,"Pooling is the process of summarizing or aggregating sections of a given data sample (usually the matrix resulting from a convolution operation) into a single number. This is usually done by either taking the maximum or the average value of said sections.This operation helps you reduce the number of parameters of your model and introduces translational invariance in the features extracted by your model (i.e., your model will be less sensitive to small translations of the input data).Use pooling in convolutional neural networks.",1
Pooling layer,"A pooling layer applies the pooling operation to its input (usually the output of a convolutional layer). On the Peltarion Platform, you can find the three kinds of pooling layers: '2D Max pooling', '2D Average pooling', 'Global Average pooling'This type of layer helps you reduce the number of parameters of your model and introduces translational invariance in the features extracted by your model (i.e., your model will be less sensitive to small translations of the input data).",1
What is Pooling layer,"A pooling layer applies the pooling operation to its input (usually the output of a convolutional layer). On the Peltarion Platform, you can find the three kinds of pooling layers: '2D Max pooling', '2D Average pooling', 'Global Average pooling'This type of layer helps you reduce the number of parameters of your model and introduces translational invariance in the features extracted by your model (i.e., your model will be less sensitive to small translations of the input data).",1
Can you help me with Pooling layer,"A pooling layer applies the pooling operation to its input (usually the output of a convolutional layer). On the Peltarion Platform, you can find the three kinds of pooling layers: '2D Max pooling', '2D Average pooling', 'Global Average pooling'This type of layer helps you reduce the number of parameters of your model and introduces translational invariance in the features extracted by your model (i.e., your model will be less sensitive to small translations of the input data).",1
What does Pooling layer mean?,"A pooling layer applies the pooling operation to its input (usually the output of a convolutional layer). On the Peltarion Platform, you can find the three kinds of pooling layers: '2D Max pooling', '2D Average pooling', 'Global Average pooling'This type of layer helps you reduce the number of parameters of your model and introduces translational invariance in the features extracted by your model (i.e., your model will be less sensitive to small translations of the input data).",1
How do I use Pooling layer?,"A pooling layer applies the pooling operation to its input (usually the output of a convolutional layer). On the Peltarion Platform, you can find the three kinds of pooling layers: '2D Max pooling', '2D Average pooling', 'Global Average pooling'This type of layer helps you reduce the number of parameters of your model and introduces translational invariance in the features extracted by your model (i.e., your model will be less sensitive to small translations of the input data).",1
Positive predictive value (PPV),See precision.,1
What is Positive predictive value (PPV),See precision.,1
Can you help me with Positive predictive value (PPV),See precision.,1
What does Positive predictive value (PPV) mean?,See precision.,1
How do I use Positive predictive value (PPV)?,See precision.,1
Precision,"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.This metric is the proportion of examples of class 'A' that are correctly predicted as class 'A', with respect to all examples predicted as class 'A'. In other words, the higher precision, the fewer examples of class 'A' will be misclassified. It's defined as: You can read about Precision here: https://peltarion.com/knowledge-center/documentation/evaluation-view/classification-loss-metrics/micro-precision#_precision",1
What is Precision,"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.This metric is the proportion of examples of class 'A' that are correctly predicted as class 'A', with respect to all examples predicted as class 'A'. In other words, the higher precision, the fewer examples of class 'A' will be misclassified. It's defined as: You can read about Precision here: https://peltarion.com/knowledge-center/documentation/evaluation-view/classification-loss-metrics/micro-precision#_precision",1
Can you help me with Precision,"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.This metric is the proportion of examples of class 'A' that are correctly predicted as class 'A', with respect to all examples predicted as class 'A'. In other words, the higher precision, the fewer examples of class 'A' will be misclassified. It's defined as: You can read about Precision here: https://peltarion.com/knowledge-center/documentation/evaluation-view/classification-loss-metrics/micro-precision#_precision",1
What does Precision mean?,"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.This metric is the proportion of examples of class 'A' that are correctly predicted as class 'A', with respect to all examples predicted as class 'A'. In other words, the higher precision, the fewer examples of class 'A' will be misclassified. It's defined as: You can read about Precision here: https://peltarion.com/knowledge-center/documentation/evaluation-view/classification-loss-metrics/micro-precision#_precision",1
How do I use Precision?,"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.This metric is the proportion of examples of class 'A' that are correctly predicted as class 'A', with respect to all examples predicted as class 'A'. In other words, the higher precision, the fewer examples of class 'A' will be misclassified. It's defined as: You can read about Precision here: https://peltarion.com/knowledge-center/documentation/evaluation-view/classification-loss-metrics/micro-precision#_precision",1
Project,"A project combines all of the steps in solving a problem, from the pre-processing of datasets to model building, evaluation, and deployment.Using projects makes it easy to collaborate with other members in your organization.You'll find all projects in your organization and create new ones in the Projects view. You can read about Projects view  here: https://peltarion.com/knowledge-center/documentation/projects-view",1
What is Project,"A project combines all of the steps in solving a problem, from the pre-processing of datasets to model building, evaluation, and deployment.Using projects makes it easy to collaborate with other members in your organization.You'll find all projects in your organization and create new ones in the Projects view. You can read about Projects view  here: https://peltarion.com/knowledge-center/documentation/projects-view",1
Can you help me with Project,"A project combines all of the steps in solving a problem, from the pre-processing of datasets to model building, evaluation, and deployment.Using projects makes it easy to collaborate with other members in your organization.You'll find all projects in your organization and create new ones in the Projects view. You can read about Projects view  here: https://peltarion.com/knowledge-center/documentation/projects-view",1
What does Project mean?,"A project combines all of the steps in solving a problem, from the pre-processing of datasets to model building, evaluation, and deployment.Using projects makes it easy to collaborate with other members in your organization.You'll find all projects in your organization and create new ones in the Projects view. You can read about Projects view  here: https://peltarion.com/knowledge-center/documentation/projects-view",1
How do I use Project?,"A project combines all of the steps in solving a problem, from the pre-processing of datasets to model building, evaluation, and deployment.Using projects makes it easy to collaborate with other members in your organization.You'll find all projects in your organization and create new ones in the Projects view. You can read about Projects view  here: https://peltarion.com/knowledge-center/documentation/projects-view",1
Pretrained blocks,"Many of the most powerful neural networks have very large architectures (e.g., the Resnet 152 network has, you guessed it, 152 layers in total) which can make them tedious to build and daunting to start working with.To help you get started, we've made many popular networks available as block on the Peltarion Platform.Using Pretrained blocks can save you a lot of time by removing the need of having to build these models yourself and consequently, the need to double-check that you haven't missed a block or connection during your build process. Instead, you can spend more time exploring and experimenting with the different architectures for your specific application. You can read about Pretrained blocks with weights licenses here: https://peltarion.com/knowledge-center/documentation/terms/pretrained-licenses#_pretrained_blocks_with_weights_licenses",1
What is Pretrained blocks,"Many of the most powerful neural networks have very large architectures (e.g., the Resnet 152 network has, you guessed it, 152 layers in total) which can make them tedious to build and daunting to start working with.To help you get started, we've made many popular networks available as block on the Peltarion Platform.Using Pretrained blocks can save you a lot of time by removing the need of having to build these models yourself and consequently, the need to double-check that you haven't missed a block or connection during your build process. Instead, you can spend more time exploring and experimenting with the different architectures for your specific application. You can read about Pretrained blocks with weights licenses here: https://peltarion.com/knowledge-center/documentation/terms/pretrained-licenses#_pretrained_blocks_with_weights_licenses",1
Can you help me with Pretrained blocks,"Many of the most powerful neural networks have very large architectures (e.g., the Resnet 152 network has, you guessed it, 152 layers in total) which can make them tedious to build and daunting to start working with.To help you get started, we've made many popular networks available as block on the Peltarion Platform.Using Pretrained blocks can save you a lot of time by removing the need of having to build these models yourself and consequently, the need to double-check that you haven't missed a block or connection during your build process. Instead, you can spend more time exploring and experimenting with the different architectures for your specific application. You can read about Pretrained blocks with weights licenses here: https://peltarion.com/knowledge-center/documentation/terms/pretrained-licenses#_pretrained_blocks_with_weights_licenses",1
What does Pretrained blocks mean?,"Many of the most powerful neural networks have very large architectures (e.g., the Resnet 152 network has, you guessed it, 152 layers in total) which can make them tedious to build and daunting to start working with.To help you get started, we've made many popular networks available as block on the Peltarion Platform.Using Pretrained blocks can save you a lot of time by removing the need of having to build these models yourself and consequently, the need to double-check that you haven't missed a block or connection during your build process. Instead, you can spend more time exploring and experimenting with the different architectures for your specific application. You can read about Pretrained blocks with weights licenses here: https://peltarion.com/knowledge-center/documentation/terms/pretrained-licenses#_pretrained_blocks_with_weights_licenses",1
How do I use Pretrained blocks?,"Many of the most powerful neural networks have very large architectures (e.g., the Resnet 152 network has, you guessed it, 152 layers in total) which can make them tedious to build and daunting to start working with.To help you get started, we've made many popular networks available as block on the Peltarion Platform.Using Pretrained blocks can save you a lot of time by removing the need of having to build these models yourself and consequently, the need to double-check that you haven't missed a block or connection during your build process. Instead, you can spend more time exploring and experimenting with the different architectures for your specific application. You can read about Pretrained blocks with weights licenses here: https://peltarion.com/knowledge-center/documentation/terms/pretrained-licenses#_pretrained_blocks_with_weights_licenses",1
Random uniform initialization,"Random uniform initialization is a technique used to initialize the weights of your model by assigning them values from a uniform distribution with zero mean and unit variance.Random uniform initialization helps generate values for your weights that are simple to understand intuitively.This used to be the standard procedure to initialize weights, but it has been superseded by other weight initialization techniques (like glorot uniform initialization). Use random uniform initialization with dense layers, convolutional layers and LSTM units, but be aware that it may cause your network not to train as effectively as with more modern choices.",1
What is Random uniform initialization,"Random uniform initialization is a technique used to initialize the weights of your model by assigning them values from a uniform distribution with zero mean and unit variance.Random uniform initialization helps generate values for your weights that are simple to understand intuitively.This used to be the standard procedure to initialize weights, but it has been superseded by other weight initialization techniques (like glorot uniform initialization). Use random uniform initialization with dense layers, convolutional layers and LSTM units, but be aware that it may cause your network not to train as effectively as with more modern choices.",1
Can you help me with Random uniform initialization,"Random uniform initialization is a technique used to initialize the weights of your model by assigning them values from a uniform distribution with zero mean and unit variance.Random uniform initialization helps generate values for your weights that are simple to understand intuitively.This used to be the standard procedure to initialize weights, but it has been superseded by other weight initialization techniques (like glorot uniform initialization). Use random uniform initialization with dense layers, convolutional layers and LSTM units, but be aware that it may cause your network not to train as effectively as with more modern choices.",1
What does Random uniform initialization mean?,"Random uniform initialization is a technique used to initialize the weights of your model by assigning them values from a uniform distribution with zero mean and unit variance.Random uniform initialization helps generate values for your weights that are simple to understand intuitively.This used to be the standard procedure to initialize weights, but it has been superseded by other weight initialization techniques (like glorot uniform initialization). Use random uniform initialization with dense layers, convolutional layers and LSTM units, but be aware that it may cause your network not to train as effectively as with more modern choices.",1
How do I use Random uniform initialization?,"Random uniform initialization is a technique used to initialize the weights of your model by assigning them values from a uniform distribution with zero mean and unit variance.Random uniform initialization helps generate values for your weights that are simple to understand intuitively.This used to be the standard procedure to initialize weights, but it has been superseded by other weight initialization techniques (like glorot uniform initialization). Use random uniform initialization with dense layers, convolutional layers and LSTM units, but be aware that it may cause your network not to train as effectively as with more modern choices.",1
Recall,"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.This metric is the proportion of examples of class 'A' that are correctly predicted as class 'A', with respect to all examples of class 'A'. In other words, the higher recall, the fewer examples of class 'A' we will miss. It's defined as: You can read about Recall here: https://peltarion.com/knowledge-center/documentation/evaluation-view/classification-loss-metrics/micro-recall#_recall",1
What is Recall,"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.This metric is the proportion of examples of class 'A' that are correctly predicted as class 'A', with respect to all examples of class 'A'. In other words, the higher recall, the fewer examples of class 'A' we will miss. It's defined as: You can read about Recall here: https://peltarion.com/knowledge-center/documentation/evaluation-view/classification-loss-metrics/micro-recall#_recall",1
Can you help me with Recall,"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.This metric is the proportion of examples of class 'A' that are correctly predicted as class 'A', with respect to all examples of class 'A'. In other words, the higher recall, the fewer examples of class 'A' we will miss. It's defined as: You can read about Recall here: https://peltarion.com/knowledge-center/documentation/evaluation-view/classification-loss-metrics/micro-recall#_recall",1
What does Recall mean?,"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.This metric is the proportion of examples of class 'A' that are correctly predicted as class 'A', with respect to all examples of class 'A'. In other words, the higher recall, the fewer examples of class 'A' we will miss. It's defined as: You can read about Recall here: https://peltarion.com/knowledge-center/documentation/evaluation-view/classification-loss-metrics/micro-recall#_recall",1
How do I use Recall?,"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.This metric is the proportion of examples of class 'A' that are correctly predicted as class 'A', with respect to all examples of class 'A'. In other words, the higher recall, the fewer examples of class 'A' we will miss. It's defined as: You can read about Recall here: https://peltarion.com/knowledge-center/documentation/evaluation-view/classification-loss-metrics/micro-recall#_recall",1
Recurrent neural network (RNN),"A recurrent neural network is a type of neural network that makes use of LSTM units and dense layers.They are tailored to take advantage of sequential information e.g., the relationships between words in a sentence or notes in music.Use recurrent neural networks when you're working with sequential data.",1
What is Recurrent neural network (RNN),"A recurrent neural network is a type of neural network that makes use of LSTM units and dense layers.They are tailored to take advantage of sequential information e.g., the relationships between words in a sentence or notes in music.Use recurrent neural networks when you're working with sequential data.",1
Can you help me with Recurrent neural network (RNN),"A recurrent neural network is a type of neural network that makes use of LSTM units and dense layers.They are tailored to take advantage of sequential information e.g., the relationships between words in a sentence or notes in music.Use recurrent neural networks when you're working with sequential data.",1
What does Recurrent neural network (RNN) mean?,"A recurrent neural network is a type of neural network that makes use of LSTM units and dense layers.They are tailored to take advantage of sequential information e.g., the relationships between words in a sentence or notes in music.Use recurrent neural networks when you're working with sequential data.",1
How do I use Recurrent neural network (RNN)?,"A recurrent neural network is a type of neural network that makes use of LSTM units and dense layers.They are tailored to take advantage of sequential information e.g., the relationships between words in a sentence or notes in music.Use recurrent neural networks when you're working with sequential data.",1
Regression predictions,"Regression prediction is the process through which a trained model predicts a value or the probability of a target.To train the model, a training set needs to have multiple labeled examples for the desired prediction target.",1
What is Regression predictions,"Regression prediction is the process through which a trained model predicts a value or the probability of a target.To train the model, a training set needs to have multiple labeled examples for the desired prediction target.",1
Can you help me with Regression predictions,"Regression prediction is the process through which a trained model predicts a value or the probability of a target.To train the model, a training set needs to have multiple labeled examples for the desired prediction target.",1
What does Regression predictions mean?,"Regression prediction is the process through which a trained model predicts a value or the probability of a target.To train the model, a training set needs to have multiple labeled examples for the desired prediction target.",1
How do I use Regression predictions?,"Regression prediction is the process through which a trained model predicts a value or the probability of a target.To train the model, a training set needs to have multiple labeled examples for the desired prediction target.",1
Regularization,"Regularization discourages a model from becoming too complex, which in turn prevents the model from overfitting the training set.Regularization artificially constrains and ultimately reduce the absolute value of the parameters of a model, by affecting the range of the values each can take and the total number of active (i.e., non-zero) parameters.",1
What is Regularization,"Regularization discourages a model from becoming too complex, which in turn prevents the model from overfitting the training set.Regularization artificially constrains and ultimately reduce the absolute value of the parameters of a model, by affecting the range of the values each can take and the total number of active (i.e., non-zero) parameters.",1
Can you help me with Regularization,"Regularization discourages a model from becoming too complex, which in turn prevents the model from overfitting the training set.Regularization artificially constrains and ultimately reduce the absolute value of the parameters of a model, by affecting the range of the values each can take and the total number of active (i.e., non-zero) parameters.",1
What does Regularization mean?,"Regularization discourages a model from becoming too complex, which in turn prevents the model from overfitting the training set.Regularization artificially constrains and ultimately reduce the absolute value of the parameters of a model, by affecting the range of the values each can take and the total number of active (i.e., non-zero) parameters.",1
How do I use Regularization?,"Regularization discourages a model from becoming too complex, which in turn prevents the model from overfitting the training set.Regularization artificially constrains and ultimately reduce the absolute value of the parameters of a model, by affecting the range of the values each can take and the total number of active (i.e., non-zero) parameters.",1
ReLU (rectified linear unit) activation function,"The ReLU (rectified linear unit) is a non-linear function that gives the same output as input if the input is above 0, otherwise the output will be 0.It is cheap to compute and works well for many applications. It also helps prevent the vanishing gradients problem.It is the go-to activation function for many neural networks. You can read about ReLU here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/activations/relu",1
What is ReLU (rectified linear unit) activation function,"The ReLU (rectified linear unit) is a non-linear function that gives the same output as input if the input is above 0, otherwise the output will be 0.It is cheap to compute and works well for many applications. It also helps prevent the vanishing gradients problem.It is the go-to activation function for many neural networks. You can read about ReLU here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/activations/relu",1
Can you help me with ReLU (rectified linear unit) activation function,"The ReLU (rectified linear unit) is a non-linear function that gives the same output as input if the input is above 0, otherwise the output will be 0.It is cheap to compute and works well for many applications. It also helps prevent the vanishing gradients problem.It is the go-to activation function for many neural networks. You can read about ReLU here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/activations/relu",1
What does ReLU (rectified linear unit) activation function mean?,"The ReLU (rectified linear unit) is a non-linear function that gives the same output as input if the input is above 0, otherwise the output will be 0.It is cheap to compute and works well for many applications. It also helps prevent the vanishing gradients problem.It is the go-to activation function for many neural networks. You can read about ReLU here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/activations/relu",1
How do I use ReLU (rectified linear unit) activation function?,"The ReLU (rectified linear unit) is a non-linear function that gives the same output as input if the input is above 0, otherwise the output will be 0.It is cheap to compute and works well for many applications. It also helps prevent the vanishing gradients problem.It is the go-to activation function for many neural networks. You can read about ReLU here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/activations/relu",1
Reshape,"Reshape takes a data structure of any shape as input and changes its shape to an user-defined one. The only parameter is the desired shape, expressed as a list of comma separated integers, one for each of the dimensions of the new shape. The product of all dimensions in the list must equal the product of all dimensions in the input.Reshape is used to transform the shape of your data structure, into the one expected by parts of your model, as these sometimes do not match. You can read about Reshape here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/reshape",1
What is Reshape,"Reshape takes a data structure of any shape as input and changes its shape to an user-defined one. The only parameter is the desired shape, expressed as a list of comma separated integers, one for each of the dimensions of the new shape. The product of all dimensions in the list must equal the product of all dimensions in the input.Reshape is used to transform the shape of your data structure, into the one expected by parts of your model, as these sometimes do not match. You can read about Reshape here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/reshape",1
Can you help me with Reshape,"Reshape takes a data structure of any shape as input and changes its shape to an user-defined one. The only parameter is the desired shape, expressed as a list of comma separated integers, one for each of the dimensions of the new shape. The product of all dimensions in the list must equal the product of all dimensions in the input.Reshape is used to transform the shape of your data structure, into the one expected by parts of your model, as these sometimes do not match. You can read about Reshape here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/reshape",1
What does Reshape mean?,"Reshape takes a data structure of any shape as input and changes its shape to an user-defined one. The only parameter is the desired shape, expressed as a list of comma separated integers, one for each of the dimensions of the new shape. The product of all dimensions in the list must equal the product of all dimensions in the input.Reshape is used to transform the shape of your data structure, into the one expected by parts of your model, as these sometimes do not match. You can read about Reshape here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/reshape",1
How do I use Reshape?,"Reshape takes a data structure of any shape as input and changes its shape to an user-defined one. The only parameter is the desired shape, expressed as a list of comma separated integers, one for each of the dimensions of the new shape. The product of all dimensions in the list must equal the product of all dimensions in the input.Reshape is used to transform the shape of your data structure, into the one expected by parts of your model, as these sometimes do not match. You can read about Reshape here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/reshape",1
RMSPROP,RMSprop is an extension of Adagrad that deals with Adagrad's radically diminishing learning rates. RMSprop divides the learning rate by an exponentially decaying average of squared gradients. Hinton suggests the set the fuzz factor epsilon to 0.9. A good default value for the learning rate is 0.001. This optimizer is usually a good choice for recurrent neural networks (RNN).,1
What is RMSPROP,RMSprop is an extension of Adagrad that deals with Adagrad's radically diminishing learning rates. RMSprop divides the learning rate by an exponentially decaying average of squared gradients. Hinton suggests the set the fuzz factor epsilon to 0.9. A good default value for the learning rate is 0.001. This optimizer is usually a good choice for recurrent neural networks (RNN).,1
Can you help me with RMSPROP,RMSprop is an extension of Adagrad that deals with Adagrad's radically diminishing learning rates. RMSprop divides the learning rate by an exponentially decaying average of squared gradients. Hinton suggests the set the fuzz factor epsilon to 0.9. A good default value for the learning rate is 0.001. This optimizer is usually a good choice for recurrent neural networks (RNN).,1
What does RMSPROP mean?,RMSprop is an extension of Adagrad that deals with Adagrad's radically diminishing learning rates. RMSprop divides the learning rate by an exponentially decaying average of squared gradients. Hinton suggests the set the fuzz factor epsilon to 0.9. A good default value for the learning rate is 0.001. This optimizer is usually a good choice for recurrent neural networks (RNN).,1
How do I use RMSPROP?,RMSprop is an extension of Adagrad that deals with Adagrad's radically diminishing learning rates. RMSprop divides the learning rate by an exponentially decaying average of squared gradients. Hinton suggests the set the fuzz factor epsilon to 0.9. A good default value for the learning rate is 0.001. This optimizer is usually a good choice for recurrent neural networks (RNN).,1
Semantic image segmentation,"Semantic image segmentation is a deep learning technique that assigns a label to every pixel of an image with the goal of associating each pixel to a class. It's semantic because it tries to classify each pixels base on their relationships (e.g., neighboring pixels or pixels of similar color are likely to belong to the same class).",1
What is Semantic image segmentation,"Semantic image segmentation is a deep learning technique that assigns a label to every pixel of an image with the goal of associating each pixel to a class. It's semantic because it tries to classify each pixels base on their relationships (e.g., neighboring pixels or pixels of similar color are likely to belong to the same class).",1
Can you help me with Semantic image segmentation,"Semantic image segmentation is a deep learning technique that assigns a label to every pixel of an image with the goal of associating each pixel to a class. It's semantic because it tries to classify each pixels base on their relationships (e.g., neighboring pixels or pixels of similar color are likely to belong to the same class).",1
What does Semantic image segmentation mean?,"Semantic image segmentation is a deep learning technique that assigns a label to every pixel of an image with the goal of associating each pixel to a class. It's semantic because it tries to classify each pixels base on their relationships (e.g., neighboring pixels or pixels of similar color are likely to belong to the same class).",1
How do I use Semantic image segmentation?,"Semantic image segmentation is a deep learning technique that assigns a label to every pixel of an image with the goal of associating each pixel to a class. It's semantic because it tries to classify each pixels base on their relationships (e.g., neighboring pixels or pixels of similar color are likely to belong to the same class).",1
Sequence length,"Sequence length determines how many tokens are included from a text feature in each sequence.
The sequence length can be between 3 and 512 tokens.The unit of length is the token, whose precise definition depends on the Language models selected in the text Feature_encoding.Input that is less than sequence length becomes padded. Text features larger than Sequence length are cut off. This may discard significant information if the Sequence length is much smaller than the average text feature.The larger the sequence length, the bigger the example size – which may result in slower training time, or your model exceeding hardware memory limits.",1
What is Sequence length,"Sequence length determines how many tokens are included from a text feature in each sequence.
The sequence length can be between 3 and 512 tokens.The unit of length is the token, whose precise definition depends on the Language models selected in the text Feature_encoding.Input that is less than sequence length becomes padded. Text features larger than Sequence length are cut off. This may discard significant information if the Sequence length is much smaller than the average text feature.The larger the sequence length, the bigger the example size – which may result in slower training time, or your model exceeding hardware memory limits.",1
Can you help me with Sequence length,"Sequence length determines how many tokens are included from a text feature in each sequence.
The sequence length can be between 3 and 512 tokens.The unit of length is the token, whose precise definition depends on the Language models selected in the text Feature_encoding.Input that is less than sequence length becomes padded. Text features larger than Sequence length are cut off. This may discard significant information if the Sequence length is much smaller than the average text feature.The larger the sequence length, the bigger the example size – which may result in slower training time, or your model exceeding hardware memory limits.",1
What does Sequence length mean?,"Sequence length determines how many tokens are included from a text feature in each sequence.
The sequence length can be between 3 and 512 tokens.The unit of length is the token, whose precise definition depends on the Language models selected in the text Feature_encoding.Input that is less than sequence length becomes padded. Text features larger than Sequence length are cut off. This may discard significant information if the Sequence length is much smaller than the average text feature.The larger the sequence length, the bigger the example size – which may result in slower training time, or your model exceeding hardware memory limits.",1
How do I use Sequence length?,"Sequence length determines how many tokens are included from a text feature in each sequence.
The sequence length can be between 3 and 512 tokens.The unit of length is the token, whose precise definition depends on the Language models selected in the text Feature_encoding.Input that is less than sequence length becomes padded. Text features larger than Sequence length are cut off. This may discard significant information if the Sequence length is much smaller than the average text feature.The larger the sequence length, the bigger the example size – which may result in slower training time, or your model exceeding hardware memory limits.",1
Sigmoid activation function,"The sigmoid activation function generates a smooth non-linear curve that maps the incoming values between 0 and 1.The sigmoid function works well for a classifier model but it has problems with vanishing gradients for high input values, that is, y change very slow for high values of x. Unlike the softmax activation function, the sum of all the outputs doesn't have to be 1 when sigmoid is used as an activation function in the target. This means that each output node with a sigmoid activation function acts independently on each input, so more than one output node can fire at the same time.The sigmoid function is often used together with the loss function binary crossentropy.Use for binary classification or multilabel classification problems. You can read about Sigmoid here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/activations/sigmoid",1
What is Sigmoid activation function,"The sigmoid activation function generates a smooth non-linear curve that maps the incoming values between 0 and 1.The sigmoid function works well for a classifier model but it has problems with vanishing gradients for high input values, that is, y change very slow for high values of x. Unlike the softmax activation function, the sum of all the outputs doesn't have to be 1 when sigmoid is used as an activation function in the target. This means that each output node with a sigmoid activation function acts independently on each input, so more than one output node can fire at the same time.The sigmoid function is often used together with the loss function binary crossentropy.Use for binary classification or multilabel classification problems. You can read about Sigmoid here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/activations/sigmoid",1
Can you help me with Sigmoid activation function,"The sigmoid activation function generates a smooth non-linear curve that maps the incoming values between 0 and 1.The sigmoid function works well for a classifier model but it has problems with vanishing gradients for high input values, that is, y change very slow for high values of x. Unlike the softmax activation function, the sum of all the outputs doesn't have to be 1 when sigmoid is used as an activation function in the target. This means that each output node with a sigmoid activation function acts independently on each input, so more than one output node can fire at the same time.The sigmoid function is often used together with the loss function binary crossentropy.Use for binary classification or multilabel classification problems. You can read about Sigmoid here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/activations/sigmoid",1
What does Sigmoid activation function mean?,"The sigmoid activation function generates a smooth non-linear curve that maps the incoming values between 0 and 1.The sigmoid function works well for a classifier model but it has problems with vanishing gradients for high input values, that is, y change very slow for high values of x. Unlike the softmax activation function, the sum of all the outputs doesn't have to be 1 when sigmoid is used as an activation function in the target. This means that each output node with a sigmoid activation function acts independently on each input, so more than one output node can fire at the same time.The sigmoid function is often used together with the loss function binary crossentropy.Use for binary classification or multilabel classification problems. You can read about Sigmoid here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/activations/sigmoid",1
How do I use Sigmoid activation function?,"The sigmoid activation function generates a smooth non-linear curve that maps the incoming values between 0 and 1.The sigmoid function works well for a classifier model but it has problems with vanishing gradients for high input values, that is, y change very slow for high values of x. Unlike the softmax activation function, the sum of all the outputs doesn't have to be 1 when sigmoid is used as an activation function in the target. This means that each output node with a sigmoid activation function acts independently on each input, so more than one output node can fire at the same time.The sigmoid function is often used together with the loss function binary crossentropy.Use for binary classification or multilabel classification problems. You can read about Sigmoid here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/activations/sigmoid",1
Signal,"Signal is the true, underlying trend or structure that one wants to capture from the data, or equivalently the relationship between the input data and the target values that one wishes to learn.",1
What is Signal,"Signal is the true, underlying trend or structure that one wants to capture from the data, or equivalently the relationship between the input data and the target values that one wishes to learn.",1
Can you help me with Signal,"Signal is the true, underlying trend or structure that one wants to capture from the data, or equivalently the relationship between the input data and the target values that one wishes to learn.",1
What does Signal mean?,"Signal is the true, underlying trend or structure that one wants to capture from the data, or equivalently the relationship between the input data and the target values that one wishes to learn.",1
How do I use Signal?,"Signal is the true, underlying trend or structure that one wants to capture from the data, or equivalently the relationship between the input data and the target values that one wishes to learn.",1
Single-label image classification,If your input data consists of labeled images containing exactly one of multiple classes. This is called single-label classification.ExampleImages of skin lesions that are either benign or malignant.Images that contain exactly one handwritten number from 0 to 9. You can read about Single-label image classification / cheat sheet  here: https://peltarion.com/knowledge-center/documentation/cheat-sheets/single-label-image-classification-/-cheat-sheet,1
What is Single-label image classification,If your input data consists of labeled images containing exactly one of multiple classes. This is called single-label classification.ExampleImages of skin lesions that are either benign or malignant.Images that contain exactly one handwritten number from 0 to 9. You can read about Single-label image classification / cheat sheet  here: https://peltarion.com/knowledge-center/documentation/cheat-sheets/single-label-image-classification-/-cheat-sheet,1
Can you help me with Single-label image classification,If your input data consists of labeled images containing exactly one of multiple classes. This is called single-label classification.ExampleImages of skin lesions that are either benign or malignant.Images that contain exactly one handwritten number from 0 to 9. You can read about Single-label image classification / cheat sheet  here: https://peltarion.com/knowledge-center/documentation/cheat-sheets/single-label-image-classification-/-cheat-sheet,1
What does Single-label image classification mean?,If your input data consists of labeled images containing exactly one of multiple classes. This is called single-label classification.ExampleImages of skin lesions that are either benign or malignant.Images that contain exactly one handwritten number from 0 to 9. You can read about Single-label image classification / cheat sheet  here: https://peltarion.com/knowledge-center/documentation/cheat-sheets/single-label-image-classification-/-cheat-sheet,1
How do I use Single-label image classification?,If your input data consists of labeled images containing exactly one of multiple classes. This is called single-label classification.ExampleImages of skin lesions that are either benign or malignant.Images that contain exactly one handwritten number from 0 to 9. You can read about Single-label image classification / cheat sheet  here: https://peltarion.com/knowledge-center/documentation/cheat-sheets/single-label-image-classification-/-cheat-sheet,1
Softmax activation function,"The softmax activation function will calculate the relative probability of each target class over all possible target classes in the dataset given the inputs it receives. In other words it normalizes the outputs so that they sum to 1, so that they can be directly treated as probabilities over the output.This is usefull for multiclass classification models, as the target class with the highest probability is going to be the output of the model.It is often used in the final layer in a classification model with the categorical crossentropy as loss function. You can read about Softmax here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/activations/softmax",1
What is Softmax activation function,"The softmax activation function will calculate the relative probability of each target class over all possible target classes in the dataset given the inputs it receives. In other words it normalizes the outputs so that they sum to 1, so that they can be directly treated as probabilities over the output.This is usefull for multiclass classification models, as the target class with the highest probability is going to be the output of the model.It is often used in the final layer in a classification model with the categorical crossentropy as loss function. You can read about Softmax here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/activations/softmax",1
Can you help me with Softmax activation function,"The softmax activation function will calculate the relative probability of each target class over all possible target classes in the dataset given the inputs it receives. In other words it normalizes the outputs so that they sum to 1, so that they can be directly treated as probabilities over the output.This is usefull for multiclass classification models, as the target class with the highest probability is going to be the output of the model.It is often used in the final layer in a classification model with the categorical crossentropy as loss function. You can read about Softmax here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/activations/softmax",1
What does Softmax activation function mean?,"The softmax activation function will calculate the relative probability of each target class over all possible target classes in the dataset given the inputs it receives. In other words it normalizes the outputs so that they sum to 1, so that they can be directly treated as probabilities over the output.This is usefull for multiclass classification models, as the target class with the highest probability is going to be the output of the model.It is often used in the final layer in a classification model with the categorical crossentropy as loss function. You can read about Softmax here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/activations/softmax",1
How do I use Softmax activation function?,"The softmax activation function will calculate the relative probability of each target class over all possible target classes in the dataset given the inputs it receives. In other words it normalizes the outputs so that they sum to 1, so that they can be directly treated as probabilities over the output.This is usefull for multiclass classification models, as the target class with the highest probability is going to be the output of the model.It is often used in the final layer in a classification model with the categorical crossentropy as loss function. You can read about Softmax here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/activations/softmax",1
Specificity,"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.This metric is the proportion of examples of class 'B' that are correctly predicted as class 'B', with respect to all examples of class 'B'. In other words, the higher specificity, the fewer examples of class 'B' we will miss. It's defined as:",1
What is Specificity,"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.This metric is the proportion of examples of class 'B' that are correctly predicted as class 'B', with respect to all examples of class 'B'. In other words, the higher specificity, the fewer examples of class 'B' we will miss. It's defined as:",1
Can you help me with Specificity,"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.This metric is the proportion of examples of class 'B' that are correctly predicted as class 'B', with respect to all examples of class 'B'. In other words, the higher specificity, the fewer examples of class 'B' we will miss. It's defined as:",1
What does Specificity mean?,"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.This metric is the proportion of examples of class 'B' that are correctly predicted as class 'B', with respect to all examples of class 'B'. In other words, the higher specificity, the fewer examples of class 'B' we will miss. It's defined as:",1
How do I use Specificity?,"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.This metric is the proportion of examples of class 'B' that are correctly predicted as class 'B', with respect to all examples of class 'B'. In other words, the higher specificity, the fewer examples of class 'B' we will miss. It's defined as:",1
Squared hinge loss,"Squared hinge loss is a loss function used for “maximum margin” binary classification problems. Mathematically it is defined as:where ŷ is the predicted value and y is either 1 or -1.Thus, the squared hinge loss is:0:when the true and predicted labels are the same and|ŷi|≥1 (which is an indication that the classifier is sure that it's the correct label)quadratically increasing with the error:when the true and predicted labels are not the same orwhen |ŷi|<1, even when the true and predicted labels are the same (which is an indication that the classifier is not sure that it's the correct label)The hinge loss guarantees that, during training, the classifier will find the classification boundary which is the furthest apart from each of the different classes of data points as possible. In other words, it finds the classification boundary that guarantees the maximum margin between the data points of the different classes.A sample use case would be when you want to classify email into 'spam' and 'not spam' and you're only interested in the classification accuracy. You can read about Squared hinge here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/squared-hinge",1
What is Squared hinge loss,"Squared hinge loss is a loss function used for “maximum margin” binary classification problems. Mathematically it is defined as:where ŷ is the predicted value and y is either 1 or -1.Thus, the squared hinge loss is:0:when the true and predicted labels are the same and|ŷi|≥1 (which is an indication that the classifier is sure that it's the correct label)quadratically increasing with the error:when the true and predicted labels are not the same orwhen |ŷi|<1, even when the true and predicted labels are the same (which is an indication that the classifier is not sure that it's the correct label)The hinge loss guarantees that, during training, the classifier will find the classification boundary which is the furthest apart from each of the different classes of data points as possible. In other words, it finds the classification boundary that guarantees the maximum margin between the data points of the different classes.A sample use case would be when you want to classify email into 'spam' and 'not spam' and you're only interested in the classification accuracy. You can read about Squared hinge here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/squared-hinge",1
Can you help me with Squared hinge loss,"Squared hinge loss is a loss function used for “maximum margin” binary classification problems. Mathematically it is defined as:where ŷ is the predicted value and y is either 1 or -1.Thus, the squared hinge loss is:0:when the true and predicted labels are the same and|ŷi|≥1 (which is an indication that the classifier is sure that it's the correct label)quadratically increasing with the error:when the true and predicted labels are not the same orwhen |ŷi|<1, even when the true and predicted labels are the same (which is an indication that the classifier is not sure that it's the correct label)The hinge loss guarantees that, during training, the classifier will find the classification boundary which is the furthest apart from each of the different classes of data points as possible. In other words, it finds the classification boundary that guarantees the maximum margin between the data points of the different classes.A sample use case would be when you want to classify email into 'spam' and 'not spam' and you're only interested in the classification accuracy. You can read about Squared hinge here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/squared-hinge",1
What does Squared hinge loss mean?,"Squared hinge loss is a loss function used for “maximum margin” binary classification problems. Mathematically it is defined as:where ŷ is the predicted value and y is either 1 or -1.Thus, the squared hinge loss is:0:when the true and predicted labels are the same and|ŷi|≥1 (which is an indication that the classifier is sure that it's the correct label)quadratically increasing with the error:when the true and predicted labels are not the same orwhen |ŷi|<1, even when the true and predicted labels are the same (which is an indication that the classifier is not sure that it's the correct label)The hinge loss guarantees that, during training, the classifier will find the classification boundary which is the furthest apart from each of the different classes of data points as possible. In other words, it finds the classification boundary that guarantees the maximum margin between the data points of the different classes.A sample use case would be when you want to classify email into 'spam' and 'not spam' and you're only interested in the classification accuracy. You can read about Squared hinge here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/squared-hinge",1
How do I use Squared hinge loss?,"Squared hinge loss is a loss function used for “maximum margin” binary classification problems. Mathematically it is defined as:where ŷ is the predicted value and y is either 1 or -1.Thus, the squared hinge loss is:0:when the true and predicted labels are the same and|ŷi|≥1 (which is an indication that the classifier is sure that it's the correct label)quadratically increasing with the error:when the true and predicted labels are not the same orwhen |ŷi|<1, even when the true and predicted labels are the same (which is an indication that the classifier is not sure that it's the correct label)The hinge loss guarantees that, during training, the classifier will find the classification boundary which is the furthest apart from each of the different classes of data points as possible. In other words, it finds the classification boundary that guarantees the maximum margin between the data points of the different classes.A sample use case would be when you want to classify email into 'spam' and 'not spam' and you're only interested in the classification accuracy. You can read about Squared hinge here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/squared-hinge",1
Standardization,"Standardization (also known as Z-Score normalize) performs a rescaling of your data so that it has a zero mean and a unit standard deviation. Values above the feature's mean value will get positive scores, and those below the mean will get a negative score.Applied across your Combined feature, it will guarantee that your data will be gaussian with mean zero and standard deviation one. This is desirable as:it allows the comparison of features with different units or scales, andthe zero centered data offers favorable numeric conditions for training a model.Note that unlike min-max normalization, standardized data will not have the exact same scale (because the gaussian allows values between -∞ and +∞), but it will handle outliers in your data well.Use standardization when your data has different units / scales, is not restricted to a range of values and / or when it has large outliers. Note that when you perform a
standardization, you make the implicit assumption that the input data are normally distributed. However, standardization typically works well even when this is not the case.",1
What is Standardization,"Standardization (also known as Z-Score normalize) performs a rescaling of your data so that it has a zero mean and a unit standard deviation. Values above the feature's mean value will get positive scores, and those below the mean will get a negative score.Applied across your Combined feature, it will guarantee that your data will be gaussian with mean zero and standard deviation one. This is desirable as:it allows the comparison of features with different units or scales, andthe zero centered data offers favorable numeric conditions for training a model.Note that unlike min-max normalization, standardized data will not have the exact same scale (because the gaussian allows values between -∞ and +∞), but it will handle outliers in your data well.Use standardization when your data has different units / scales, is not restricted to a range of values and / or when it has large outliers. Note that when you perform a
standardization, you make the implicit assumption that the input data are normally distributed. However, standardization typically works well even when this is not the case.",1
Can you help me with Standardization,"Standardization (also known as Z-Score normalize) performs a rescaling of your data so that it has a zero mean and a unit standard deviation. Values above the feature's mean value will get positive scores, and those below the mean will get a negative score.Applied across your Combined feature, it will guarantee that your data will be gaussian with mean zero and standard deviation one. This is desirable as:it allows the comparison of features with different units or scales, andthe zero centered data offers favorable numeric conditions for training a model.Note that unlike min-max normalization, standardized data will not have the exact same scale (because the gaussian allows values between -∞ and +∞), but it will handle outliers in your data well.Use standardization when your data has different units / scales, is not restricted to a range of values and / or when it has large outliers. Note that when you perform a
standardization, you make the implicit assumption that the input data are normally distributed. However, standardization typically works well even when this is not the case.",1
What does Standardization mean?,"Standardization (also known as Z-Score normalize) performs a rescaling of your data so that it has a zero mean and a unit standard deviation. Values above the feature's mean value will get positive scores, and those below the mean will get a negative score.Applied across your Combined feature, it will guarantee that your data will be gaussian with mean zero and standard deviation one. This is desirable as:it allows the comparison of features with different units or scales, andthe zero centered data offers favorable numeric conditions for training a model.Note that unlike min-max normalization, standardized data will not have the exact same scale (because the gaussian allows values between -∞ and +∞), but it will handle outliers in your data well.Use standardization when your data has different units / scales, is not restricted to a range of values and / or when it has large outliers. Note that when you perform a
standardization, you make the implicit assumption that the input data are normally distributed. However, standardization typically works well even when this is not the case.",1
How do I use Standardization?,"Standardization (also known as Z-Score normalize) performs a rescaling of your data so that it has a zero mean and a unit standard deviation. Values above the feature's mean value will get positive scores, and those below the mean will get a negative score.Applied across your Combined feature, it will guarantee that your data will be gaussian with mean zero and standard deviation one. This is desirable as:it allows the comparison of features with different units or scales, andthe zero centered data offers favorable numeric conditions for training a model.Note that unlike min-max normalization, standardized data will not have the exact same scale (because the gaussian allows values between -∞ and +∞), but it will handle outliers in your data well.Use standardization when your data has different units / scales, is not restricted to a range of values and / or when it has large outliers. Note that when you perform a
standardization, you make the implicit assumption that the input data are normally distributed. However, standardization typically works well even when this is not the case.",1
Stochastic gradient descent (SGD),"Stochastic gradient descent (SGD) is an implementation of gradient descent which approximates the real gradient of the loss function, which is computed by taking into account all the training examples, with an approximated gradient, which is calculated by iteratively taking a single training example at a time until it has gone through all training examples.This method is much faster than batch gradient descent, but it doesn't calculate the real gradient of the loss function, since it only uses one training example at a time. This has the effect that the parameter updates made by SGD can fluctuate significantly (i.e., updates can be unstable and not necessarily correspond to a global pattern in the data), which translates to a model potentially being hard to train. This can be somewhat mitigated by slowly decreasing the learning rate throughout training. SGD is also more computationally expensive than batch gradient descent, since it's calculating the gradient much more often.Use SGD for online learning applications. You can read about Stochastic gradient descent here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/the-optimizers/stochastic-gradient-descent",1
What is Stochastic gradient descent (SGD),"Stochastic gradient descent (SGD) is an implementation of gradient descent which approximates the real gradient of the loss function, which is computed by taking into account all the training examples, with an approximated gradient, which is calculated by iteratively taking a single training example at a time until it has gone through all training examples.This method is much faster than batch gradient descent, but it doesn't calculate the real gradient of the loss function, since it only uses one training example at a time. This has the effect that the parameter updates made by SGD can fluctuate significantly (i.e., updates can be unstable and not necessarily correspond to a global pattern in the data), which translates to a model potentially being hard to train. This can be somewhat mitigated by slowly decreasing the learning rate throughout training. SGD is also more computationally expensive than batch gradient descent, since it's calculating the gradient much more often.Use SGD for online learning applications. You can read about Stochastic gradient descent here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/the-optimizers/stochastic-gradient-descent",1
Can you help me with Stochastic gradient descent (SGD),"Stochastic gradient descent (SGD) is an implementation of gradient descent which approximates the real gradient of the loss function, which is computed by taking into account all the training examples, with an approximated gradient, which is calculated by iteratively taking a single training example at a time until it has gone through all training examples.This method is much faster than batch gradient descent, but it doesn't calculate the real gradient of the loss function, since it only uses one training example at a time. This has the effect that the parameter updates made by SGD can fluctuate significantly (i.e., updates can be unstable and not necessarily correspond to a global pattern in the data), which translates to a model potentially being hard to train. This can be somewhat mitigated by slowly decreasing the learning rate throughout training. SGD is also more computationally expensive than batch gradient descent, since it's calculating the gradient much more often.Use SGD for online learning applications. You can read about Stochastic gradient descent here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/the-optimizers/stochastic-gradient-descent",1
What does Stochastic gradient descent (SGD) mean?,"Stochastic gradient descent (SGD) is an implementation of gradient descent which approximates the real gradient of the loss function, which is computed by taking into account all the training examples, with an approximated gradient, which is calculated by iteratively taking a single training example at a time until it has gone through all training examples.This method is much faster than batch gradient descent, but it doesn't calculate the real gradient of the loss function, since it only uses one training example at a time. This has the effect that the parameter updates made by SGD can fluctuate significantly (i.e., updates can be unstable and not necessarily correspond to a global pattern in the data), which translates to a model potentially being hard to train. This can be somewhat mitigated by slowly decreasing the learning rate throughout training. SGD is also more computationally expensive than batch gradient descent, since it's calculating the gradient much more often.Use SGD for online learning applications. You can read about Stochastic gradient descent here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/the-optimizers/stochastic-gradient-descent",1
How do I use Stochastic gradient descent (SGD)?,"Stochastic gradient descent (SGD) is an implementation of gradient descent which approximates the real gradient of the loss function, which is computed by taking into account all the training examples, with an approximated gradient, which is calculated by iteratively taking a single training example at a time until it has gone through all training examples.This method is much faster than batch gradient descent, but it doesn't calculate the real gradient of the loss function, since it only uses one training example at a time. This has the effect that the parameter updates made by SGD can fluctuate significantly (i.e., updates can be unstable and not necessarily correspond to a global pattern in the data), which translates to a model potentially being hard to train. This can be somewhat mitigated by slowly decreasing the learning rate throughout training. SGD is also more computationally expensive than batch gradient descent, since it's calculating the gradient much more often.Use SGD for online learning applications. You can read about Stochastic gradient descent here: https://peltarion.com/knowledge-center/documentation/modeling-view/run-a-model/the-optimizers/stochastic-gradient-descent",1
Subset,"A subset is a smaller set of your dataset. For the purpose of training a model, you usually subdivide your dataset into three subsets: training set, validation set and test set. You can read about Subset of a dataset  here: https://peltarion.com/knowledge-center/documentation/datasets-view/edit-an-imported-dataset-for-use-in-experiments/subset-of-a-dataset",1
What is Subset,"A subset is a smaller set of your dataset. For the purpose of training a model, you usually subdivide your dataset into three subsets: training set, validation set and test set. You can read about Subset of a dataset  here: https://peltarion.com/knowledge-center/documentation/datasets-view/edit-an-imported-dataset-for-use-in-experiments/subset-of-a-dataset",1
Can you help me with Subset,"A subset is a smaller set of your dataset. For the purpose of training a model, you usually subdivide your dataset into three subsets: training set, validation set and test set. You can read about Subset of a dataset  here: https://peltarion.com/knowledge-center/documentation/datasets-view/edit-an-imported-dataset-for-use-in-experiments/subset-of-a-dataset",1
What does Subset mean?,"A subset is a smaller set of your dataset. For the purpose of training a model, you usually subdivide your dataset into three subsets: training set, validation set and test set. You can read about Subset of a dataset  here: https://peltarion.com/knowledge-center/documentation/datasets-view/edit-an-imported-dataset-for-use-in-experiments/subset-of-a-dataset",1
How do I use Subset?,"A subset is a smaller set of your dataset. For the purpose of training a model, you usually subdivide your dataset into three subsets: training set, validation set and test set. You can read about Subset of a dataset  here: https://peltarion.com/knowledge-center/documentation/datasets-view/edit-an-imported-dataset-for-use-in-experiments/subset-of-a-dataset",1
Supervised learning,"Supervised learning is the task of learning a model from a dataset that has labeled examples. In other words, it is the task of learning a model / function that maps the input to the target. Examples include learning models for classification and prediction task.",1
What is Supervised learning,"Supervised learning is the task of learning a model from a dataset that has labeled examples. In other words, it is the task of learning a model / function that maps the input to the target. Examples include learning models for classification and prediction task.",1
Can you help me with Supervised learning,"Supervised learning is the task of learning a model from a dataset that has labeled examples. In other words, it is the task of learning a model / function that maps the input to the target. Examples include learning models for classification and prediction task.",1
What does Supervised learning mean?,"Supervised learning is the task of learning a model from a dataset that has labeled examples. In other words, it is the task of learning a model / function that maps the input to the target. Examples include learning models for classification and prediction task.",1
How do I use Supervised learning?,"Supervised learning is the task of learning a model from a dataset that has labeled examples. In other words, it is the task of learning a model / function that maps the input to the target. Examples include learning models for classification and prediction task.",1
Tanh activation function,"Tanh is a scaled sigmoid activation function. The gradient is stronger for tanh than sigmoid, that is, the derivatives are steeper.Unlike the sigmoid function, the tanh function is zero-centered, which means that it dosen't introduce a bias in the gradients making training a network easier. The downsinde is that tanh is computationally more expensive than the sigmoid function.Which one to use of the sigmoid or tanh depends on your requirement of gradient strength. Tanh resembles a linear function more as long as the activations of the network can be kept small. This makes the tanh network easier to compute. You can read about Tanh here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/activations/tanh",1
What is Tanh activation function,"Tanh is a scaled sigmoid activation function. The gradient is stronger for tanh than sigmoid, that is, the derivatives are steeper.Unlike the sigmoid function, the tanh function is zero-centered, which means that it dosen't introduce a bias in the gradients making training a network easier. The downsinde is that tanh is computationally more expensive than the sigmoid function.Which one to use of the sigmoid or tanh depends on your requirement of gradient strength. Tanh resembles a linear function more as long as the activations of the network can be kept small. This makes the tanh network easier to compute. You can read about Tanh here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/activations/tanh",1
Can you help me with Tanh activation function,"Tanh is a scaled sigmoid activation function. The gradient is stronger for tanh than sigmoid, that is, the derivatives are steeper.Unlike the sigmoid function, the tanh function is zero-centered, which means that it dosen't introduce a bias in the gradients making training a network easier. The downsinde is that tanh is computationally more expensive than the sigmoid function.Which one to use of the sigmoid or tanh depends on your requirement of gradient strength. Tanh resembles a linear function more as long as the activations of the network can be kept small. This makes the tanh network easier to compute. You can read about Tanh here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/activations/tanh",1
What does Tanh activation function mean?,"Tanh is a scaled sigmoid activation function. The gradient is stronger for tanh than sigmoid, that is, the derivatives are steeper.Unlike the sigmoid function, the tanh function is zero-centered, which means that it dosen't introduce a bias in the gradients making training a network easier. The downsinde is that tanh is computationally more expensive than the sigmoid function.Which one to use of the sigmoid or tanh depends on your requirement of gradient strength. Tanh resembles a linear function more as long as the activations of the network can be kept small. This makes the tanh network easier to compute. You can read about Tanh here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/activations/tanh",1
How do I use Tanh activation function?,"Tanh is a scaled sigmoid activation function. The gradient is stronger for tanh than sigmoid, that is, the derivatives are steeper.Unlike the sigmoid function, the tanh function is zero-centered, which means that it dosen't introduce a bias in the gradients making training a network easier. The downsinde is that tanh is computationally more expensive than the sigmoid function.Which one to use of the sigmoid or tanh depends on your requirement of gradient strength. Tanh resembles a linear function more as long as the activations of the network can be kept small. This makes the tanh network easier to compute. You can read about Tanh here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/activations/tanh",1
Target,"Target represents the desired output that we want our model to learn. In the case of a classification problem, the targets would be the labels of each of the examples in the training set. You can read about Target here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/target",1
What is Target,"Target represents the desired output that we want our model to learn. In the case of a classification problem, the targets would be the labels of each of the examples in the training set. You can read about Target here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/target",1
Can you help me with Target,"Target represents the desired output that we want our model to learn. In the case of a classification problem, the targets would be the labels of each of the examples in the training set. You can read about Target here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/target",1
What does Target mean?,"Target represents the desired output that we want our model to learn. In the case of a classification problem, the targets would be the labels of each of the examples in the training set. You can read about Target here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/target",1
How do I use Target?,"Target represents the desired output that we want our model to learn. In the case of a classification problem, the targets would be the labels of each of the examples in the training set. You can read about Target here: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/target",1
Test set,"A test set is a subset of your dataset that is used to check the performance of the model that was learned during training. It consists of a set of examples that the model has never seen, which help confirm its prediction accuracy.The test set is only used after training is completed and is used to provide a final assessment of the performance of the model. Note that the validation set is not able to do this, since it was used during training to adjust the hyperparameters and/or the architecture of the model.In short: the test set is used to assess the model's performance (i.e., generalization and predictive power)",1
What is Test set,"A test set is a subset of your dataset that is used to check the performance of the model that was learned during training. It consists of a set of examples that the model has never seen, which help confirm its prediction accuracy.The test set is only used after training is completed and is used to provide a final assessment of the performance of the model. Note that the validation set is not able to do this, since it was used during training to adjust the hyperparameters and/or the architecture of the model.In short: the test set is used to assess the model's performance (i.e., generalization and predictive power)",1
Can you help me with Test set,"A test set is a subset of your dataset that is used to check the performance of the model that was learned during training. It consists of a set of examples that the model has never seen, which help confirm its prediction accuracy.The test set is only used after training is completed and is used to provide a final assessment of the performance of the model. Note that the validation set is not able to do this, since it was used during training to adjust the hyperparameters and/or the architecture of the model.In short: the test set is used to assess the model's performance (i.e., generalization and predictive power)",1
What does Test set mean?,"A test set is a subset of your dataset that is used to check the performance of the model that was learned during training. It consists of a set of examples that the model has never seen, which help confirm its prediction accuracy.The test set is only used after training is completed and is used to provide a final assessment of the performance of the model. Note that the validation set is not able to do this, since it was used during training to adjust the hyperparameters and/or the architecture of the model.In short: the test set is used to assess the model's performance (i.e., generalization and predictive power)",1
How do I use Test set?,"A test set is a subset of your dataset that is used to check the performance of the model that was learned during training. It consists of a set of examples that the model has never seen, which help confirm its prediction accuracy.The test set is only used after training is completed and is used to provide a final assessment of the performance of the model. Note that the validation set is not able to do this, since it was used during training to adjust the hyperparameters and/or the architecture of the model.In short: the test set is used to assess the model's performance (i.e., generalization and predictive power)",1
Trained model,A trained model is a model that has undergone training.,1
What is Trained model,A trained model is a model that has undergone training.,1
Can you help me with Trained model,A trained model is a model that has undergone training.,1
What does Trained model mean?,A trained model is a model that has undergone training.,1
How do I use Trained model?,A trained model is a model that has undergone training.,1
Training,Training is the process of building a model by setting the ideal parameters through the use of gradient descent applied on the training set.,1
What is Training,Training is the process of building a model by setting the ideal parameters through the use of gradient descent applied on the training set.,1
Can you help me with Training,Training is the process of building a model by setting the ideal parameters through the use of gradient descent applied on the training set.,1
What does Training mean?,Training is the process of building a model by setting the ideal parameters through the use of gradient descent applied on the training set.,1
How do I use Training?,Training is the process of building a model by setting the ideal parameters through the use of gradient descent applied on the training set.,1
Training example,A training example is an example that is included in your training set.,1
What is Training example,A training example is an example that is included in your training set.,1
Can you help me with Training example,A training example is an example that is included in your training set.,1
What does Training example mean?,A training example is an example that is included in your training set.,1
How do I use Training example?,A training example is an example that is included in your training set.,1
Training iteration,"A training iteration is the process of the model training on a (mini) batch, i.e., a single update of a model's weights during training.",1
What is Training iteration,"A training iteration is the process of the model training on a (mini) batch, i.e., a single update of a model's weights during training.",1
Can you help me with Training iteration,"A training iteration is the process of the model training on a (mini) batch, i.e., a single update of a model's weights during training.",1
What does Training iteration mean?,"A training iteration is the process of the model training on a (mini) batch, i.e., a single update of a model's weights during training.",1
How do I use Training iteration?,"A training iteration is the process of the model training on a (mini) batch, i.e., a single update of a model's weights during training.",1
Training loss,Training loss is the average loss per training example of your model based on your training set.,1
What is Training loss,Training loss is the average loss per training example of your model based on your training set.,1
Can you help me with Training loss,Training loss is the average loss per training example of your model based on your training set.,1
What does Training loss mean?,Training loss is the average loss per training example of your model based on your training set.,1
How do I use Training loss?,Training loss is the average loss per training example of your model based on your training set.,1
Training set,"A training set is a subset of your dataset which contains all the examples available to a neural network to create a model during training. It's the data that gradient descent runs on, in order to adjust the parameters of the model.In short: the training set is used to fit the model parameters (i.e., weights).",1
What is Training set,"A training set is a subset of your dataset which contains all the examples available to a neural network to create a model during training. It's the data that gradient descent runs on, in order to adjust the parameters of the model.In short: the training set is used to fit the model parameters (i.e., weights).",1
Can you help me with Training set,"A training set is a subset of your dataset which contains all the examples available to a neural network to create a model during training. It's the data that gradient descent runs on, in order to adjust the parameters of the model.In short: the training set is used to fit the model parameters (i.e., weights).",1
What does Training set mean?,"A training set is a subset of your dataset which contains all the examples available to a neural network to create a model during training. It's the data that gradient descent runs on, in order to adjust the parameters of the model.In short: the training set is used to fit the model parameters (i.e., weights).",1
How do I use Training set?,"A training set is a subset of your dataset which contains all the examples available to a neural network to create a model during training. It's the data that gradient descent runs on, in order to adjust the parameters of the model.In short: the training set is used to fit the model parameters (i.e., weights).",1
True negative rate (TNR),See specificity.,1
What is True negative rate (TNR),See specificity.,1
Can you help me with True negative rate (TNR),See specificity.,1
What does True negative rate (TNR) mean?,See specificity.,1
How do I use True negative rate (TNR)?,See specificity.,1
True negatives (TN),"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.True negatives is a field in the confusion matrix which shows the cases when the actual class of the example was 'B' and the predicted class for the same example was also 'B'.",1
What is True negatives (TN),"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.True negatives is a field in the confusion matrix which shows the cases when the actual class of the example was 'B' and the predicted class for the same example was also 'B'.",1
Can you help me with True negatives (TN),"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.True negatives is a field in the confusion matrix which shows the cases when the actual class of the example was 'B' and the predicted class for the same example was also 'B'.",1
What does True negatives (TN) mean?,"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.True negatives is a field in the confusion matrix which shows the cases when the actual class of the example was 'B' and the predicted class for the same example was also 'B'.",1
How do I use True negatives (TN)?,"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.True negatives is a field in the confusion matrix which shows the cases when the actual class of the example was 'B' and the predicted class for the same example was also 'B'.",1
True positive rate (TPR),See recall.,1
What is True positive rate (TPR),See recall.,1
Can you help me with True positive rate (TPR),See recall.,1
What does True positive rate (TPR) mean?,See recall.,1
How do I use True positive rate (TPR)?,See recall.,1
True positives (TP),"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.True positives is a field in the confusion matrix which shows the cases when the actual class of the example was 'A' and the predicted class for the same example was also 'A'.",1
What is True positives (TP),"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.True positives is a field in the confusion matrix which shows the cases when the actual class of the example was 'A' and the predicted class for the same example was also 'A'.",1
Can you help me with True positives (TP),"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.True positives is a field in the confusion matrix which shows the cases when the actual class of the example was 'A' and the predicted class for the same example was also 'A'.",1
What does True positives (TP) mean?,"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.True positives is a field in the confusion matrix which shows the cases when the actual class of the example was 'A' and the predicted class for the same example was also 'A'.",1
How do I use True positives (TP)?,"Assume a dataset that includes examples of a class 'A' and examples of class 'B' (where 'B' can stand in for a single or multiple classes). Assume further, that you're evaluating your model's performance to predict examples of class 'A'.True positives is a field in the confusion matrix which shows the cases when the actual class of the example was 'A' and the predicted class for the same example was also 'A'.",1
Underfitting,"Underfitting is the phenomenon of a model not performing well, i.e., not making good predictions, because it wasn't able to correctly or completely capture the signal in the training set. In other words, the model is generalizing too much, to the point that it's actually missing the signal.This means that the model doesn't perform well on training examples (resulting in a high training loss), nor on examples it hasn't seen before (resulting in a high validation loss).",1
What is Underfitting,"Underfitting is the phenomenon of a model not performing well, i.e., not making good predictions, because it wasn't able to correctly or completely capture the signal in the training set. In other words, the model is generalizing too much, to the point that it's actually missing the signal.This means that the model doesn't perform well on training examples (resulting in a high training loss), nor on examples it hasn't seen before (resulting in a high validation loss).",1
Can you help me with Underfitting,"Underfitting is the phenomenon of a model not performing well, i.e., not making good predictions, because it wasn't able to correctly or completely capture the signal in the training set. In other words, the model is generalizing too much, to the point that it's actually missing the signal.This means that the model doesn't perform well on training examples (resulting in a high training loss), nor on examples it hasn't seen before (resulting in a high validation loss).",1
What does Underfitting mean?,"Underfitting is the phenomenon of a model not performing well, i.e., not making good predictions, because it wasn't able to correctly or completely capture the signal in the training set. In other words, the model is generalizing too much, to the point that it's actually missing the signal.This means that the model doesn't perform well on training examples (resulting in a high training loss), nor on examples it hasn't seen before (resulting in a high validation loss).",1
How do I use Underfitting?,"Underfitting is the phenomenon of a model not performing well, i.e., not making good predictions, because it wasn't able to correctly or completely capture the signal in the training set. In other words, the model is generalizing too much, to the point that it's actually missing the signal.This means that the model doesn't perform well on training examples (resulting in a high training loss), nor on examples it hasn't seen before (resulting in a high validation loss).",1
Undersampling,"It's the process of balancing a dataset by discarding examples of one or more overrepresented classes so that each has the same amount of examples.A balanced dataset allows a model to learn equal amounts of characteristics from each one of the classes represented in the dataset, as opposed to one class dominating what the model learns.Use when you have an  imbalanced dataset. Note that oversampling is usually preferred to undersampling as data is rarely overabundant.",1
What is Undersampling,"It's the process of balancing a dataset by discarding examples of one or more overrepresented classes so that each has the same amount of examples.A balanced dataset allows a model to learn equal amounts of characteristics from each one of the classes represented in the dataset, as opposed to one class dominating what the model learns.Use when you have an  imbalanced dataset. Note that oversampling is usually preferred to undersampling as data is rarely overabundant.",1
Can you help me with Undersampling,"It's the process of balancing a dataset by discarding examples of one or more overrepresented classes so that each has the same amount of examples.A balanced dataset allows a model to learn equal amounts of characteristics from each one of the classes represented in the dataset, as opposed to one class dominating what the model learns.Use when you have an  imbalanced dataset. Note that oversampling is usually preferred to undersampling as data is rarely overabundant.",1
What does Undersampling mean?,"It's the process of balancing a dataset by discarding examples of one or more overrepresented classes so that each has the same amount of examples.A balanced dataset allows a model to learn equal amounts of characteristics from each one of the classes represented in the dataset, as opposed to one class dominating what the model learns.Use when you have an  imbalanced dataset. Note that oversampling is usually preferred to undersampling as data is rarely overabundant.",1
How do I use Undersampling?,"It's the process of balancing a dataset by discarding examples of one or more overrepresented classes so that each has the same amount of examples.A balanced dataset allows a model to learn equal amounts of characteristics from each one of the classes represented in the dataset, as opposed to one class dominating what the model learns.Use when you have an  imbalanced dataset. Note that oversampling is usually preferred to undersampling as data is rarely overabundant.",1
Unsupervised learning,"Unsupervised learning is the task of learning a model from a dataset that doesn't have labeled examples. In other words, it is the task of learning a model that captures the underlying (or hidden / latent) structures and patterns in the dataset. Examples include: clustering and dimensionality reduction.",1
What is Unsupervised learning,"Unsupervised learning is the task of learning a model from a dataset that doesn't have labeled examples. In other words, it is the task of learning a model that captures the underlying (or hidden / latent) structures and patterns in the dataset. Examples include: clustering and dimensionality reduction.",1
Can you help me with Unsupervised learning,"Unsupervised learning is the task of learning a model from a dataset that doesn't have labeled examples. In other words, it is the task of learning a model that captures the underlying (or hidden / latent) structures and patterns in the dataset. Examples include: clustering and dimensionality reduction.",1
What does Unsupervised learning mean?,"Unsupervised learning is the task of learning a model from a dataset that doesn't have labeled examples. In other words, it is the task of learning a model that captures the underlying (or hidden / latent) structures and patterns in the dataset. Examples include: clustering and dimensionality reduction.",1
How do I use Unsupervised learning?,"Unsupervised learning is the task of learning a model from a dataset that doesn't have labeled examples. In other words, it is the task of learning a model that captures the underlying (or hidden / latent) structures and patterns in the dataset. Examples include: clustering and dimensionality reduction.",1
Validation example,A validation example is an example that is included in your validation set.,1
What is Validation example,A validation example is an example that is included in your validation set.,1
Can you help me with Validation example,A validation example is an example that is included in your validation set.,1
What does Validation example mean?,A validation example is an example that is included in your validation set.,1
How do I use Validation example?,A validation example is an example that is included in your validation set.,1
Validation loss,Validation loss is the average loss per validation example of your model based on your validation set.,1
What is Validation loss,Validation loss is the average loss per validation example of your model based on your validation set.,1
Can you help me with Validation loss,Validation loss is the average loss per validation example of your model based on your validation set.,1
What does Validation loss mean?,Validation loss is the average loss per validation example of your model based on your validation set.,1
How do I use Validation loss?,Validation loss is the average loss per validation example of your model based on your validation set.,1
Validation set,"A validation set is a subset of your dataset which contains examples available to a neural network to adjust the hyperarameters or the model architecture based on the validation loss.The validation set is used during training to run validation examples through the model after each epoch, in order to compute the validation loss. A good model (one that generalizes well) is one where the training loss is as small as possible, while at the same time keeping the gap between the trainingand validation loss as small as possible.If the validation loss is high or starts increasing during early training, training can be stopped to adjust the hyperarameters or the model architecture, in order to improve the model's performance. Alternatively, if the validation loss starts increasing after it being at a comparatively low level, training can be stopped to prevent the model from overfitting.In short: the validation set is used to tune the model's hyperarameters or the model architecture (i.e., learning rate, number of layers, etc.)",1
What is Validation set,"A validation set is a subset of your dataset which contains examples available to a neural network to adjust the hyperarameters or the model architecture based on the validation loss.The validation set is used during training to run validation examples through the model after each epoch, in order to compute the validation loss. A good model (one that generalizes well) is one where the training loss is as small as possible, while at the same time keeping the gap between the trainingand validation loss as small as possible.If the validation loss is high or starts increasing during early training, training can be stopped to adjust the hyperarameters or the model architecture, in order to improve the model's performance. Alternatively, if the validation loss starts increasing after it being at a comparatively low level, training can be stopped to prevent the model from overfitting.In short: the validation set is used to tune the model's hyperarameters or the model architecture (i.e., learning rate, number of layers, etc.)",1
Can you help me with Validation set,"A validation set is a subset of your dataset which contains examples available to a neural network to adjust the hyperarameters or the model architecture based on the validation loss.The validation set is used during training to run validation examples through the model after each epoch, in order to compute the validation loss. A good model (one that generalizes well) is one where the training loss is as small as possible, while at the same time keeping the gap between the trainingand validation loss as small as possible.If the validation loss is high or starts increasing during early training, training can be stopped to adjust the hyperarameters or the model architecture, in order to improve the model's performance. Alternatively, if the validation loss starts increasing after it being at a comparatively low level, training can be stopped to prevent the model from overfitting.In short: the validation set is used to tune the model's hyperarameters or the model architecture (i.e., learning rate, number of layers, etc.)",1
What does Validation set mean?,"A validation set is a subset of your dataset which contains examples available to a neural network to adjust the hyperarameters or the model architecture based on the validation loss.The validation set is used during training to run validation examples through the model after each epoch, in order to compute the validation loss. A good model (one that generalizes well) is one where the training loss is as small as possible, while at the same time keeping the gap between the trainingand validation loss as small as possible.If the validation loss is high or starts increasing during early training, training can be stopped to adjust the hyperarameters or the model architecture, in order to improve the model's performance. Alternatively, if the validation loss starts increasing after it being at a comparatively low level, training can be stopped to prevent the model from overfitting.In short: the validation set is used to tune the model's hyperarameters or the model architecture (i.e., learning rate, number of layers, etc.)",1
How do I use Validation set?,"A validation set is a subset of your dataset which contains examples available to a neural network to adjust the hyperarameters or the model architecture based on the validation loss.The validation set is used during training to run validation examples through the model after each epoch, in order to compute the validation loss. A good model (one that generalizes well) is one where the training loss is as small as possible, while at the same time keeping the gap between the trainingand validation loss as small as possible.If the validation loss is high or starts increasing during early training, training can be stopped to adjust the hyperarameters or the model architecture, in order to improve the model's performance. Alternatively, if the validation loss starts increasing after it being at a comparatively low level, training can be stopped to prevent the model from overfitting.In short: the validation set is used to tune the model's hyperarameters or the model architecture (i.e., learning rate, number of layers, etc.)",1
Vanishing gradient problem,"The vanishing gradient problem is the phenomenon of the gradients calculated by gradient descent getting progressively smaller when moving backward in the networks from output to input layer.This means that the weights of the nodes in early layers only change slowly (compared to later layers in a network), which means that they train and hence, learn, very slowly or not at all.",1
What is Vanishing gradient problem,"The vanishing gradient problem is the phenomenon of the gradients calculated by gradient descent getting progressively smaller when moving backward in the networks from output to input layer.This means that the weights of the nodes in early layers only change slowly (compared to later layers in a network), which means that they train and hence, learn, very slowly or not at all.",1
Can you help me with Vanishing gradient problem,"The vanishing gradient problem is the phenomenon of the gradients calculated by gradient descent getting progressively smaller when moving backward in the networks from output to input layer.This means that the weights of the nodes in early layers only change slowly (compared to later layers in a network), which means that they train and hence, learn, very slowly or not at all.",1
What does Vanishing gradient problem mean?,"The vanishing gradient problem is the phenomenon of the gradients calculated by gradient descent getting progressively smaller when moving backward in the networks from output to input layer.This means that the weights of the nodes in early layers only change slowly (compared to later layers in a network), which means that they train and hence, learn, very slowly or not at all.",1
How do I use Vanishing gradient problem?,"The vanishing gradient problem is the phenomenon of the gradients calculated by gradient descent getting progressively smaller when moving backward in the networks from output to input layer.This means that the weights of the nodes in early layers only change slowly (compared to later layers in a network), which means that they train and hence, learn, very slowly or not at all.",1
Weight initialization,"Weight initialization is the process of assigning some starting values to the weights of your model, before starting training.The starting values of the weights have a significant impact on the training of your model. Naïve initialization strategies, like making the initial value of all weights equal to 0, can result in your model not learning anything at all (or in other words, gradient descent is unable to converge). A good weight initialization strategy can also help prevent the vanishing / exploding gradient problem.Always use a weight initilization strategy with dense layers, convolutional layers and LSTM units.",1
What is Weight initialization,"Weight initialization is the process of assigning some starting values to the weights of your model, before starting training.The starting values of the weights have a significant impact on the training of your model. Naïve initialization strategies, like making the initial value of all weights equal to 0, can result in your model not learning anything at all (or in other words, gradient descent is unable to converge). A good weight initialization strategy can also help prevent the vanishing / exploding gradient problem.Always use a weight initilization strategy with dense layers, convolutional layers and LSTM units.",1
Can you help me with Weight initialization,"Weight initialization is the process of assigning some starting values to the weights of your model, before starting training.The starting values of the weights have a significant impact on the training of your model. Naïve initialization strategies, like making the initial value of all weights equal to 0, can result in your model not learning anything at all (or in other words, gradient descent is unable to converge). A good weight initialization strategy can also help prevent the vanishing / exploding gradient problem.Always use a weight initilization strategy with dense layers, convolutional layers and LSTM units.",1
What does Weight initialization mean?,"Weight initialization is the process of assigning some starting values to the weights of your model, before starting training.The starting values of the weights have a significant impact on the training of your model. Naïve initialization strategies, like making the initial value of all weights equal to 0, can result in your model not learning anything at all (or in other words, gradient descent is unable to converge). A good weight initialization strategy can also help prevent the vanishing / exploding gradient problem.Always use a weight initilization strategy with dense layers, convolutional layers and LSTM units.",1
How do I use Weight initialization?,"Weight initialization is the process of assigning some starting values to the weights of your model, before starting training.The starting values of the weights have a significant impact on the training of your model. Naïve initialization strategies, like making the initial value of all weights equal to 0, can result in your model not learning anything at all (or in other words, gradient descent is unable to converge). A good weight initialization strategy can also help prevent the vanishing / exploding gradient problem.Always use a weight initilization strategy with dense layers, convolutional layers and LSTM units.",1
Weights,"The weights and the operations performed on them by a neural network are the way your model is encoded in the network. A weight is a trainable parameter and it's value can be thought of as the strength of the connection between different nodes. The higher the weight, the stronger the connection between two nodes or alternatively, the more important that connections is for the model to predict the target.",1
What is Weights,"The weights and the operations performed on them by a neural network are the way your model is encoded in the network. A weight is a trainable parameter and it's value can be thought of as the strength of the connection between different nodes. The higher the weight, the stronger the connection between two nodes or alternatively, the more important that connections is for the model to predict the target.",1
Can you help me with Weights,"The weights and the operations performed on them by a neural network are the way your model is encoded in the network. A weight is a trainable parameter and it's value can be thought of as the strength of the connection between different nodes. The higher the weight, the stronger the connection between two nodes or alternatively, the more important that connections is for the model to predict the target.",1
What does Weights mean?,"The weights and the operations performed on them by a neural network are the way your model is encoded in the network. A weight is a trainable parameter and it's value can be thought of as the strength of the connection between different nodes. The higher the weight, the stronger the connection between two nodes or alternatively, the more important that connections is for the model to predict the target.",1
How do I use Weights?,"The weights and the operations performed on them by a neural network are the way your model is encoded in the network. A weight is a trainable parameter and it's value can be thought of as the strength of the connection between different nodes. The higher the weight, the stronger the connection between two nodes or alternatively, the more important that connections is for the model to predict the target.",1
Xavier initialization,See glorot uniform initialization,1
What is Xavier initialization,See glorot uniform initialization,1
Can you help me with Xavier initialization,See glorot uniform initialization,1
What does Xavier initialization mean?,See glorot uniform initialization,1
How do I use Xavier initialization?,See glorot uniform initialization,1
Z-Score normalize,See standardization.,1
What is Z-Score normalize,See standardization.,1
Can you help me with Z-Score normalize,See standardization.,1
What does Z-Score normalize mean?,See standardization.,1
How do I use Z-Score normalize?,See standardization.,1
Deploy an operational AI model,"We have a tutorial called ""Deploy an operational AI model"" here: /knowledge-center/documentation/tutorials/deploy-an-operational-ai-model",1
Can you tell me about Deploy an operational AI model,"We have a tutorial called ""Deploy an operational AI model"" here: /knowledge-center/documentation/tutorials/deploy-an-operational-ai-model",1
Can you help me with Deploy an operational AI model,"We have a tutorial called ""Deploy an operational AI model"" here: /knowledge-center/documentation/tutorials/deploy-an-operational-ai-model",1
I want to Deploy an operational AI model,"We have a tutorial called ""Deploy an operational AI model"" here: /knowledge-center/documentation/tutorials/deploy-an-operational-ai-model",1
How can I Deploy an operational AI model,"We have a tutorial called ""Deploy an operational AI model"" here: /knowledge-center/documentation/tutorials/deploy-an-operational-ai-model",1
Self sorting wardrobe,"We have a tutorial called ""Self sorting wardrobe"" here: /knowledge-center/documentation/tutorials/self-sorting-wardrobe",1
Can you tell me about Self sorting wardrobe,"We have a tutorial called ""Self sorting wardrobe"" here: /knowledge-center/documentation/tutorials/self-sorting-wardrobe",1
Can you help me with Self sorting wardrobe,"We have a tutorial called ""Self sorting wardrobe"" here: /knowledge-center/documentation/tutorials/self-sorting-wardrobe",1
I want to Self sorting wardrobe,"We have a tutorial called ""Self sorting wardrobe"" here: /knowledge-center/documentation/tutorials/self-sorting-wardrobe",1
How can I Self sorting wardrobe,"We have a tutorial called ""Self sorting wardrobe"" here: /knowledge-center/documentation/tutorials/self-sorting-wardrobe",1
Movie review feelings,"We have a tutorial called ""Movie review feelings"" here: /knowledge-center/documentation/tutorials/movie-review-feelings",1
Can you tell me about Movie review feelings,"We have a tutorial called ""Movie review feelings"" here: /knowledge-center/documentation/tutorials/movie-review-feelings",1
Can you help me with Movie review feelings,"We have a tutorial called ""Movie review feelings"" here: /knowledge-center/documentation/tutorials/movie-review-feelings",1
I want to Movie review feelings,"We have a tutorial called ""Movie review feelings"" here: /knowledge-center/documentation/tutorials/movie-review-feelings",1
How can I Movie review feelings,"We have a tutorial called ""Movie review feelings"" here: /knowledge-center/documentation/tutorials/movie-review-feelings",1
Classify text in any language,"We have a tutorial called ""Classify text in any language"" here: /knowledge-center/documentation/tutorials/classify-text-in-any-language",1
Can you tell me about Classify text in any language,"We have a tutorial called ""Classify text in any language"" here: /knowledge-center/documentation/tutorials/classify-text-in-any-language",1
Can you help me with Classify text in any language,"We have a tutorial called ""Classify text in any language"" here: /knowledge-center/documentation/tutorials/classify-text-in-any-language",1
I want to Classify text in any language,"We have a tutorial called ""Classify text in any language"" here: /knowledge-center/documentation/tutorials/classify-text-in-any-language",1
How can I Classify text in any language,"We have a tutorial called ""Classify text in any language"" here: /knowledge-center/documentation/tutorials/classify-text-in-any-language",1
Car damage assessment,"We have a tutorial called ""Car damage assessment"" here: /knowledge-center/documentation/tutorials/car-damage-assessment",1
Can you tell me about Car damage assessment,"We have a tutorial called ""Car damage assessment"" here: /knowledge-center/documentation/tutorials/car-damage-assessment",1
Can you help me with Car damage assessment,"We have a tutorial called ""Car damage assessment"" here: /knowledge-center/documentation/tutorials/car-damage-assessment",1
I want to Car damage assessment,"We have a tutorial called ""Car damage assessment"" here: /knowledge-center/documentation/tutorials/car-damage-assessment",1
How can I Car damage assessment,"We have a tutorial called ""Car damage assessment"" here: /knowledge-center/documentation/tutorials/car-damage-assessment",1
Book genre classification,"We have a tutorial called ""Book genre classification"" here: /knowledge-center/documentation/tutorials/book-genre-classification",1
Can you tell me about Book genre classification,"We have a tutorial called ""Book genre classification"" here: /knowledge-center/documentation/tutorials/book-genre-classification",1
Can you help me with Book genre classification,"We have a tutorial called ""Book genre classification"" here: /knowledge-center/documentation/tutorials/book-genre-classification",1
I want to Book genre classification,"We have a tutorial called ""Book genre classification"" here: /knowledge-center/documentation/tutorials/book-genre-classification",1
How can I Book genre classification,"We have a tutorial called ""Book genre classification"" here: /knowledge-center/documentation/tutorials/book-genre-classification",1
Use AI to detect fraud,"We have a tutorial called ""Use AI to detect fraud"" here: /knowledge-center/documentation/tutorials/use-ai-to-detect-fraud",1
Can you tell me about Use AI to detect fraud,"We have a tutorial called ""Use AI to detect fraud"" here: /knowledge-center/documentation/tutorials/use-ai-to-detect-fraud",1
Can you help me with Use AI to detect fraud,"We have a tutorial called ""Use AI to detect fraud"" here: /knowledge-center/documentation/tutorials/use-ai-to-detect-fraud",1
I want to Use AI to detect fraud,"We have a tutorial called ""Use AI to detect fraud"" here: /knowledge-center/documentation/tutorials/use-ai-to-detect-fraud",1
How can I Use AI to detect fraud,"We have a tutorial called ""Use AI to detect fraud"" here: /knowledge-center/documentation/tutorials/use-ai-to-detect-fraud",1
Detecting defects in mass produced parts,"We have a tutorial called ""Detecting defects in mass produced parts"" here: /knowledge-center/documentation/tutorials/detecting-defects-in-mass-produced-parts",1
Can you tell me about Detecting defects in mass produced parts,"We have a tutorial called ""Detecting defects in mass produced parts"" here: /knowledge-center/documentation/tutorials/detecting-defects-in-mass-produced-parts",1
Can you help me with Detecting defects in mass produced parts,"We have a tutorial called ""Detecting defects in mass produced parts"" here: /knowledge-center/documentation/tutorials/detecting-defects-in-mass-produced-parts",1
I want to Detecting defects in mass produced parts,"We have a tutorial called ""Detecting defects in mass produced parts"" here: /knowledge-center/documentation/tutorials/detecting-defects-in-mass-produced-parts",1
How can I Detecting defects in mass produced parts,"We have a tutorial called ""Detecting defects in mass produced parts"" here: /knowledge-center/documentation/tutorials/detecting-defects-in-mass-produced-parts",1
Buy or not? Predict from tabular data,"We have a tutorial called ""Buy or not? Predict from tabular data"" here: /knowledge-center/documentation/tutorials/buy-or-not-/-predict-from-tabular-data",1
Can you tell me about Buy or not? Predict from tabular data,"We have a tutorial called ""Buy or not? Predict from tabular data"" here: /knowledge-center/documentation/tutorials/buy-or-not-/-predict-from-tabular-data",1
Can you help me with Buy or not? Predict from tabular data,"We have a tutorial called ""Buy or not? Predict from tabular data"" here: /knowledge-center/documentation/tutorials/buy-or-not-/-predict-from-tabular-data",1
I want to Buy or not? Predict from tabular data,"We have a tutorial called ""Buy or not? Predict from tabular data"" here: /knowledge-center/documentation/tutorials/buy-or-not-/-predict-from-tabular-data",1
How can I Buy or not? Predict from tabular data,"We have a tutorial called ""Buy or not? Predict from tabular data"" here: /knowledge-center/documentation/tutorials/buy-or-not-/-predict-from-tabular-data",1
Fruit similarity search,"We have a tutorial called ""Fruit similarity search"" here: /knowledge-center/documentation/tutorials/find-similar-images-of-fruits",1
Can you tell me about Fruit similarity search,"We have a tutorial called ""Fruit similarity search"" here: /knowledge-center/documentation/tutorials/find-similar-images-of-fruits",1
Can you help me with Fruit similarity search,"We have a tutorial called ""Fruit similarity search"" here: /knowledge-center/documentation/tutorials/find-similar-images-of-fruits",1
I want to Fruit similarity search,"We have a tutorial called ""Fruit similarity search"" here: /knowledge-center/documentation/tutorials/find-similar-images-of-fruits",1
How can I Fruit similarity search,"We have a tutorial called ""Fruit similarity search"" here: /knowledge-center/documentation/tutorials/find-similar-images-of-fruits",1
Text similarity search,"We have a tutorial called ""Text similarity search"" here: /knowledge-center/documentation/tutorials/find-similar-google-questions",1
Can you tell me about Text similarity search,"We have a tutorial called ""Text similarity search"" here: /knowledge-center/documentation/tutorials/find-similar-google-questions",1
Can you help me with Text similarity search,"We have a tutorial called ""Text similarity search"" here: /knowledge-center/documentation/tutorials/find-similar-google-questions",1
I want to Text similarity search,"We have a tutorial called ""Text similarity search"" here: /knowledge-center/documentation/tutorials/find-similar-google-questions",1
How can I Text similarity search,"We have a tutorial called ""Text similarity search"" here: /knowledge-center/documentation/tutorials/find-similar-google-questions",1
Create a team mood dashboard with Slack data,"We have a tutorial called ""Create a team mood dashboard with Slack data"" here: /knowledge-center/documentation/tutorials/understand-the-mood-of-your-team-with-slack-data",1
Can you tell me about Create a team mood dashboard with Slack data,"We have a tutorial called ""Create a team mood dashboard with Slack data"" here: /knowledge-center/documentation/tutorials/understand-the-mood-of-your-team-with-slack-data",1
Can you help me with Create a team mood dashboard with Slack data,"We have a tutorial called ""Create a team mood dashboard with Slack data"" here: /knowledge-center/documentation/tutorials/understand-the-mood-of-your-team-with-slack-data",1
I want to Create a team mood dashboard with Slack data,"We have a tutorial called ""Create a team mood dashboard with Slack data"" here: /knowledge-center/documentation/tutorials/understand-the-mood-of-your-team-with-slack-data",1
How can I Create a team mood dashboard with Slack data,"We have a tutorial called ""Create a team mood dashboard with Slack data"" here: /knowledge-center/documentation/tutorials/understand-the-mood-of-your-team-with-slack-data",1
Sales forecasting with spreadsheet integration,"We have a tutorial called ""Sales forecasting with spreadsheet integration"" here: /knowledge-center/documentation/tutorials/sales-forecasting-with-spreadsheet-integration",1
Can you tell me about Sales forecasting with spreadsheet integration,"We have a tutorial called ""Sales forecasting with spreadsheet integration"" here: /knowledge-center/documentation/tutorials/sales-forecasting-with-spreadsheet-integration",1
Can you help me with Sales forecasting with spreadsheet integration,"We have a tutorial called ""Sales forecasting with spreadsheet integration"" here: /knowledge-center/documentation/tutorials/sales-forecasting-with-spreadsheet-integration",1
I want to Sales forecasting with spreadsheet integration,"We have a tutorial called ""Sales forecasting with spreadsheet integration"" here: /knowledge-center/documentation/tutorials/sales-forecasting-with-spreadsheet-integration",1
How can I Sales forecasting with spreadsheet integration,"We have a tutorial called ""Sales forecasting with spreadsheet integration"" here: /knowledge-center/documentation/tutorials/sales-forecasting-with-spreadsheet-integration",1
Integrate AI into Microsoft Excel for sales forecasting,"We have a tutorial called ""Integrate AI into Microsoft Excel for sales forecasting"" here: /knowledge-center/documentation/tutorials/integrate-ai-into-microsoft-excel-for-sales-forecasting",1
Can you tell me about Integrate AI into Microsoft Excel for sales forecasting,"We have a tutorial called ""Integrate AI into Microsoft Excel for sales forecasting"" here: /knowledge-center/documentation/tutorials/integrate-ai-into-microsoft-excel-for-sales-forecasting",1
Can you help me with Integrate AI into Microsoft Excel for sales forecasting,"We have a tutorial called ""Integrate AI into Microsoft Excel for sales forecasting"" here: /knowledge-center/documentation/tutorials/integrate-ai-into-microsoft-excel-for-sales-forecasting",1
I want to Integrate AI into Microsoft Excel for sales forecasting,"We have a tutorial called ""Integrate AI into Microsoft Excel for sales forecasting"" here: /knowledge-center/documentation/tutorials/integrate-ai-into-microsoft-excel-for-sales-forecasting",1
How can I Integrate AI into Microsoft Excel for sales forecasting,"We have a tutorial called ""Integrate AI into Microsoft Excel for sales forecasting"" here: /knowledge-center/documentation/tutorials/integrate-ai-into-microsoft-excel-for-sales-forecasting",1
Integrate AI into Google Sheets for sales forecasting,"We have a tutorial called ""Integrate AI into Google Sheets for sales forecasting"" here: /knowledge-center/documentation/tutorials/integrate-ai-into-google-sheets-for-sales-forecasting",1
Can you tell me about Integrate AI into Google Sheets for sales forecasting,"We have a tutorial called ""Integrate AI into Google Sheets for sales forecasting"" here: /knowledge-center/documentation/tutorials/integrate-ai-into-google-sheets-for-sales-forecasting",1
Can you help me with Integrate AI into Google Sheets for sales forecasting,"We have a tutorial called ""Integrate AI into Google Sheets for sales forecasting"" here: /knowledge-center/documentation/tutorials/integrate-ai-into-google-sheets-for-sales-forecasting",1
I want to Integrate AI into Google Sheets for sales forecasting,"We have a tutorial called ""Integrate AI into Google Sheets for sales forecasting"" here: /knowledge-center/documentation/tutorials/integrate-ai-into-google-sheets-for-sales-forecasting",1
How can I Integrate AI into Google Sheets for sales forecasting,"We have a tutorial called ""Integrate AI into Google Sheets for sales forecasting"" here: /knowledge-center/documentation/tutorials/integrate-ai-into-google-sheets-for-sales-forecasting",1
Build your own music critic,"We have a tutorial called ""Build your own music critic"" here: /knowledge-center/documentation/tutorials/build-your-own-music-critic",1
Can you tell me about Build your own music critic,"We have a tutorial called ""Build your own music critic"" here: /knowledge-center/documentation/tutorials/build-your-own-music-critic",1
Can you help me with Build your own music critic,"We have a tutorial called ""Build your own music critic"" here: /knowledge-center/documentation/tutorials/build-your-own-music-critic",1
I want to Build your own music critic,"We have a tutorial called ""Build your own music critic"" here: /knowledge-center/documentation/tutorials/build-your-own-music-critic",1
How can I Build your own music critic,"We have a tutorial called ""Build your own music critic"" here: /knowledge-center/documentation/tutorials/build-your-own-music-critic",1
Verify images with Zapier and Peltarion,"We have a tutorial called ""Verify images with Zapier and Peltarion"" here: /knowledge-center/documentation/tutorials/verify-images-with-zapier-and-peltarion",1
Can you tell me about Verify images with Zapier and Peltarion,"We have a tutorial called ""Verify images with Zapier and Peltarion"" here: /knowledge-center/documentation/tutorials/verify-images-with-zapier-and-peltarion",1
Can you help me with Verify images with Zapier and Peltarion,"We have a tutorial called ""Verify images with Zapier and Peltarion"" here: /knowledge-center/documentation/tutorials/verify-images-with-zapier-and-peltarion",1
I want to Verify images with Zapier and Peltarion,"We have a tutorial called ""Verify images with Zapier and Peltarion"" here: /knowledge-center/documentation/tutorials/verify-images-with-zapier-and-peltarion",1
How can I Verify images with Zapier and Peltarion,"We have a tutorial called ""Verify images with Zapier and Peltarion"" here: /knowledge-center/documentation/tutorials/verify-images-with-zapier-and-peltarion",1
Predict real estate prices,"We have a tutorial called ""Predict real estate prices"" here: /knowledge-center/documentation/tutorials/predict-real-estate-prices",1
Can you tell me about Predict real estate prices,"We have a tutorial called ""Predict real estate prices"" here: /knowledge-center/documentation/tutorials/predict-real-estate-prices",1
Can you help me with Predict real estate prices,"We have a tutorial called ""Predict real estate prices"" here: /knowledge-center/documentation/tutorials/predict-real-estate-prices",1
I want to Predict real estate prices,"We have a tutorial called ""Predict real estate prices"" here: /knowledge-center/documentation/tutorials/predict-real-estate-prices",1
How can I Predict real estate prices,"We have a tutorial called ""Predict real estate prices"" here: /knowledge-center/documentation/tutorials/predict-real-estate-prices",1
Look deep into DNA,"We have a tutorial called ""Look deep into DNA"" here: /knowledge-center/documentation/tutorials/look-deep-into-dna",1
Can you tell me about Look deep into DNA,"We have a tutorial called ""Look deep into DNA"" here: /knowledge-center/documentation/tutorials/look-deep-into-dna",1
Can you help me with Look deep into DNA,"We have a tutorial called ""Look deep into DNA"" here: /knowledge-center/documentation/tutorials/look-deep-into-dna",1
I want to Look deep into DNA,"We have a tutorial called ""Look deep into DNA"" here: /knowledge-center/documentation/tutorials/look-deep-into-dna",1
How can I Look deep into DNA,"We have a tutorial called ""Look deep into DNA"" here: /knowledge-center/documentation/tutorials/look-deep-into-dna",1
Skin cancer detection,"We have a tutorial called ""Skin cancer detection"" here: /knowledge-center/documentation/tutorials/skin-cancer-detection",1
Can you tell me about Skin cancer detection,"We have a tutorial called ""Skin cancer detection"" here: /knowledge-center/documentation/tutorials/skin-cancer-detection",1
Can you help me with Skin cancer detection,"We have a tutorial called ""Skin cancer detection"" here: /knowledge-center/documentation/tutorials/skin-cancer-detection",1
I want to Skin cancer detection,"We have a tutorial called ""Skin cancer detection"" here: /knowledge-center/documentation/tutorials/skin-cancer-detection",1
How can I Skin cancer detection,"We have a tutorial called ""Skin cancer detection"" here: /knowledge-center/documentation/tutorials/skin-cancer-detection",1
How to Improve a model you have built on tabular data,"We have a tutorial called ""How to Improve a model you have built on tabular data"" here: /knowledge-center/documentation/tutorials/how-to-improve-a-model-that-uses-tabular-data",1
Can you tell me about How to Improve a model you have built on tabular data,"We have a tutorial called ""How to Improve a model you have built on tabular data"" here: /knowledge-center/documentation/tutorials/how-to-improve-a-model-that-uses-tabular-data",1
Can you help me with How to Improve a model you have built on tabular data,"We have a tutorial called ""How to Improve a model you have built on tabular data"" here: /knowledge-center/documentation/tutorials/how-to-improve-a-model-that-uses-tabular-data",1
I want to How to Improve a model you have built on tabular data,"We have a tutorial called ""How to Improve a model you have built on tabular data"" here: /knowledge-center/documentation/tutorials/how-to-improve-a-model-that-uses-tabular-data",1
How can I How to Improve a model you have built on tabular data,"We have a tutorial called ""How to Improve a model you have built on tabular data"" here: /knowledge-center/documentation/tutorials/how-to-improve-a-model-that-uses-tabular-data",1
Kaggle competition with zero code,"We have a tutorial called ""Kaggle competition with zero code"" here: /knowledge-center/documentation/tutorials/kaggle-competition-with-zero-code",1
Can you tell me about Kaggle competition with zero code,"We have a tutorial called ""Kaggle competition with zero code"" here: /knowledge-center/documentation/tutorials/kaggle-competition-with-zero-code",1
Can you help me with Kaggle competition with zero code,"We have a tutorial called ""Kaggle competition with zero code"" here: /knowledge-center/documentation/tutorials/kaggle-competition-with-zero-code",1
I want to Kaggle competition with zero code,"We have a tutorial called ""Kaggle competition with zero code"" here: /knowledge-center/documentation/tutorials/kaggle-competition-with-zero-code",1
How can I Kaggle competition with zero code,"We have a tutorial called ""Kaggle competition with zero code"" here: /knowledge-center/documentation/tutorials/kaggle-competition-with-zero-code",1
Writing style tutor,"We have a tutorial called ""Writing style tutor"" here: /knowledge-center/documentation/tutorials/writing-style-tutor",1
Can you tell me about Writing style tutor,"We have a tutorial called ""Writing style tutor"" here: /knowledge-center/documentation/tutorials/writing-style-tutor",1
Can you help me with Writing style tutor,"We have a tutorial called ""Writing style tutor"" here: /knowledge-center/documentation/tutorials/writing-style-tutor",1
I want to Writing style tutor,"We have a tutorial called ""Writing style tutor"" here: /knowledge-center/documentation/tutorials/writing-style-tutor",1
How can I Writing style tutor,"We have a tutorial called ""Writing style tutor"" here: /knowledge-center/documentation/tutorials/writing-style-tutor",1
Denoising images,"We have a tutorial called ""Denoising images"" here: /knowledge-center/documentation/tutorials/denoising-images",1
Can you tell me about Denoising images,"We have a tutorial called ""Denoising images"" here: /knowledge-center/documentation/tutorials/denoising-images",1
Can you help me with Denoising images,"We have a tutorial called ""Denoising images"" here: /knowledge-center/documentation/tutorials/denoising-images",1
I want to Denoising images,"We have a tutorial called ""Denoising images"" here: /knowledge-center/documentation/tutorials/denoising-images",1
How can I Denoising images,"We have a tutorial called ""Denoising images"" here: /knowledge-center/documentation/tutorials/denoising-images",1
Create a no-code app,"We have a tutorial called ""Create a no-code app"" here: /knowledge-center/documentation/tutorials/create-a-no-code-ai-app",1
Can you tell me about Create a no-code app,"We have a tutorial called ""Create a no-code app"" here: /knowledge-center/documentation/tutorials/create-a-no-code-ai-app",1
Can you help me with Create a no-code app,"We have a tutorial called ""Create a no-code app"" here: /knowledge-center/documentation/tutorials/create-a-no-code-ai-app",1
I want to Create a no-code app,"We have a tutorial called ""Create a no-code app"" here: /knowledge-center/documentation/tutorials/create-a-no-code-ai-app",1
How can I Create a no-code app,"We have a tutorial called ""Create a no-code app"" here: /knowledge-center/documentation/tutorials/create-a-no-code-ai-app",1
Audio analysis for industrial maintenance,"We have a tutorial called ""Audio analysis for industrial maintenance"" here: /knowledge-center/documentation/tutorials/audio-analysis-for-industrial-maintenance",1
Can you tell me about Audio analysis for industrial maintenance,"We have a tutorial called ""Audio analysis for industrial maintenance"" here: /knowledge-center/documentation/tutorials/audio-analysis-for-industrial-maintenance",1
Can you help me with Audio analysis for industrial maintenance,"We have a tutorial called ""Audio analysis for industrial maintenance"" here: /knowledge-center/documentation/tutorials/audio-analysis-for-industrial-maintenance",1
I want to Audio analysis for industrial maintenance,"We have a tutorial called ""Audio analysis for industrial maintenance"" here: /knowledge-center/documentation/tutorials/audio-analysis-for-industrial-maintenance",1
How can I Audio analysis for industrial maintenance,"We have a tutorial called ""Audio analysis for industrial maintenance"" here: /knowledge-center/documentation/tutorials/audio-analysis-for-industrial-maintenance",1
Classify customer complaints,"We have a tutorial called ""Classify customer complaints"" here: /knowledge-center/documentation/tutorials/classify-customer-complaints",1
Can you tell me about Classify customer complaints,"We have a tutorial called ""Classify customer complaints"" here: /knowledge-center/documentation/tutorials/classify-customer-complaints",1
Can you help me with Classify customer complaints,"We have a tutorial called ""Classify customer complaints"" here: /knowledge-center/documentation/tutorials/classify-customer-complaints",1
I want to Classify customer complaints,"We have a tutorial called ""Classify customer complaints"" here: /knowledge-center/documentation/tutorials/classify-customer-complaints",1
How can I Classify customer complaints,"We have a tutorial called ""Classify customer complaints"" here: /knowledge-center/documentation/tutorials/classify-customer-complaints",1
Use Peltarion connector in Microsoft Power Apps,"We have a tutorial called ""Use Peltarion connector in Microsoft Power Apps"" here: /knowledge-center/documentation/tutorials/use-peltarion-connector-in-microsoft-powerapps",1
Can you tell me about Use Peltarion connector in Microsoft Power Apps,"We have a tutorial called ""Use Peltarion connector in Microsoft Power Apps"" here: /knowledge-center/documentation/tutorials/use-peltarion-connector-in-microsoft-powerapps",1
Can you help me with Use Peltarion connector in Microsoft Power Apps,"We have a tutorial called ""Use Peltarion connector in Microsoft Power Apps"" here: /knowledge-center/documentation/tutorials/use-peltarion-connector-in-microsoft-powerapps",1
I want to Use Peltarion connector in Microsoft Power Apps,"We have a tutorial called ""Use Peltarion connector in Microsoft Power Apps"" here: /knowledge-center/documentation/tutorials/use-peltarion-connector-in-microsoft-powerapps",1
How can I Use Peltarion connector in Microsoft Power Apps,"We have a tutorial called ""Use Peltarion connector in Microsoft Power Apps"" here: /knowledge-center/documentation/tutorials/use-peltarion-connector-in-microsoft-powerapps",1
Shape up your Slack chaos,"We have a tutorial called ""Shape up your Slack chaos"" here: /knowledge-center/documentation/tutorials/shape-up-your-slack-chaos",1
Can you tell me about Shape up your Slack chaos,"We have a tutorial called ""Shape up your Slack chaos"" here: /knowledge-center/documentation/tutorials/shape-up-your-slack-chaos",1
Can you help me with Shape up your Slack chaos,"We have a tutorial called ""Shape up your Slack chaos"" here: /knowledge-center/documentation/tutorials/shape-up-your-slack-chaos",1
I want to Shape up your Slack chaos,"We have a tutorial called ""Shape up your Slack chaos"" here: /knowledge-center/documentation/tutorials/shape-up-your-slack-chaos",1
How can I Shape up your Slack chaos,"We have a tutorial called ""Shape up your Slack chaos"" here: /knowledge-center/documentation/tutorials/shape-up-your-slack-chaos",1
What is the Peltarion Platform anyway?,"In short, the Peltarion Platform is a cloud-based operational AI platform that allows you to build and deploy your own deep learning models, even if youre not an AI superstar.",1
What do I need to use the Peltarion Platform?,"To use Peltarion Platform you basically need Google Chrome installed on your computer. Then youre good to go! For more detailed requirements, check our details in the Technical requirements article.",1
Where do I ask for help?,"If you have any questions about the Peltarion platform functionality, please contact support@peltarion.com.",1
How do I report a bug?,"If you find a bug, please submit a bug report through Platform issue report or send us an email to support@peltarion.com.",1
What was Synapse?,"Synapse was Peltarions first product. It was the most advanced adaptive- and neural systems development environment on the market at the time. Synapse allowed the user to design, train, analyze, and deploy adaptive systems, such as artificial neural networks.
If you want to know more, you should use Wayback Machine to peek into the past. This link will take you back to Peltarions documentation November 13th, 2013.",1
How do I navigate to the Datasets view?,"First, click + New project in the left panel to create a project. Then click on Open. This will take you to the Datasets view.",1
I use the downloaded .h5 when I test. Do I have to standardize the test dataset in the same way as the training dataset?,"Yes, you have to be consistent and perform the same preprocessing for your train and test dataset.",1
How can I view my results for the test dataset?,You cant use a test dataset on the Peltarion Platform right now. But you can use our tool Sidekick.,1
How do I prepare my data to fit the Platform?,"Use Sidekick! The code in Peltarions public GitHub repo Sidekick handles the mundane tasks like bundling up data into the Platforms preferred format.
Link: https://github.com/Peltarion/sidekick",1
I got an error message in the Modeling view. What does it mean?,"There are several error messages on the Platform. We try to make them as short and full of information as possible. But if you want further guidance, check out cause and remedy for each error message in Error messages.",1
Can I have  multiple input blocks?,"Yes, you can have multiple inputs, e.g., in our Tutorial - Predict California house prices, we use both images and tabular data as input.",1
Which block should use when Im designing my model?,It depends on your data and on your task. Check out our cheat sheets for tips and tricks on how to solve your problem.,1
How many nodes should I have in the last dense block?,"As many as the shape of your target, so it depends on your task.",1
How do I work with multiple experiments?,Easy experimenting is a key feature of the Peltarion Platform.,1
How do I use a deployed model?,"First, follow the instructions in the Deployment view part of the Knowledge center.",1
How do I reset my password?,"To reset your password, go to this link: Reset password.",1
How do I upgrade my usage plan?,"To upgrade your usage plan, please contact sales@peltarion.com.",1
